<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>YC Note - YC Chen</title><link>https://www.ycc.idv.tw/</link><description>YC Note, 機器學習(Machine Learning)、深度學習(Deep Learning)、類神經網路(Neural Network)、資料科學(Date Science)、Python、演算法(Algorithm)</description><lastBuildDate>Sat, 10 Oct 2020 12:00:00 +0800</lastBuildDate><item><title>OCR場景文字辨識：CRNN+CTC開源加詳細解析</title><link>https://www.ycc.idv.tw/crnn-ctc.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 10 Oct 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-10-10:/crnn-ctc.html</guid><category>cv</category></item><item><title>資源整理：跟上AI前沿知識</title><link>https://www.ycc.idv.tw/latest_ai_info.html</link><description>&lt;p&gt;AI領域日新月異，在這領域的玩家應該要持續的跟上最前沿的知識和技術，本篇文章整理了相關學術研討會、部落格，讓讀者可以輕易的接觸到可靠的新資源。（也歡迎讀者補充更多資訊）(持續更新)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 04 Jul 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-07-04:/latest_ai_info.html</guid></item><item><title>剖析深度學習 (4)：Sigmoid, Softmax怎麼來？為什麼要用MSE和Cross Entropy？談廣義線性模型</title><link>https://www.ycc.idv.tw/deep-dl_4.html</link><description>&lt;p&gt;學習一段時間深度學習的你是不是有一個疑惑：Activation Function為什麼要用Sigmoid和Softmax？Loss Function為什麼要用MSE和Cross Entropy？其他狀況要用什麼？當然你可以把它們看作是個合理定義，但是學習深度就端看你是不是可以用最少的定義表示最多的東西，如果你仔細google一下就會發現有一個相關的名詞—廣義線性定理，但是大部分的文章和教材都沒辦法將它講的很清楚，原因是因為沒有先介紹「充分統計量」的概念。在本講你會學到如何用「充分統計量」來說明在廣義線性定理中的Canonical Link Function，進而推導出Activation Function，你會學到如何藉由MLE和MAP來推導出Loss Function，學完以後你會對Activation Function和Loss Function有更深的認識。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 14 Mar 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-03-14:/deep-dl_4.html</guid><category>剖析深度學習</category></item><item><title>剖析深度學習 (3)：MLE、MAP差在哪？談機器學習裡的兩大統計觀點</title><link>https://www.ycc.idv.tw/deep-dl_3.html</link><description>&lt;p&gt;本講主要探討統計的兩大學派（頻率學派和貝氏學派）對於機器如何學習的觀點。頻率學派主張Maximum Likelihood Estimation (MLE)，會提到這等同於最小化data與model之間的Cross Entropy或KL Divergence。而貝氏學派則主張Maximum A Posterior (MAP) ，會提到這會等同於極大化Likelihood並同時考慮Regularization Term，我們也可以在本講看到L1和L2 Regularation Term是怎麼被導出的。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 07 Mar 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-03-07:/deep-dl_3.html</guid><category>剖析深度學習</category></item><item><title>剖析深度學習 (2)：你知道Cross Entropy和KL Divergence代表什麼意義嗎？談機器學習裡的資訊理論</title><link>https://www.ycc.idv.tw/deep-dl_2.html</link><description>&lt;p&gt;在深度學習裡面，尤其是分類問題，常常會用到Cross Entropy，教學上通常會從Maximum Likelihood推導而來，但是Cross Entropy其實具有更廣義的涵義，甚至不限於分類問題使用。還有學習過程也經常會出現KL Divergence這樣既熟悉又陌生的東西，甚至到了GAN會用到更多種類的Divergence，例如：JS Divergence。這全部都與資訊理論息息相關，這一講讓我們來搞清楚Entropy、Cross Entropy、KL Divergence和f-Divergence到底具有什麼涵義。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Tue, 25 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-25:/deep-dl_2.html</guid><category>剖析深度學習</category></item><item><title>剖析深度學習 (1)：為什麼Normal Distribution這麼好用？</title><link>https://www.ycc.idv.tw/deep-dl_1.html</link><description>&lt;p&gt;如果你已經學了好一陣子的機器學習或深度學習，應該對於Normal Distribution不陌生，但是你真的懂Normal Distribution嗎？本講會詳細的探討Normal Distribution，並且引入中央極限定理（Central Limit Theorm）來解釋為何自然界的隨機誤差大都呈現Normal Distribution，再來介紹Entropy，並且利用Entropy揭示Normal Distribution具有最少先驗知識（Prior Knowledge）的特性。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Tue, 18 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-18:/deep-dl_1.html</guid><category>剖析深度學習</category></item><item><title>[入埃及記] Day9-10: 開羅【埃及博物館、哈利利市集】</title><link>https://www.ycc.idv.tw/egypt-travel_8.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Thu, 13 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-13:/egypt-travel_8.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day8: 開羅Cairo【吉薩金字塔群、人面獅身像、香精專賣店、紙莎草專賣店】</title><link>https://www.ycc.idv.tw/egypt-travel_7.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Wed, 12 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-12:/egypt-travel_7.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day7: 虎加達Hurghada【紅海渡假勝地】</title><link>https://www.ycc.idv.tw/egypt-travel_6.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Tue, 11 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-11:/egypt-travel_6.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day6: 路克索【帝王谷、曼儂巨像】、虎加達</title><link>https://www.ycc.idv.tw/egypt-travel_5.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 10 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-10:/egypt-travel_5.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day5: 艾得夫 Edfu【艾得夫神殿】、伊斯納水匣門、路克索【路克索神殿、卡納克神殿】</title><link>https://www.ycc.idv.tw/egypt-travel_4.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 09 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-09:/egypt-travel_4.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day4: 阿布辛貝Abu Simbel【阿布辛貝雙神殿】、康孟波Kom Ombo【康孟波雙神殿】</title><link>https://www.ycc.idv.tw/egypt-travel_3.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 08 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-08:/egypt-travel_3.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day3: 亞斯文【亞斯文大水壩、騎駱駝拜訪努比亞人家、三角風帆船】</title><link>https://www.ycc.idv.tw/egypt-travel_2.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Fri, 07 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-07:/egypt-travel_2.html</guid><category>遊記</category><category>埃及</category></item><item><title>[入埃及記] Day1-2: 開羅 穆罕默德阿里清真寺</title><link>https://www.ycc.idv.tw/egypt-travel_1.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Wed, 05 Feb 2020 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2020-02-05:/egypt-travel_1.html</guid><category>遊記</category><category>埃及</category></item><item><title>[Paper] Wide &amp; Deep Learning for Recommender Systems</title><link>https://www.ycc.idv.tw/wide-and-deep-learning.html</link><description>&lt;p&gt;以往認為deep learning有辦法完全取代feature engineering，Google在2016年寫下的這篇paper，指出在數據相對稀疏（sparse）的情況下feature engineering仍然有其重要性&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 01 Jun 2019 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2019-06-01:/wide-and-deep-learning.html</guid><category>Papers</category></item><item><title>尾牙表演 - Sweet Child Oh Mine</title><link>https://www.ycc.idv.tw/sweet-child-oh-mine.html</link><description>&lt;p&gt;尾牙吼起來&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 30 Mar 2019 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2019-03-30:/sweet-child-oh-mine.html</guid><category>吉他</category></item><item><title>物件導向武功秘笈（3）：內功篇 — 物件導向指導原則SOLID</title><link>https://www.ycc.idv.tw/introduction-object-oriented-programming_3.html</link><description>&lt;p&gt;物件導向怎麼用才能成就好的程式碼？ / UML類別圖 / 單一職責原則(Single Responsibility Principle, SRP) / 開閉原則(Open-Closed Principle, OCP) / 里氏替換原則(Liskov Subsititution Principle, LSP) / 迪米特法則(Law of Demeter, LoD) / 依賴倒置原則(Dependence Inversion Principle, DIP) / 接口分隔原則(Interface Segregation Principle, ISP)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 14 Apr 2018 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2018-04-14:/introduction-object-oriented-programming_3.html</guid><category>軟體設計</category></item><item><title>物件導向武功秘笈（2）：招式篇 — Python與Java的物件導向編程介紹</title><link>https://www.ycc.idv.tw/introduction-object-oriented-programming_2.html</link><description>&lt;p&gt;物件導向編程 / 類別(Class)與物件(Object) / 方法多載（Method Overloading） / 物件導向三大特性—封裝(Encapsulation) / 物件導向三大特性—繼承(Inheritance) / 抽象化：抽象類別(Abstract Class)、抽象方法(Abstract Method)和接口(Interface) / 物件導向三大特性—多型(Polymorphism) /&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Tue, 10 Apr 2018 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2018-04-10:/introduction-object-oriented-programming_2.html</guid><category>軟體設計</category></item><item><title>物件導向武功秘笈（1）：認知篇 — 什麼是好的程式？</title><link>https://www.ycc.idv.tw/introduction-object-oriented-programming_1.html</link><description>&lt;p&gt;物件導向為何重要？ / 程式的好壞？ / 低耦合、高內聚 / 程式碼精練之旅 / 形塑出物件導向&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Thu, 05 Apr 2018 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2018-04-05:/introduction-object-oriented-programming_1.html</guid><category>軟體設計</category></item><item><title>自私的基因：基因觀點下的天擇</title><link>https://www.ycc.idv.tw/the-selfish-gene.html</link><description>&lt;p&gt;物競天擇？ / 生命源自於複製 / 基因的代理人—神經網絡 / 再談利他行為 / 文化的複製者—迷因（Meme）&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 03 Feb 2018 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2018-02-03:/the-selfish-gene.html</guid></item><item><title>實作Tensorflow (6)：Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM)</title><link>https://www.ycc.idv.tw/tensorflow-tutorial_6.html</link><description>&lt;p&gt;概論RNN / 梯度消失與梯度爆炸 / Long Short-Term Memory (LSTM) / 使用LSTM實作文章產生器&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 25 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-25:/tensorflow-tutorial_6.html</guid><category>Tensorflow</category></item><item><title>實作Tensorflow (5)：Word2Vec</title><link>https://www.ycc.idv.tw/tensorflow-tutorial_5.html</link><description>&lt;p&gt;Word2Vec觀念解析 / Word2Vec的架構 / Word2Vec的兩種常用方法：Skip-Gram和CBOW / 準備文本語料庫 / 實作Skip-Gram / 實作CBOW (Continuous Bag of Words)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 19 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-19:/tensorflow-tutorial_5.html</guid><category>Tensorflow</category></item><item><title>實作Tensorflow (4)：Autoencoder</title><link>https://www.ycc.idv.tw/tensorflow-tutorial_4.html</link><description>&lt;p&gt;Autoencoder觀念解析 / Autoencoder程式碼 / 測試Autoencoder / 壓縮碼Code與視覺化 / 去雜訊(De-noise) Autoencoder&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 18 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-18:/tensorflow-tutorial_4.html</guid><category>Tensorflow</category></item><item><title>實作Tensorflow (3)：Build First Convolutional Neurel Network (CNN)</title><link>https://www.ycc.idv.tw/tensorflow-tutorial_3.html</link><description>&lt;p&gt;影像有什麼特性 / DNN用在影像上的侷限 / Convolutional Neurel Network (CNN) / Convolution Layer / Pooling Layer / 最簡單的CNN架構：LeNet5 / 圖像化&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 12 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-12:/tensorflow-tutorial_3.html</guid><category>Tensorflow</category></item><item><title>[吉他] 方大同-三人遊</title><link>https://www.ycc.idv.tw/uwarn-performance_1.html</link><description>&lt;p&gt;有窩表演&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Thu, 09 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-09:/uwarn-performance_1.html</guid><category>吉他</category></item><item><title>[吉他] 光良-傷心地鐵</title><link>https://www.ycc.idv.tw/uwarn-performance_2.html</link><description>&lt;p&gt;有窩表演&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Wed, 08 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-08:/uwarn-performance_2.html</guid><category>吉他</category></item><item><title>實作Tensorflow (2)：Build First Deep Neurel Network (DNN)</title><link>https://www.ycc.idv.tw/tensorflow-tutorial_2.html</link><description>&lt;p&gt;增加Hidden Layer / Activation Function的選擇 / Mini-Batch Gradient Descent / Regularization / Weight Regularization / Dropout / Optimizer的選擇 / 來看看程式怎麼寫&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Tue, 07 Nov 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-11-07:/tensorflow-tutorial_2.html</guid><category>Tensorflow</category></item><item><title>實作Tensorflow (1)：Simple Logistic Classification on MNIST</title><link>https://www.ycc.idv.tw/tensorflow-tutorial_1.html</link><description>&lt;p&gt;MNIST Dataset / Softmax / Cross-Entropy Loss / 分離數據的重要性 / Tensorflow工作流程 / Tensorflow的基本「張量」元素 / Session的操作 / 第一個Tensorflow Model&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 23 Oct 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-10-23:/tensorflow-tutorial_1.html</guid><category>Tensorflow</category></item><item><title>股票策略：移動停損法</title><link>https://www.ycc.idv.tw/stock-sell-point.html</link><description>&lt;p&gt;簡言之就是「從買入當天開始算起，以過程的每天當中最高股價當作基準點，向下去設停損點，或是停利點，低於這點就當天賣，或隔天賣」&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Tue, 05 Sep 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-09-05:/stock-sell-point.html</guid></item><item><title>如何辨別機器學習模型的好壞？秒懂Confusion Matrix</title><link>https://www.ycc.idv.tw/confusion-matrix.html</link><description>&lt;p&gt;本篇介紹包含Confusion Matrix, True Positive, False Negative, False Positive, True Negative, Type I Error, Type II Error, Prevalence, Accuracy, Precision, Recall, F1 Measure, F Measure, Sensitivity, Specificity, ROC Curve, AUC, TPR, FNR, FPR, TNR, FDR, FOR, PPV, NPV, 算數平均, 幾何平均, 調和平均&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Fri, 04 Aug 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-08-04:/confusion-matrix.html</guid></item><item><title>Python玩數據 (3)：Numpy [2/2]</title><link>https://www.ycc.idv.tw/python-play-with-data_3.html</link><description>&lt;p&gt;產生ndarray的其他方法 / Broadcasting / Slice and Fancy Indexing /&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 06 May 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-05-06:/python-play-with-data_3.html</guid><category>Python玩數據</category></item><item><title>機器學習技法 學習筆記 (7)：Radial Basis Function Network與Matrix Factorization</title><link>https://www.ycc.idv.tw/ml-course-techniques_7.html</link><description>&lt;p&gt;本篇內容涵蓋Radial Basis Function (RBF) Network、K-Means、One-Hot Encoding和Matrix Factorization&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 22 Apr 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-04-22:/ml-course-techniques_7.html</guid><category>機器學習技法</category></item><item><title>機器學習技法 學習筆記 (6)：神經網路(Neural Network)與深度學習(Deep Learning)</title><link>https://www.ycc.idv.tw/ml-course-techniques_6.html</link><description>&lt;p&gt;本篇內容涵蓋神經網路(Neural Network, NN)、深度學習(Deep Learning, DL)、反向傳播算法(Backpropagation, BP)、Weight-elimination Regularizer、Early Stop、Autoencoder、Principal Component Analysis (PCA)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 17 Apr 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-04-17:/ml-course-techniques_6.html</guid><category>機器學習技法</category></item><item><title>Python玩數據 (2)：Numpy [1/2]</title><link>https://www.ycc.idv.tw/python-play-with-data_2.html</link><description>&lt;p&gt;Python常見的資料型別 / Numpy的數學運算 / Numpy基礎元素：ndarray / Numpy的矩陣運算&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 17 Apr 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-04-17:/python-play-with-data_2.html</guid><category>Python玩數據</category></item><item><title>大數據 Big Data:A Revolution That Will Transform How We Live, Work, and Think</title><link>https://www.ycc.idv.tw/big-data-a-revolution.html</link><description>&lt;p&gt;樣本=總體 / 允許不精確 / 「是什麼」比「為什麼」還重要 / 大數據時代的商業變革 / 全息社會&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Fri, 07 Apr 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-04-07:/big-data-a-revolution.html</guid></item><item><title>機器學習技法 學習筆記 (5)：Boost Aggregation Models</title><link>https://www.ycc.idv.tw/ml-course-techniques_5.html</link><description>&lt;p&gt;本篇內容涵蓋AdaBoost (Adaptive Boost)、Gradient Boost、AdaBoosted Decision Tree和Gradient Boosted Decision Tree (GBDT)。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 02 Apr 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-04-02:/ml-course-techniques_5.html</guid><category>機器學習技法</category></item><item><title>輕鬆談演算法的複雜度分界：什麼是P, NP, NP-Complete, NP-Hard問題</title><link>https://www.ycc.idv.tw/algorithm-complexity-theory.html</link><description>&lt;p&gt;Turing Machine / 時間複雜度 / P＝NP？ / NP-Complete 問題&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Thu, 30 Mar 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-03-30:/algorithm-complexity-theory.html</guid></item><item><title>機器學習技法 學習筆記 (4)：Basic Aggregation Models</title><link>https://www.ycc.idv.tw/ml-course-techniques_4.html</link><description>&lt;p&gt;本篇內容涵蓋Blending、Bagging、Decision Tree和Random Forest&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Wed, 29 Mar 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-03-29:/ml-course-techniques_4.html</guid><category>機器學習技法</category></item><item><title>讀書手札：大腦解密手冊 The Brain: The Story of You</title><link>https://www.ycc.idv.tw/the-brain-the-story-of-you.html</link><description>&lt;p&gt;大腦的可塑性 / 意識與無意識 / 腦中的交戰網路 / 科技將如何改變大腦的未來&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Fri, 24 Mar 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-03-24:/the-brain-the-story-of-you.html</guid></item><item><title>Python玩數據 (1)：安裝Python, IPython, Numpy, Pandas</title><link>https://www.ycc.idv.tw/python-play-with-data_1.html</link><description>&lt;p&gt;安裝Python, IPython, Numpy, Pandas&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 20 Mar 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-03-20:/python-play-with-data_1.html</guid><category>Python玩數據</category></item><item><title>從《如何閱讀一本書》想像一種不同的知識呈現方法</title><link>https://www.ycc.idv.tw/how-to-read-books.html</link><description>&lt;p&gt;書籍與網路的PK / 閱讀的層次 / 檢視閱讀 / 分析閱讀 / 主題閱讀 / 書籍與網路的第二回合PK&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sat, 18 Mar 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-03-18:/how-to-read-books.html</guid></item><item><title>機器學習技法 學習筆記 (3)：Kernel Regression</title><link>https://www.ycc.idv.tw/ml-course-techniques_3.html</link><description>&lt;p&gt;本篇內容涵蓋Probabilistic SVM、Kernel Logistic Regression、Kernel Ridge Regression、Support Vector Regression (SVR)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Wed, 15 Mar 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-03-15:/ml-course-techniques_3.html</guid><category>機器學習技法</category></item><item><title>機器學習技法 學習筆記 (2)：Support Vector Machine (SVM)</title><link>https://www.ycc.idv.tw/ml-course-techniques_2.html</link><description>&lt;p&gt;本篇內容涵蓋Hard-Margin Support Vector Machine (SVM)、Kernel Function、Kernel Hard-Margin SVM、Soft-Margin SVM、Kernel Soft-Margin SVM、拉格朗日乘子法（Lagrange Multiplier）、Lagrangian Dual Problem&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 20 Feb 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-02-20:/ml-course-techniques_2.html</guid><category>機器學習技法</category></item><item><title>機器學習技法 學習筆記 (1)：我們將會學到什麼? 先見林再來見樹</title><link>https://www.ycc.idv.tw/ml-course-techniques_1.html</link><description>&lt;p&gt;有什麼特徵可以使用？ / Embedding Numerous Features ：Kernel Models / Combining Predictive Features：Aggregation Models / Distilling Implicit Features：Extraction Models&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Thu, 12 Jan 2017 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2017-01-12:/ml-course-techniques_1.html</guid><category>機器學習技法</category></item><item><title>機器學習基石 學習筆記 (4)：機器可以怎麼學得更好?</title><link>https://www.ycc.idv.tw/ml-course-foundations_4.html</link><description>&lt;p&gt;特徵轉換 / Overfitting / Regularization / Validation&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 18 Sep 2016 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2016-09-18:/ml-course-foundations_4.html</guid><category>機器學習基石</category></item><item><title>機器學習基石 學習筆記 (3)：機器可以怎麼樣學習?</title><link>https://www.ycc.idv.tw/ml-course-foundations_3.html</link><description>&lt;p&gt;Gradient Descent / Linear Regression / Logistic Regression / 使用迴歸法做二元分類問題&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 07 Aug 2016 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2016-08-07:/ml-course-foundations_3.html</guid><category>機器學習基石</category></item><item><title>機器學習基石 學習筆記 (2)：為什麼機器可以學習?</title><link>https://www.ycc.idv.tw/ml-course-foundations_2.html</link><description>&lt;p&gt;機器可以學習嗎? / &lt;span class="math"&gt;\(E_{in}\)&lt;/span&gt;和&lt;span class="math"&gt;\(E_{out}\)&lt;/span&gt;的差異 / VC Generalization Bound / 機器要能學習的三要素 / 學習架構&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Sun, 26 Jun 2016 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2016-06-26:/ml-course-foundations_2.html</guid><category>機器學習基石</category></item><item><title>機器學習基石 學習筆記 (1)：何時可以使用機器學習?</title><link>https://www.ycc.idv.tw/ml-course-foundations_1.html</link><description>&lt;p&gt;什麼是Machine Learning / ML的使用時機 / 二元分類問題 / 多元學習&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">YC Chen</dc:creator><pubDate>Mon, 06 Jun 2016 12:00:00 +0800</pubDate><guid isPermaLink="false">tag:www.ycc.idv.tw,2016-06-06:/ml-course-foundations_1.html</guid><category>機器學習基石</category></item></channel></rss>