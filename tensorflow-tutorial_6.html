<!DOCTYPE html>
<html lang="zh">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="如果我們想要處理的問題是具有時序性的，該怎麼辦呢？本章將會介紹有時序性的Neurel Network。 本單元程式碼LSTM部分可於Github下載。 概論RNN 當我們想使得Neurel Network具有時序性，我們的Neurel ...">
        <meta name="keywords" content="Tensorflow">
        <link rel="icon" href="https://www.ycc.idv.tw/static/img/favicon.png">

        <title>實作Tensorflow (6)：Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) - YC Note</title>

        <!-- Stylesheets -->
        <link href="https://www.ycc.idv.tw/theme/css/all.min.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script type="text/x-mathjax-config"> 
            MathJax.Hub.Config({ 
                "HTML-CSS": { scale: 90, linebreaks: { automatic: true } }, 
                SVG: { linebreaks: { automatic:true } } 
                });
        </script>


        <!-- Google Analytics -->
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-68393177-2', 'auto');
          ga('send', 'pageview');
        </script>
        <!-- /Google Analytics -->


    </head>

    <body>

        <!-- Header -->
    <div class="header-container" style="background: linear-gradient(rgba(0, 0, 0, 0.2), rgba(0, 0, 0, 0.2)), url('https://www.ycc.idv.tw/images/tensorflow-logo.jpg'); background-position: center; background-size: cover;">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                        <a class="pull-left" href="https://www.ycc.idv.tw/"><img class="logo" src="https://www.ycc.idv.tw/static/img/favicon.png" alt="logo">YC Note</a>
                    </div>
                    <div class="nav pull-right">
                                <a href="https://www.ycc.idv.tw/category/coding.html">Coding</a>
                                <a href="https://www.ycc.idv.tw/category/aiml.html">AI.ML</a>
                                <a href="https://www.ycc.idv.tw/category/reading.html">Reading</a>
                                <a href="https://www.ycc.idv.tw/category/recording.html">Recording</a>
                                <a href="https://www.ycc.idv.tw/about-me.html">About Me</a>
                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title">實作Tensorflow (6)：Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM)</h1>
                      <p class="header-date">By <a href="https://www.ycc.idv.tw/author/yc-chen.html">YC Chen</a>, 2017 / 11月 25, in category <a href="https://www.ycc.idv.tw/category/aiml.html">AI.ML</a></p>
                      <div class="header-underline"></div>
                      <div class="clearfix"></div>
                      <p class="pull-right header-tags">
                          <span class="glyphicon glyphicon-tags mr5" aria-hidden="true"></span>
<a href="https://www.ycc.idv.tw/tag/tensorflow.html">Tensorflow</a>                      </p>
                  </div>
              </div>
        </div>
    </div>
    <!-- /Header -->
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    <div class="container content">
        <p>如果我們想要處理的問題是具有時序性的，該怎麼辦呢？本章將會介紹有時序性的Neurel Network。</p>
<p>本單元程式碼LSTM部分可於<a href="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/06_LSTM.py">Github</a>下載。</p>
<h3>概論RNN</h3>
<p>當我們想使得Neurel Network具有時序性，我們的Neurel Network就必須有記憶的功能，然後在我不斷的輸入新資訊時，也能同時保有歷史資訊的影響，最簡單的作法就是將Output的結果保留，等到新資訊進來時，將新的資訊和舊的Output一起考量來訓練Neurel Network。</p>
<p><img alt="unrolling" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.010.jpeg"></p>
<p>這種將舊有資訊保留的Neurel Network統稱為Recurrent Neural Networks (RNN)，這種不斷回饋的網路可以攤開來處理，如上圖，如果我有5筆數據，拿訓練一個RNN 5個回合並做了5次更新，其實就等效於攤開來一次處理5筆數據並做1次更新，這樣的手法叫做Unrolling，我們實作上會使用Unrolling的手法來增加計算效率。</p>
<p><img alt="RNN" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.011.jpeg"></p>
<p>接下來來看RNN內部怎麼實現的，上圖是最簡單的RNN形式，我們將上一回產生的Output和這一回的Input一起評估出這一回的Output，詳細式子如下：</p>
<div class="math">$$
o_{new}=tanh(i \times W_i + o \times W_o + B)
$$</div>
<p>
如此一來RNN就具有時序性了，舊的歷史資料將可以被「記憶」起來，你可以把RNN的「記憶」看成是「短期記憶」，因為它只會記得上一回的Output而已。</p>
<h3>梯度消失與梯度爆炸</h3>
<p>但這種形式的RNN在實作上會遇到很大的問題，還記得第二章當中，我們有講過像是tanh這類有飽和區的函數，會造成梯度消失的問題，而我們如果使用Unrolling的觀點來看RNN，將會發現這是一個超級深的網路，Backpapagation必須一路通到t0的RNN，想當然爾，有些梯度將會消失，部分權重就更新不到了，那有一些聰明的讀者一定會想到，那就使用Relu就好啦！不過其實還有一個重要的因素造成梯度消失，同時也造成梯度爆炸。</p>
<p>注意喔！雖然我們使用Unrolling的觀點，把網路看成是一個Deep網路的連接，但是和之前DNN不同之處，這些RNN彼此間是共享同一組權重的，這會造成梯度消失和梯度爆炸兩個問題，在RNN的結構裡頭，一個權重會隨著時間不斷的加強影響一個單一特徵，因為不同時間之下的RNN Cell共用同一個權重，這麼一來若是權重大於1，影響將會隨時間放大到梯度爆炸，若是權重小於1，影響將會隨時間縮小到梯度消失，就像是蝴蝶效應一般，微小的差異因為回饋的機制，而不合理的放大或是消失，因此RNN的Error Surface將會崎嶇不平，這會造成我們無法穩定的找到最佳解，難以收斂。這才是RNN難以使用的重要原因，把Activation Function換成Relu不會解決問題，文獻上反而告訴我們會變更差。</p>
<p>解決梯度爆炸有一個聽起來很廢但廣為人們使用的方法，叫做Gradient Clipping，也就是只要在更新過程梯度超過一個值，我就切掉讓梯度維持在這個上限，這樣就不會爆炸啦，待會會講到的LSTM只能夠解決梯度消失問題，但不能解決梯度爆炸問題，因此我們還是需要Gradient Clipping方法的幫忙。</p>
<p>在Tensorflow怎麼做到Gradient Clipping呢？作法是這樣的，以往我們使用<code>optimizer.minimize(loss)</code>來進行更新，事實上我們可以把這一步驟拆成兩部分，第一部分計算所有參數的梯度，第二部分使用這些梯度進行更新。因此我們可以從中作梗，把gradients偷天換日一番，一開始使用<code>optimizer.compute_gradients(loss)</code>來計算出個別的梯度，然後使用<code>tf.clip_by_global_norm(gradients, clip_norm)</code>來切梯度，最後再使用<code>optimizer.apply_gradients</code>把新的梯度餵入進行更新。</p>
<h3>Long Short-Term Memory (LSTM)</h3>
<p>LSTM是現今RNN的主流，它可以解決梯度消失的問題，我們先來看看結構，先預告一下，LSTM是迄今為止這系列課程當中看過最複雜的Neurel Network。</p>
<p><img alt="LSTM" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.012.jpeg"></p>
<p>最一開始和RNN一樣，Input會和上一回的Output一起評估一個「短期記憶」，</p>
<div class="math">$$
f_m = tanh (i \times W_{mi} + o \times W_{mo} + B_m)
$$</div>
<p>
但接下來不同於RNN直接輸出，LSTM做了一個類似於轉換成「長期記憶」的機制，「長期記憶」在這裡稱為State，State的狀態由三道門所控制，Input Gate負責控管哪些「短期記憶」可以進到「長期記憶」，Forget Gate負責調配哪一些「長期記憶」需要被遺忘，Output Gate則負責去決定需要從「長期記憶」中輸出怎樣的內容，先不要管這些Gate怎麼來，我們可以把這樣的記憶機制寫成以下的式子，假設State為<span class="math">\(f_{state}\)</span>、Input Gate為<span class="math">\(G_i\)</span>、Forget Gate為<span class="math">\(G_f\)</span>和Output Gate為<span class="math">\(G_o\)</span>。
</p>
<div class="math">$$
f_{state,new} = G_i \times f_m + G_f \times f_{state}
$$</div>
<div class="math">$$
o_{new} = G_o \times tanh(f_{state,new})
$$</div>
<p>如果我們要使得上面中Gates的部分具有開關的功能的話，我們會希望Gates可以是0到1的值，0代表全關，1代表全開，sigmoid正可以幫我們做到這件事，那哪些因素會決定Gates的關閉與否呢？不妨考慮所有可能的因素，也就是所有輸入這個Cell的資訊都考慮進去，但上一回的State必須被剔除於外，因為上一回的State來決定下一個State的操作是不合理的，因此我們就可以寫下所有Gates的表示式了。
</p>
<div class="math">$$
G_i = Sigmoid (i \times W_{ii} + o \times W_{io} + B_i)
$$</div>
<div class="math">$$
G_f = Sigmoid (i \times W_{fi} + o \times W_{fo} + B_f)
$$</div>
<div class="math">$$
G_o = Sigmoid(i \times W_{oi} + o \times W_{oo} + B_o)
$$</div>
<p>這就是LSTM，「長期記憶」的出現可以解決掉梯度消失的問題，RNN只有「短期記憶」，所以一旦認為一個特徵不重要，經過幾回連乘，這個特徵的梯度就會消失殆盡，但是LSTM保留State，並且使用「加」的方法更新State，所以有一些重要的State得以留下來持續影響著Output，解決了梯度消失的問題。但是，不幸的LSTM還是免不了梯度爆炸，為什麼呢？如果一個特徵真的很重要，State會記住，Input也會強調，所以幾輪下來還是有可能出現爆炸的情況，這時候我們就需要Gradient Clipping的幫忙。</p>
<h3>使用LSTM實作文章產生器</h3>
<p>接下來我們來實作LSTM，目標是做一個文章產生器，我們希望機器可以不斷的根據前文猜測下一個「字母」(Letters)應該要下什麼，如此一來我只要給個開頭字母，LSTM就可以幫我腦補成一篇文章。</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves.urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>


<div class="highlight"><pre><span class="n">LETTER_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="c"># [a-z] + &#39; &#39;</span>
<span class="n">FIRST_LETTER_ASCII</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">maybe_download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">filename</span><span class="p">,</span> <span class="n">expected_bytes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Download a file if not present, and make sure it&#39;s the right size.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="n">filename</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="n">statinfo</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">stat</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span> <span class="o">==</span> <span class="n">expected_bytes</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;Found and verified </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
          <span class="s">&#39;Failed to verify &#39;</span> <span class="o">+</span> <span class="n">filename</span> <span class="o">+</span> <span class="s">&#39;. Can you get to it with a browser?&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">filename</span>

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">namelist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">as_str</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">char2id</span><span class="p">(</span><span class="n">char</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="o">-</span> <span class="n">FIRST_LETTER_ASCII</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">char</span> <span class="o">==</span> <span class="s">&#39; &#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;Unexpected character: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">char</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">id2char</span><span class="p">(</span><span class="n">dictid</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">dictid</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">chr</span><span class="p">(</span><span class="n">dictid</span> <span class="o">+</span> <span class="n">FIRST_LETTER_ASCII</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">&#39; &#39;</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;Downloading text8.zip&quot;</span><span class="p">)</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">maybe_download</span><span class="p">(</span><span class="s">&#39;http://mattmahoney.net/dc/text8.zip&#39;</span><span class="p">,</span><span class="s">&#39;./text8.zip&#39;</span><span class="p">,</span> <span class="mi">31344016</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;=====&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Data size </span><span class="si">%d</span><span class="s"> letters&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;=====&quot;</span><span class="p">)</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">valid_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="n">valid_size</span><span class="p">]</span>
<span class="n">train_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">valid_size</span><span class="p">:]</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Train Dataset: size:&#39;</span><span class="p">,</span><span class="n">train_size</span><span class="p">,</span><span class="s">&#39;letters,</span><span class="se">\n</span><span class="s">  first 64:&#39;</span><span class="p">,</span><span class="n">train_text</span><span class="p">[:</span><span class="mi">64</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Validation Dataset: size:&#39;</span><span class="p">,</span><span class="n">valid_size</span><span class="p">,</span><span class="s">&#39;letters,</span><span class="se">\n</span><span class="s">  first 64:&#39;</span><span class="p">,</span><span class="n">valid_text</span><span class="p">[:</span><span class="mi">64</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span class="n">Downloading</span> <span class="n">text8</span><span class="p">.</span><span class="n">zip</span>
<span class="n">Found</span> <span class="n">and</span> <span class="n">verified</span> <span class="p">.</span><span class="o">/</span><span class="n">text8</span><span class="p">.</span><span class="n">zip</span>
<span class="o">=====</span>
<span class="n">Data</span> <span class="n">size</span> <span class="mi">100000000</span> <span class="n">letters</span>
<span class="o">=====</span>
<span class="n">Train</span> <span class="n">Dataset</span><span class="o">:</span> <span class="n">size</span><span class="o">:</span> <span class="mi">99999000</span> <span class="n">letters</span><span class="p">,</span>
  <span class="n">first</span> <span class="mi">64</span><span class="o">:</span> <span class="n">ons</span> <span class="n">anarchists</span> <span class="n">advocate</span> <span class="n">social</span> <span class="n">relations</span> <span class="n">based</span> <span class="n">upon</span> <span class="n">voluntary</span> <span class="n">as</span>
<span class="n">Validation</span> <span class="n">Dataset</span><span class="o">:</span> <span class="n">size</span><span class="o">:</span> <span class="mi">1000</span> <span class="n">letters</span><span class="p">,</span>
  <span class="n">first</span> <span class="mi">64</span><span class="o">:</span>  <span class="n">anarchism</span> <span class="n">originated</span> <span class="n">as</span> <span class="n">a</span> <span class="n">term</span> <span class="n">of</span> <span class="n">abuse</span> <span class="n">first</span> <span class="n">used</span> <span class="n">against</span> <span class="n">earl</span>
</pre></div>


<p>上面操作我們建制完成了字母庫，接下來就可以產生我們訓練所需要的Batch Data，所以我們來看看究竟要產生怎樣格式的資料。</p>
<p><img alt="LSTM Implement" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.013.jpeg"></p>
<p>如上圖所示，有點小複雜，假設我要設計一個LSTM Model，它的Unrolling Number為3，Batch Size為2，然後遇到的字串是"abcde fghij klmno pqrst"，接下來就開始產生每個Round要用的Data，產生的結果如上圖所示，你會發現產生的Data第0軸表示的是考慮unrolling需要取樣的資料，總共應該會有(Unrolling Number+1)筆，如上圖例，共有4筆，3筆當作輸入而3筆當作Labels，中間有2筆重疊使用，另外還有一點，我們會保留最後一筆Data當作下一個回合的第一筆，這是為了不浪費使用每一個字母前後的組合。而第1軸則是餵入單一LSTM需要的資料，我們一次可以餵多組不相干的字母進去，如上圖例，Batch Size=2所以餵2個字母進去，那這些不相干的字母在取樣的時候，我們會盡量讓它平均分配在文字庫，才能確保彼此之間不相干，以增加LSTM的訓練效率和效果。</p>
<p>因此，先產生Batch Data吧！</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">characters</span><span class="p">(</span><span class="n">probabilities</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Turn a 1-hot encoding or a probability distribution over the possible</span>
<span class="sd">    characters back into its (most likely) character representation.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">id2char</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">batches2string</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert a sequence of batches back into their (most likely) string</span>
<span class="sd">    representation.&quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">characters</span><span class="p">(</span><span class="n">b</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">rnn_batch_generator</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_unrollings</span><span class="p">):</span>
    <span class="n">text_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c">### initialization</span>
    <span class="n">segment</span> <span class="o">=</span> <span class="n">text_size</span> <span class="o">//</span> <span class="n">batch_size</span>
    <span class="n">cursors</span> <span class="o">=</span> <span class="p">[</span> <span class="n">offset</span> <span class="o">*</span> <span class="n">segment</span> <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batch_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">cursor</span> <span class="o">=</span> <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">id_</span> <span class="o">=</span> <span class="n">char2id</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">cursor</span><span class="p">])</span>
        <span class="n">batch_initial</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">id_</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="c">#move cursor</span>
        <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">text_size</span>

    <span class="n">batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_initial</span><span class="p">)</span> 

    <span class="c">### generate loop</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="p">[</span> <span class="n">batches</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_unrollings</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">cursor</span> <span class="o">=</span> <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">id_</span> <span class="o">=</span> <span class="n">char2id</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">cursor</span><span class="p">])</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">id_</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

                <span class="c">#move cursor</span>
                <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">text_size</span>
            <span class="n">batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="k">yield</span> <span class="n">batches</span>  <span class="c"># [last batch of previous batches] + [unrollings]</span>


<span class="c"># demonstrate generator</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span>
<span class="n">num_unrollings</span><span class="o">=</span><span class="mi">10</span>

<span class="n">train_batches</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">train_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_unrollings</span><span class="p">)</span>
<span class="n">valid_batches</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">valid_text</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;*** train_batches:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">train_batches</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">train_batches</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;*** valid_batches:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">valid_batches</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">valid_batches</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span class="o">***</span> <span class="n">train_batches</span><span class="o">:</span>
<span class="p">[</span><span class="err">&#39;</span><span class="n">ons</span> <span class="n">anarchi</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">when</span> <span class="n">milita</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">lleria</span> <span class="n">arch</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">abbeys</span> <span class="n">and</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">married</span> <span class="n">urr</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">hel</span> <span class="n">and</span> <span class="n">ric</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">y</span> <span class="n">and</span> <span class="n">litur</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ay</span> <span class="n">opened</span> <span class="n">f</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">tion</span> <span class="n">from</span> <span class="n">t</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">migration</span> <span class="n">t</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">new</span> <span class="n">york</span> <span class="n">ot</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">he</span> <span class="n">boeing</span> <span class="n">s</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">e</span> <span class="n">listed</span> <span class="n">wi</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">eber</span> <span class="n">has</span> <span class="n">pr</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">o</span> <span class="n">be</span> <span class="n">made</span> <span class="n">t</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">yer</span> <span class="n">who</span> <span class="n">rec</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ore</span> <span class="n">signifi</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">a</span> <span class="n">fierce</span> <span class="n">cr</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">two</span> <span class="n">six</span> <span class="n">ei</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">aristotle</span> <span class="n">s</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ity</span> <span class="n">can</span> <span class="n">be</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">and</span> <span class="n">intrac</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">tion</span> <span class="n">of</span> <span class="n">the</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">dy</span> <span class="n">to</span> <span class="n">pass</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">f</span> <span class="n">certain</span> <span class="n">d</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">at</span> <span class="n">it</span> <span class="n">will</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">e</span> <span class="n">convince</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ent</span> <span class="n">told</span> <span class="n">hi</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ampaign</span> <span class="n">and</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">rver</span> <span class="n">side</span> <span class="n">s</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ious</span> <span class="n">texts</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">o</span> <span class="n">capitaliz</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">a</span> <span class="n">duplicate</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">gh</span> <span class="n">ann</span> <span class="n">es</span> <span class="n">d</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ine</span> <span class="n">january</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ross</span> <span class="n">zero</span> <span class="n">t</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">cal</span> <span class="n">theorie</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ast</span> <span class="n">instanc</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">dimensiona</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">most</span> <span class="n">holy</span> <span class="n">m</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">t</span> <span class="n">s</span> <span class="n">support</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">u</span> <span class="n">is</span> <span class="n">still</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">e</span> <span class="n">oscillati</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">o</span> <span class="n">eight</span> <span class="n">sub</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">of</span> <span class="n">italy</span> <span class="n">la</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">s</span> <span class="n">the</span> <span class="n">tower</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">klahoma</span> <span class="n">pre</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">erprise</span> <span class="n">lin</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ws</span> <span class="n">becomes</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">et</span> <span class="n">in</span> <span class="n">a</span> <span class="n">naz</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">the</span> <span class="n">fabian</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">etchy</span> <span class="n">to</span> <span class="n">re</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">sharman</span> <span class="n">ne</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ised</span> <span class="n">empero</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ting</span> <span class="n">in</span> <span class="n">pol</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">d</span> <span class="n">neo</span> <span class="n">latin</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">th</span> <span class="n">risky</span> <span class="n">ri</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">encyclopedi</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">fense</span> <span class="n">the</span> <span class="n">a</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">duating</span> <span class="n">fro</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">treet</span> <span class="n">grid</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ations</span> <span class="n">more</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">appeal</span> <span class="n">of</span> <span class="n">d</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">si</span> <span class="n">have</span> <span class="n">mad</span><span class="err">&#39;</span><span class="p">]</span>
<span class="p">[</span><span class="err">&#39;</span><span class="n">ists</span> <span class="n">advoca</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ary</span> <span class="n">governm</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">hes</span> <span class="n">nationa</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">d</span> <span class="n">monasteri</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">raca</span> <span class="n">prince</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">chard</span> <span class="n">baer</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">rgical</span> <span class="n">lang</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="k">for</span> <span class="n">passeng</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">the</span> <span class="n">nationa</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">took</span> <span class="n">place</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ther</span> <span class="n">well</span> <span class="n">k</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">seven</span> <span class="n">six</span> <span class="n">s</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ith</span> <span class="n">a</span> <span class="n">gloss</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">robably</span> <span class="n">bee</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">to</span> <span class="n">recogniz</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ceived</span> <span class="n">the</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">icant</span> <span class="n">than</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ritic</span> <span class="n">of</span> <span class="n">th</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ight</span> <span class="n">in</span> <span class="n">sig</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">s</span> <span class="n">uncaused</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">lost</span> <span class="n">as</span> <span class="n">in</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">cellular</span> <span class="n">ic</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">e</span> <span class="n">size</span> <span class="n">of</span> <span class="n">t</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">him</span> <span class="n">a</span> <span class="n">stic</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">drugs</span> <span class="n">confu</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">take</span> <span class="n">to</span> <span class="n">co</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">the</span> <span class="n">priest</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">im</span> <span class="n">to</span> <span class="n">name</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">d</span> <span class="n">barred</span> <span class="n">at</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">standard</span> <span class="n">fo</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">such</span> <span class="n">as</span> <span class="n">es</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ze</span> <span class="n">on</span> <span class="n">the</span> <span class="n">g</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">e</span> <span class="n">of</span> <span class="n">the</span> <span class="n">or</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">d</span> <span class="n">hiver</span> <span class="n">one</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">y</span> <span class="n">eight</span> <span class="n">mar</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">the</span> <span class="n">lead</span> <span class="n">ch</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">es</span> <span class="n">classica</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ce</span> <span class="n">the</span> <span class="n">non</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">al</span> <span class="n">analysis</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">mormons</span> <span class="n">bel</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">t</span> <span class="n">or</span> <span class="n">at</span> <span class="n">lea</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">disagreed</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ing</span> <span class="n">system</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">btypes</span> <span class="n">base</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">anguages</span> <span class="n">th</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">r</span> <span class="n">commissio</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ess</span> <span class="n">one</span> <span class="n">nin</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">nux</span> <span class="n">suse</span> <span class="n">li</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">the</span> <span class="n">first</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">zi</span> <span class="n">concentr</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">society</span> <span class="n">ne</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">elatively</span> <span class="n">s</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">etworks</span> <span class="n">sha</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">or</span> <span class="n">hirohito</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">litical</span> <span class="n">ini</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">n</span> <span class="n">most</span> <span class="n">of</span> <span class="n">t</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">iskerdoo</span> <span class="n">ri</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">ic</span> <span class="n">overview</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">air</span> <span class="n">compone</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">om</span> <span class="n">acnm</span> <span class="n">acc</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span> <span class="n">centerline</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">e</span> <span class="n">than</span> <span class="n">any</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">devotional</span> <span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">de</span> <span class="n">such</span> <span class="n">dev</span><span class="err">&#39;</span><span class="p">]</span>
<span class="o">***</span> <span class="n">valid_batches</span><span class="o">:</span>
<span class="p">[</span><span class="err">&#39;</span> <span class="n">a</span><span class="err">&#39;</span><span class="p">]</span>
<span class="p">[</span><span class="err">&#39;</span><span class="n">an</span><span class="err">&#39;</span><span class="p">]</span>
</pre></div>


<p>定義一下待會會用到的函數。</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">sample_distribution</span><span class="p">(</span><span class="n">distribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample one element from a distribution assumed to be an array of normalized</span>
<span class="sd">    probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">distribution</span><span class="p">)):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">distribution</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">s</span> <span class="o">&gt;=</span> <span class="n">r</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">i</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">distribution</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">prediction</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Turn a (column) prediction into 1-hot encoded samples.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">sample_distribution</span><span class="p">(</span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">p</span>

<span class="k">def</span> <span class="nf">logprob</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Log-probability of the true labels in a predicted batch.&quot;&quot;&quot;</span>
    <span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-10</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">predictions</span><span class="p">)))</span> <span class="o">/</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>


<p>開始建制LSTM Model。</p>
<div class="highlight"><pre><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_unrollings</span><span class="p">,</span><span class="n">n_memory</span><span class="p">,</span><span class="n">n_train_batch</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span> <span class="o">=</span> <span class="n">n_unrollings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span> <span class="o">=</span> <span class="n">n_memory</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saved</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c"># initialize new grap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">n_train_batch</span><span class="p">)</span> <span class="c"># building graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="c"># create session by the graph </span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">n_train_batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="c">### Input      </span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_train_batch</span><span class="p">,</span><span class="n">LETTER_SIZE</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c"># labels are inputs shifted by one time step.</span>


            <span class="c">### Optimalization</span>
            <span class="c"># build neurel network structure and get their loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span> <span class="n">inputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">,</span>
                                                 <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">,</span>
                                                 <span class="n">n_batch</span><span class="o">=</span><span class="n">n_train_batch</span><span class="p">,</span>
                                               <span class="p">)</span>

            <span class="c"># define training operation</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdagradOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

            <span class="c"># gradient clipping</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">))</span> <span class="c"># output gradients one by one</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_global_norm</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">)</span> <span class="c"># clip gradient</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span> <span class="c"># apply clipped gradients</span>


            <span class="c">### Sampling and validation eval: batch 1, no unrolling.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">])</span>

            <span class="n">saved_sample_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]))</span>
            <span class="n">saved_sample_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_sample_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span>     <span class="c"># reset sample state operator</span>
                <span class="n">saved_sample_output</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
                <span class="n">saved_sample_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])))</span>

            <span class="n">sample_output</span><span class="p">,</span> <span class="n">sample_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_cell</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">,</span> <span class="n">saved_sample_output</span><span class="p">,</span> <span class="n">saved_sample_state</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">saved_sample_output</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">sample_output</span><span class="p">),</span>
                                          <span class="n">saved_sample_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">sample_state</span><span class="p">)]):</span>
                <span class="c"># use tf.control_dependencies to make sure &quot;saving&quot; before &quot;prediction&quot;</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">sample_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">sample_output</span><span class="p">,</span> 
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;classifier&#39;</span><span class="p">],</span> 
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s">&#39;classifier&#39;</span><span class="p">]))</span>

            <span class="c">### Initialization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  

    <span class="k">def</span> <span class="nf">lstm_cell</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">o</span><span class="p">,</span><span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf</span>
<span class="sd">        Note that in this formulation, we omit the various connections between the</span>
<span class="sd">        previous state and the gates.&quot;&quot;&quot;</span>
        <span class="c">## Build Input Gate</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;input_gate_i&#39;</span><span class="p">]</span>
        <span class="n">im</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;input_gate_o&#39;</span><span class="p">]</span>
        <span class="n">ib</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s">&#39;input_gate&#39;</span><span class="p">]</span>
        <span class="n">input_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ix</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">im</span><span class="p">)</span> <span class="o">+</span> <span class="n">ib</span><span class="p">)</span>
        <span class="c">## Build Forget Gate</span>
        <span class="n">fx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;forget_gate_i&#39;</span><span class="p">]</span>
        <span class="n">fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;forget_gate_o&#39;</span><span class="p">]</span>
        <span class="n">fb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s">&#39;forget_gate&#39;</span><span class="p">]</span>        
        <span class="n">forget_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">fx</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">fm</span><span class="p">)</span> <span class="o">+</span> <span class="n">fb</span><span class="p">)</span>
        <span class="c">## Memory</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;memory_i&#39;</span><span class="p">]</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;memory_o&#39;</span><span class="p">]</span>
        <span class="n">cb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s">&#39;memory&#39;</span><span class="p">]</span>
        <span class="n">update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cx</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">cm</span><span class="p">)</span> <span class="o">+</span> <span class="n">cb</span>
        <span class="c">## Update State</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">forget_gate</span> <span class="o">*</span> <span class="n">state</span> <span class="o">+</span> <span class="n">input_gate</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>
        <span class="c">## Build Output Gate        </span>
        <span class="n">ox</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;output_gate_i&#39;</span><span class="p">]</span>
        <span class="n">om</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;output_gate_o&#39;</span><span class="p">]</span>
        <span class="n">ob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s">&#39;output_gate&#39;</span><span class="p">]</span>
        <span class="n">output_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ox</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">om</span><span class="p">)</span> <span class="o">+</span> <span class="n">ob</span><span class="p">)</span>
        <span class="c">## Ouput</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output_gate</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">structure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">inputs</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">n_batch</span><span class="p">):</span>
        <span class="c">### Variable</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
              <span class="s">&#39;input_gate_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;input_gate_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;forget_gate_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;forget_gate_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;output_gate_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;output_gate_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;memory_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;memory_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s">&#39;classifier&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>

            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
              <span class="s">&#39;input_gate&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s">&#39;forget_gate&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s">&#39;output_gate&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s">&#39;memory&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s">&#39;classifier&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">])),</span>
            <span class="p">}</span>

        <span class="c"># Variables saving state across unrollings.</span>
        <span class="n">saved_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">saved_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="c">### Structure</span>
        <span class="c"># Unrolled LSTM loop.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">saved_output</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">saved_state</span>
        <span class="k">for</span> <span class="n">input_</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_cell</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="c"># State saving across unrollings.</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">saved_output</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">output</span><span class="p">),</span>
                                      <span class="n">saved_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">state</span><span class="p">)]):</span>
            <span class="c"># use tf.control_dependencies to make sure &quot;saving&quot; before &quot;calculating loss&quot;</span>

            <span class="c"># Classifier</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> 
                                     <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s">&#39;classifier&#39;</span><span class="p">],</span> 
                                     <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s">&#39;classifier&#39;</span><span class="p">])</span>
            <span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
                        <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">y_</span><span class="p">,</span> <span class="n">loss</span>


    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">online_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>      
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>    
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">perplexity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">sum_logprob</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">sample_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_sample_state</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample_size</span><span class="p">):</span>
                <span class="n">sample_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">],</span><span class="n">newshape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">sample_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">],</span><span class="n">newshape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_prediction</span><span class="p">,</span>
                                            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">:</span> <span class="n">sample_input</span><span class="p">})</span>
                <span class="n">sum_logprob</span> <span class="o">+=</span> <span class="n">logprob</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">sample_label</span><span class="p">)</span>
        <span class="n">perplexity</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sum_logprob</span> <span class="o">/</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="n">sample_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">perplexity</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">len_generate</span><span class="p">):</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">id2char</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">==</span><span class="n">c</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">LETTER_SIZE</span><span class="p">)]])</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">characters</span><span class="p">(</span><span class="n">feed</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_sample_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_generate</span><span class="p">):</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_prediction</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">:</span> <span class="n">feed</span><span class="p">})</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
            <span class="n">sentence</span> <span class="o">+=</span> <span class="n">characters</span><span class="p">(</span><span class="n">feed</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sentence</span>
</pre></div>


<div class="highlight"><pre><span class="c"># build training batch generator</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">train_text</span><span class="p">,</span>
                                      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                      <span class="n">num_unrollings</span><span class="o">=</span><span class="n">num_unrollings</span><span class="p">)</span>

<span class="c"># build validation data</span>
<span class="n">valid_batches</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">valid_text</span><span class="p">,</span> 
                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                    <span class="n">num_unrollings</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">valid_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">valid_batches</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_size</span><span class="p">)]</span>

<span class="c"># build LSTM model</span>
<span class="n">model_LSTM</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">n_unrollings</span><span class="o">=</span><span class="n">num_unrollings</span><span class="p">,</span>
                  <span class="n">n_memory</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                  <span class="n">n_train_batch</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="c"># initial model</span>
<span class="n">model_LSTM</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

<span class="c"># online training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">num_batchs_in_epoch</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">valid_freq</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batchs_in_epoch</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model_LSTM</span><span class="o">.</span><span class="n">online_fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span>

    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="n">num_batchs_in_epoch</span>

    <span class="n">train_perplexity</span> <span class="o">=</span> <span class="n">model_LSTM</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Epoch </span><span class="si">%d</span><span class="s">/</span><span class="si">%d</span><span class="s">: </span><span class="si">%d</span><span class="s">s loss = </span><span class="si">%6.4f</span><span class="s">, perplexity = </span><span class="si">%6.4f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span>
                                                   <span class="n">avg_loss</span><span class="p">,</span> <span class="n">train_perplexity</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">valid_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;=============== Validation ===============&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;validation perplexity = </span><span class="si">%6.4f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;Generate From &#39;a&#39;:  &quot;</span><span class="p">,</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;Generate From &#39;h&#39;:  &quot;</span><span class="p">,</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s">&#39;h&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;Generate From &#39;m&#39;:  &quot;</span><span class="p">,</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s">&#39;m&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;==========================================&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">96</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.8350</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.0744</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">93</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.5473</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.9950</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">96</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.4832</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.7988</span>
<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">95</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.4460</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.5873</span>
<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">93</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.4268</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.0196</span>

<span class="o">===============</span> <span class="n">Validation</span> <span class="o">===============</span>
<span class="n">validation</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">3.7728</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;a&#39;</span><span class="o">:</span>   <span class="n">a</span> <span class="n">addressed</span> <span class="n">trojp</span> <span class="n">herregore</span> <span class="n">efforts</span> <span class="n">taxothers</span> <span class="n">of</span> <span class="n">fi</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;h&#39;</span><span class="o">:</span>   <span class="n">h</span> <span class="n">a</span> <span class="n">one</span> <span class="n">nine</span> <span class="n">one</span> <span class="n">s</span> <span class="n">personalt</span> <span class="n">god</span> <span class="n">tranant</span> <span class="n">of</span> <span class="n">genuali</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;m&#39;</span><span class="o">:</span>   <span class="n">m</span> <span class="n">with</span> <span class="n">the</span> <span class="n">of</span> <span class="n">retrintuutar</span> <span class="n">one</span> <span class="n">five</span> <span class="n">zero</span> <span class="n">and</span> <span class="n">even</span> <span class="n">t</span>
<span class="o">==========================================</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.4116</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.8374</span>
<span class="n">Epoch</span> <span class="mi">7</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3958</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.7529</span>
<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">91</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3911</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.8161</span>
<span class="n">Epoch</span> <span class="mi">9</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3670</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.6386</span>
<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3871</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.5209</span>

<span class="o">===============</span> <span class="n">Validation</span> <span class="o">===============</span>
<span class="n">validation</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">3.6448</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;a&#39;</span><span class="o">:</span>   <span class="n">as</span> <span class="n">mark</span> <span class="n">but</span> <span class="n">use</span> <span class="n">the</span> <span class="n">church</span> <span class="n">management</span> <span class="n">seniorie</span> <span class="n">othe</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;h&#39;</span><span class="o">:</span>   <span class="n">h</span> <span class="n">mathum</span> <span class="n">it</span> <span class="n">layor</span> <span class="n">j</span> <span class="n">cape</span> <span class="n">not</span> <span class="n">pac</span> <span class="n">feloghaokurg</span> <span class="n">the</span> <span class="n">a</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;m&#39;</span><span class="o">:</span>   <span class="n">ment</span> <span class="n">condition</span> <span class="n">christmishem</span> <span class="n">the</span> <span class="n">reasons</span> <span class="n">obaging</span> <span class="n">out</span>
<span class="o">==========================================</span>

<span class="n">Epoch</span> <span class="mi">11</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3772</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.4907</span>
<span class="n">Epoch</span> <span class="mi">12</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3782</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.1908</span>
<span class="n">Epoch</span> <span class="mi">13</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3713</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.7394</span>
<span class="n">Epoch</span> <span class="mi">14</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3722</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.5244</span>
<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3665</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.5655</span>

<span class="o">===============</span> <span class="n">Validation</span> <span class="o">===============</span>
<span class="n">validation</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">3.6228</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;a&#39;</span><span class="o">:</span>   <span class="n">ans</span> <span class="n">in</span> <span class="n">the</span> <span class="n">first</span> <span class="n">glds</span> <span class="k">for</span> <span class="n">exclusively</span> <span class="n">assistance</span> <span class="n">es</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;h&#39;</span><span class="o">:</span>   <span class="n">h</span> <span class="n">south</span> <span class="n">and</span> <span class="n">the</span> <span class="n">w</span> <span class="n">cops</span> <span class="n">and</span> <span class="n">goat</span> <span class="n">right</span> <span class="n">as</span> <span class="n">known</span> <span class="n">the</span> 
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;m&#39;</span><span class="o">:</span>   <span class="n">m</span> <span class="n">charges</span> <span class="n">has</span> <span class="n">a</span> <span class="n">properties</span> <span class="n">keit</span> <span class="n">was</span> <span class="n">in</span> <span class="n">second</span> <span class="n">state</span>
<span class="o">==========================================</span>

<span class="n">Epoch</span> <span class="mi">16</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">362</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3627</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.3342</span>
<span class="n">Epoch</span> <span class="mi">17</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">95</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3674</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.2295</span>
<span class="n">Epoch</span> <span class="mi">18</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">93</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3513</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.6203</span>
<span class="n">Epoch</span> <span class="mi">19</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">94</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3637</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.9332</span>
<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">94</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3561</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.0590</span>

<span class="o">===============</span> <span class="n">Validation</span> <span class="o">===============</span>
<span class="n">validation</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">3.4923</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;a&#39;</span><span class="o">:</span>   <span class="n">a</span> <span class="n">the</span> <span class="n">problems</span> <span class="n">in</span> <span class="n">mind</span> <span class="n">types</span> <span class="n">in</span> <span class="n">one</span> <span class="n">strieging</span> <span class="n">call</span> 
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;h&#39;</span><span class="o">:</span>   <span class="n">huragre</span> <span class="n">ray</span> <span class="n">fundament</span> <span class="n">lost</span> <span class="n">knishera</span> <span class="n">claokhen</span> <span class="n">nalony</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;m&#39;</span><span class="o">:</span>   <span class="n">m</span> <span class="k">for</span> <span class="n">five</span> <span class="n">one</span> <span class="n">nine</span> <span class="n">four</span> <span class="n">zero</span> <span class="n">market</span> <span class="n">hell</span> <span class="n">one</span> <span class="n">nine</span> 
<span class="o">==========================================</span>

<span class="n">Epoch</span> <span class="mi">21</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">93</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3569</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.9601</span>
<span class="n">Epoch</span> <span class="mi">22</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">93</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3516</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.9727</span>
<span class="n">Epoch</span> <span class="mi">23</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3676</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.5722</span>
<span class="n">Epoch</span> <span class="mi">24</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">94</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3603</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.1140</span>
<span class="n">Epoch</span> <span class="mi">25</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">92</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3649</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.2638</span>

<span class="o">===============</span> <span class="n">Validation</span> <span class="o">===============</span>
<span class="n">validation</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">3.5306</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;a&#39;</span><span class="o">:</span>   <span class="n">an</span> <span class="n">experimenting</span> <span class="n">meaning</span> <span class="n">as</span> <span class="n">dosil</span> <span class="n">smold</span> <span class="n">seven</span> <span class="n">eight</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;h&#39;</span><span class="o">:</span>   <span class="n">h</span> <span class="n">one</span> <span class="n">nine</span> <span class="n">seven</span> <span class="n">biero</span> <span class="n">shimm</span> <span class="n">in</span> <span class="n">died</span> <span class="n">this</span> <span class="n">theorothy</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;m&#39;</span><span class="o">:</span>   <span class="n">m</span> <span class="n">to</span> <span class="n">threat</span> <span class="n">loss</span> <span class="n">away</span> <span class="n">a</span> <span class="n">roon</span> <span class="n">b</span> <span class="n">one</span> <span class="n">six</span> <span class="n">four</span> <span class="n">nine</span> <span class="n">fa</span>
<span class="o">==========================================</span>

<span class="n">Epoch</span> <span class="mi">26</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">95</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3533</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.1450</span>
<span class="n">Epoch</span> <span class="mi">27</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">75</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3568</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.3603</span>
<span class="n">Epoch</span> <span class="mi">28</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">93</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3719</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.4497</span>
<span class="n">Epoch</span> <span class="mi">29</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">96</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3620</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">6.1687</span>
<span class="n">Epoch</span> <span class="mi">30</span><span class="o">/</span><span class="mi">30</span><span class="o">:</span> <span class="mi">95</span><span class="n">s</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">1.3660</span><span class="p">,</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">5.9484</span>

<span class="o">===============</span> <span class="n">Validation</span> <span class="o">===============</span>
<span class="n">validation</span> <span class="n">perplexity</span> <span class="o">=</span> <span class="mf">3.4477</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;a&#39;</span><span class="o">:</span>   <span class="n">ates</span> <span class="n">in</span> <span class="n">weaved</span> <span class="n">to</span> <span class="n">has</span> <span class="n">be</span> <span class="n">five</span> <span class="n">six</span> <span class="n">zero</span> <span class="n">song</span> <span class="n">in</span> <span class="n">the</span> 
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;h&#39;</span><span class="o">:</span>   <span class="n">h</span> <span class="n">a</span> <span class="n">neil</span> <span class="n">and</span> <span class="n">would</span> <span class="n">lockspry</span> <span class="kt">short</span> <span class="n">there</span> <span class="n">is</span> <span class="n">attempte</span>
<span class="n">Generate</span> <span class="n">From</span> <span class="sc">&#39;m&#39;</span><span class="o">:</span>   <span class="n">man</span> <span class="n">one</span> <span class="n">nine</span> <span class="n">zero</span> <span class="n">eight</span> <span class="n">moming</span> <span class="n">between</span> <span class="n">language</span> <span class="n">yea</span>
<span class="o">==========================================</span>
</pre></div>


<p>最後來產生一篇以"t"為開頭的1000字文章吧！</p>
<div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s">&#39;t&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span class="n">tifician</span> <span class="n">linulation</span> <span class="n">fromsantinated</span> <span class="n">inscriptions</span> <span class="n">have</span> <span class="n">been</span> <span class="n">followne</span> <span class="n">members</span> <span class="n">of</span> <span class="n">gomewhokeno</span> <span class="n">science</span> <span class="n">and</span> <span class="n">direct</span> <span class="n">to</span> <span class="n">player</span> <span class="n">by</span> <span class="n">the</span> <span class="n">xh</span> <span class="n">music</span> <span class="n">the</span> <span class="n">work</span> <span class="n">mercing</span> <span class="n">a</span> <span class="n">completely</span> <span class="n">categories</span> <span class="n">following</span> <span class="n">were</span> <span class="n">now</span> <span class="n">shrries</span> <span class="n">the</span> <span class="n">graduate</span> <span class="n">painters</span> <span class="n">but</span> <span class="n">three</span> <span class="n">limil</span> <span class="n">bp</span> <span class="n">inversing</span> <span class="n">to</span> <span class="n">in</span> <span class="n">show</span> <span class="n">monasteria</span> <span class="n">ziver</span> <span class="n">buriale</span> <span class="n">hollesthea</span> <span class="n">or</span> <span class="n">universities</span> <span class="n">contains</span> <span class="n">one</span> <span class="n">nine</span> <span class="n">five</span> <span class="n">three</span> <span class="n">villes</span> <span class="n">on</span> <span class="n">in</span> <span class="n">wolf</span> <span class="n">from</span> <span class="n">home</span> <span class="n">with</span> <span class="n">alimon</span> <span class="n">del</span> <span class="n">wi</span> <span class="n">tallation</span> <span class="n">austry</span> <span class="n">five</span> <span class="n">he</span> <span class="n">is</span> <span class="n">generate</span> <span class="n">three</span> <span class="n">visitiral</span> <span class="n">spectring</span> <span class="n">greece</span> <span class="n">of</span> <span class="n">many</span> <span class="n">proper</span> <span class="n">six</span> <span class="n">one</span> <span class="n">would</span> <span class="n">frequently</span> <span class="n">to</span> <span class="n">be</span> <span class="n">along</span> <span class="n">two</span> <span class="n">zero</span> <span class="n">zero</span> <span class="n">one</span> <span class="n">aberrieds</span> <span class="n">him</span> <span class="n">hockel</span> <span class="n">alphaliatiss</span> <span class="n">r</span> <span class="n">kabif</span> <span class="n">figant</span> <span class="n">in</span> <span class="n">jock</span> <span class="n">final</span> <span class="n">click</span> <span class="n">hospite</span> <span class="n">michael</span> <span class="n">hetrion</span> <span class="n">as</span> <span class="n">the</span> <span class="n">equations</span> <span class="n">were</span> <span class="n">feature</span> <span class="n">to</span> <span class="n">notably</span> <span class="n">algebraic</span> <span class="n">important</span> <span class="n">but</span> <span class="n">better</span> <span class="n">can</span> <span class="n">requires</span> <span class="n">of</span> <span class="n">the</span> <span class="n">same</span> <span class="n">since</span> <span class="n">the</span> <span class="n">many</span> <span class="n">bag</span> <span class="n">among</span> <span class="n">the</span> <span class="n">mastic</span> <span class="n">five</span> <span class="n">official</span> <span class="n">with</span> <span class="n">the</span> <span class="n">homes</span> <span class="n">abertosiar</span> <span class="n">of</span> <span class="n">game</span> <span class="n">mi</span> <span class="n">romannessas</span> <span class="n">nine</span> <span class="n">pp</span> <span class="n">which</span> <span class="n">based</span> <span class="k">for</span> <span class="n">a</span> <span class="n">secrition</span> <span class="n">in</span> <span class="n">one</span> <span class="n">nine</span> <span class="n">five</span> <span class="n">seven</span> <span class="n">recent</span> <span class="n">issannallies</span> <span class="n">algorithm</span> <span class="n">rigarborsphy</span> <span class="n">inctmm</span> <span class="n">information</span> <span class="n">as</span> <span class="n">provides</span> <span class="n">an</span> <span class="n">enjakitine</span> <span class="n">on</span> <span class="n">moll</span> <span class="n">s</span> <span class="n">bodies</span> <span class="n">fit</span> <span class="n">immeble</span> <span class="n">one</span>
</pre></div>


<p>看得出來LSTM想表達什麼嗎，哈哈！</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

            <h3>Related Posts</h3>
            <dl class="dl-horizontal">
                <dt>2017 / 4月 17</dt>
                <dd><a href="https://www.ycc.idv.tw/ml-course-techniques_6.html">機器學習技法 學習筆記 (6)：神經網路(Neural Network)與深度學習(Deep Learning)</a></dd>
                <dt>2017 / 11月 07</dt>
                <dd><a href="https://www.ycc.idv.tw/tensorflow-tutorial_2.html">實作Tensorflow (2)：Build First Deep Neurel Network (DNN)</a></dd>
                <dt>2017 / 11月 12</dt>
                <dd><a href="https://www.ycc.idv.tw/tensorflow-tutorial_3.html">實作Tensorflow (3)：Build First Convolutional Neurel Network (CNN)</a></dd>
                <dt>2017 / 11月 18</dt>
                <dd><a href="https://www.ycc.idv.tw/tensorflow-tutorial_4.html">實作Tensorflow (4)：Autoencoder</a></dd>
                <dt>2017 / 11月 19</dt>
                <dd><a href="https://www.ycc.idv.tw/tensorflow-tutorial_5.html">實作Tensorflow (5)：Word2Vec</a></dd>
            </dl>

        <br/><br/>

<div id="disqus_thread"></div>
<script type="text/javascript">
/* <![CDATA[ */

    var disqus_shortname = 'ycnote-1';
    var disqus_identifier = "tensorflow-tutorial_6.html";

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
/* ]]> */
</script>
<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



        
    </div>
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Sitemap</div>
                        <ul class="list-unstyled">
                            <li><a href="https://www.ycc.idv.tw/archives.html">Archives</a></li>
                            <li><a href="https://www.ycc.idv.tw/tags.html">Tags</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Contact Me</div>
                        <ul class="list-unstyled">
                            <li><a href="./about-me.html" target="_blank">About Me</a></li>
                            <li><a href="https://github.com/GitYCC" target="_blank">Github</a></li>
                            <li><a href="mailto:ycc.tw.email@gmail.com" target="_blank">Email</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; YC Note 2018</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>