
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="True" name="HandheldFriendly"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="index, follow" name="robots"/>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&amp;family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&amp;display=swap" rel="stylesheet"/>
<link href="https://ycc.idv.tw/theme/stylesheet/style.less" rel="stylesheet/less" type="text/css"/>
<script src="//cdnjs.cloudflare.com/ajax/libs/less.js/2.5.1/less.min.js" type="text/javascript"></script>
<link href="https://ycc.idv.tw/theme/pygments/default.min.css" id="pygments-light-theme" rel="stylesheet" type="text/css"/>
<link href="https://ycc.idv.tw/theme/stork/stork.css" rel="stylesheet" type="text/css">
<link href="https://ycc.idv.tw/theme/font-awesome/css/fontawesome.css" rel="stylesheet" type="text/css"/>
<link href="https://ycc.idv.tw/theme/font-awesome/css/brands.css" rel="stylesheet" type="text/css"/>
<link href="https://ycc.idv.tw/theme/font-awesome/css/solid.css" rel="stylesheet" type="text/css"/>
<link href="/images/favicon.png" rel="shortcut icon" type="image/x-icon"/>
<link href="/images/favicon.png" rel="icon" type="image/x-icon"/>
<!-- Chrome, Firefox OS and Opera -->
<meta content="#FFFFFF" name="theme-color"/>
<!-- Windows Phone -->
<meta content="#FFFFFF" name="msapplication-navbutton-color"/>
<!-- iOS Safari -->
<meta content="yes" name="apple-mobile-web-app-capable"/>
<meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"/>
<!-- Microsoft EDGE -->
<meta content="#FFFFFF" name="msapplication-TileColor"/>
<link href="https://ycc.idv.tw/feeds/all.atom.xml" rel="alternate" title="YC Note Atom" type="application/atom+xml"/>
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68393177-2', 'auto');
  ga('send', 'pageview');
</script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LXDD9FZFX2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LXDD9FZFX2');
</script>
<meta content="YC Chen" name="author">
<meta content="什麼是Machine Learning / ML的使用時機 / 二元分類問題 / 多元學習" name="description">
<meta content="機器學習基石" name="keywords"/>
<meta content="YC Note" property="og:site_name">
<meta content="機器學習基石 學習筆記 (1)：何時可以使用機器學習?" property="og:title">
<meta content="什麼是Machine Learning / ML的使用時機 / 二元分類問題 / 多元學習" property="og:description">
<meta content="en_US" property="og:locale">
<meta content="https://ycc.idv.tw/ml-course-foundations_1.html" property="og:url"/>
<meta content="article" property="og:type"/>
<meta content="2016-06-06 12:00:00+08:00" property="article:published_time"/>
<meta content="" property="article:modified_time"/>
<meta content="https://ycc.idv.tw/author/yc-chen.html" property="article:author"/>
<meta content="AI.ML" property="article:section">
<meta content="機器學習基石" property="article:tag"/>
<meta content="" property="og:image"/>
<title>YC Note – 機器學習基石 學習筆記 (1)：何時可以使用機器學習?</title>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-5639899546876072",
      enable_page_level_ads: true
    });
  </script>
</meta></meta></meta></meta></meta></meta></meta></link><link href="https://ycc.idv.tw/ml-course-foundations_1.html" rel="canonical"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "BreadcrumbList", "itemListElement": [{"@type": "ListItem", "position": 1, "name": "YC Note", "item": "https://ycc.idv.tw"}, {"@type": "ListItem", "position": 2, "name": "Ml course foundations_1", "item": "https://ycc.idv.tw/ml-course-foundations_1.html"}]}</script><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "author": {"@type": "Person", "name": "YC Chen"}, "publisher": {"@type": "Organization", "name": "YC Note"}, "headline": "機器學習基石 學習筆記 (1)：何時可以使用機器學習?", "about": "AI.ML", "datePublished": "2016-06-06 12:00"}</script></head>
<body class="light-theme">
<aside>
<div>
<a href="https://ycc.idv.tw/">
<img alt="YC Note" src="https://ycc.idv.tw/theme/img/profile.png" title="YC Note"/>
</a>
<h1>
<a href="https://ycc.idv.tw/">YC Note</a>
</h1>
<p style="text-align: center;">ML/DL Tech Blog (Total Views: 522,196) </p>
<div class="stork">
<input autocomplete="off" class="stork-input" data-stork="sitesearch" name="q" onclick="loadStorkIndex(this); this.onclick=null;" placeholder="Search (beta feature) ..." type="text"/>
<div class="stork-output" data-stork="sitesearch-output"></div>
</div>
<!-- <script>
      window.addEventListener('load', 
        function() { 
          loadStorkIndex();
        }, false);
    </script> -->
<p>Hello, I am YC, an ML engineer/researcher with experience in CV, NLP/NLU, and Recommender. I also have experience in high-QPS ML systems. In my spare time, I'm a blogger and guitar singer. <a href="https://ycc.idv.tw/about-me.html#anchor" style="color:yellow">More about me.</a></p>
<p>This blog is a resource for anyone interested in data science and machine learning, featuring tutorials, research papers, and the latest industry technologies.</p>
<ul class="social">
<li>
<a class="sc-facebook" href="https://www.facebook.com/yc.note" target="_blank">
<i class="fa-brands fa-facebook"></i>
</a>
</li>
<li>
<a class="sc-github" href="https://github.com/GitYCC" target="_blank">
<i class="fa-brands fa-github"></i>
</a>
</li>
<li>
<a class="sc-linkedin" href="https://www.linkedin.com/in/yi-chang-chen-aba1b6114/" target="_blank">
<i class="fa-brands fa-linkedin"></i>
</a>
</li>
</ul>
</div>
</aside>
<main>
<nav id="anchor">
<a href="https://ycc.idv.tw/">Home</a>
<a href="/about-me.html#anchor">About Me</a>
<a href="/category/aiml.html#anchor">AI.ML</a>
<a href="/category/cs.html#anchor">CS</a>
<a href="/categories.html#anchor">Categories</a>
<a href="/tags.html#anchor">Tags</a>
<a href="https://ycc.idv.tw/feeds/all.atom.xml">Atom</a>
</nav>
<article class="single">
<header>
<h1 id="ml-course-foundations_1">機器學習基石 學習筆記 (1)：何時可以使用機器學習?</h1>
<p>
      Posted on June 06, 2016 in <a href="https://ycc.idv.tw/category/aiml.html">AI.ML</a>. View: 12,613

    </p>
</header>
<div class="tag-cloud">
<p>
<a href="https://ycc.idv.tw/tag/ji-qi-xue-xi-ji-shi.html">機器學習基石</a>
</p>
</div>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle ads-responsive" data-ad-client="ca-pub-5639899546876072" data-ad-slot="5718861428"></ins>
<script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
<div class="main-contents">
<h3 id="_1">前言</h3>
<p>經過幾個月的努力，終於完成田神在Coursera上machine learning的兩門課中的第一門課—<a href="https://www.coursera.org/course/ntumlone">機器學習基石</a>，田神不愧為田神的名號，整門課上起來非常流暢，每個觀念講得非常得清晰，考究學理，但是又不會單單只有理論而已，課程中會舉很多實用的例子，讓你了解每個觀念如何實踐。因此，非常推薦大家去把Coursera上面的課程完整聽一次，應該會收益良多，接下來一系列的文章，我會摘要出《機器學習基石》之中主要的概念，適合對Machine Learning（ML）有興趣的初學者來一窺它的脈絡。</p>
<p>《機器學習基石》一共有16堂課，主要分為四個方向，第一個方向，<strong>何時可以使用機器學習(When Can Machines Learn? )</strong>，點出什麼是機器學習，適合在哪些情形下使用，並引入貫穿整個課程的二元分類問題，第二個方向，<strong>為什麼機器可以學習(Why Can Machines Learn?)</strong>，介紹學理上機器學習必須要有哪些條件才可行，這些理論是了解機器學習非常重要的內功，第三個方向，<strong>機器可以怎麼樣學習(How Can Machines Learn?)</strong>，學習完了學理，我們來看機器學習有哪些的使用方法，最後一個方向，<strong>機器可以怎麼樣學得更好(How Can Machines Learn Better?)</strong>，探討哪些問題會造成機器學不好，然後怎麼去改善。</p>
<h3 id="machine-learning-ml">什麼是Machine Learning (ML)</h3>
<p>在了解機器學習之前，我們不妨來想想「你」從小是怎麼學習的，有人會說學習就是一個不斷記憶的過程，但這樣的說法顯然不夠全面，你總不會認為把考題的所有答案都背起來的學生就已經學會一門知識了吧！所以，考題只是表象，我們真正要學習的是它背後的觀念，可以拿來推敲未知的知識。</p>
<p>同樣的，ML的學習方式也有點類似於人類的學習，機器從Data中開始學習起，這些Data就像是一道一道的考題，而ML做的事正是去學習Data後面的觀念，而不是單純把Data給儲存起來，有了Data背後的觀念才能舉一反三，才算是真正的學會了。</p>
<p>所以，做ML有點像是手把手的造一顆大腦，並且訓練它學會Data背後的知識。那這個大腦要怎麼設計呢？這個大腦用我們學物理的人的說法就是建一個Model，而餵給它Data的過程就是Model Fitting。</p>
<p>那什麼是Model呢？讓我來解釋一下，<strong>所謂的Model就是給一個未知現象的框架來試圖描述它</strong>，舉個例子，我們都知道力的公式是<span class="math">\(F=ma\)</span>（力＝質量x加速度），但如果你今天拿一顆皮球來，你就會發現這個公式並不那麼正確，因為皮球會形變，那怎麼辦呢？我們可以假設形變會把部份的力給抵消掉，所以式子改寫成<span class="math">\((F-F_1)=ma\)</span>，在這邊<span class="math">\(F_1\)</span>就是那個抵消的力，這樣就是設計了一個Model來描述這個現象，而<span class="math">\(F_1\)</span>是一個未知的值，我們可以用實驗數據來推估<span class="math">\(F_1\)</span>，這就是所謂的Model Fitting。</p>
<p>物理上的Model通常是這樣做的，我們先觀察未知現象，然後從中猜測可能造成這現象的原因，總結這些原因來設計一個Model，Model中可能有一些參數還沒被決定，此時我們就可以用數據來決定它，這就是Model Fitting。</p>
<p><img alt="MachineLearningFoundations.001" src="/media/MachineLearningFoundations/MachineLearningFoundations.001.jpeg"/></p>
<p>了解了Model的概念就相當好了解ML的架構，上圖是ML的基本架構，<strong>假設我們今天要讓機器學一樣技術，這個技術我們用一個函數來表示，稱之為Target Function，這個Target Function就是隱藏在Data後面的真正道理</strong>，每個變數<span class="math">\(X\)</span>會有相應的正確答案<span class="math">\(Y\)</span>。</p>
<p>今天我從Target Function中取出<span class="math">\(N\)</span>組當作Data來給我的機器學習，那目標是什麼?<strong>目標當然是讓機器學習出這個Target Function啦！</strong>所以我們要先設計我們的Model，最終目的是決定Model裡的參數之後，這個被選擇的Model就是Target Function。</p>
<p>Model就是上圖中的Hypothesis Set，在Model參數還沒被決定之前，你可以想像它就像一個集合包含很多可以選擇的函數，而使用數據Model Fitting以後，選出一組最佳化的參數，就好像從這個集合中挑選一組函數一樣。</p>
<p>在這個找最佳化參數的過程，我們需要一個機制，這個機制可以評估Hypothesis Set中每組函數描述Data的好壞，並且找出描述Data最好的那組參數，這個機制就是上圖中的Learning Algorithm。</p>
<p><strong>建立Model，使用Data加上Learning Algorithm找出最佳參數，這就是ML的架構輪廓</strong>。當然這邊要補充一下，物理上的Model通常是建基在已知的知識之上，而常見的ML強大之處是不需要太多的人為的智慧，機器可以自行學習，所以我這裡指的Model是比物理上的Model更加廣義的。</p>
<h3 id="machine-learning-ml_1">Machine Learning (ML)的使用時機</h3>
<p>剛剛帶大家初探了ML的架構，接下來帶大家了解什麼時候我們適合使用ML。</p>
<p>舉幾個例子，大家可能比較有感覺，譬如說Netflix曾辦過一場競賽，競賽的內容是利用客戶的影片評分紀錄，來預測未評分影片的得分，如果可以增進預測率10%，就可以獨得100萬美元獎金，這個問題就可以使用ML，Data是過去得評分紀錄，Target Function是用戶評分的規律，如此一來，機器學到了這個技術，未來就可以舉一反三的推出未評分影片的分數，和用戶喜歡的影片可能有哪些。</p>
<p>再多看幾個例子，例如設計火星勘查機，人類目前對火星的了解仍相當有限，所以我們沒辦法完全猜測勘查機在火星會遇到什麼問題，所以必須讓勘查機有ML的能力去學習各種問題的解決方法。</p>
<p>再來個例子，現在很夯的汽車自動駕駛也需要ML技術，機器去學習辨識交通號誌。</p>
<p>看了這麼多例子，我們會發現這些例子都很難以寫出簡單的規則，但是卻又存在著一種規律，這種情形正是適合用ML來做。</p>
<p>在以往電腦工程幾乎都是由工程師用嚴謹的邏輯去逐條的把規則一一的寫上，這樣的機器不具有學習能力，或稱得上人工智慧，因為它只是單純反應工程師的工人智慧而已，但如果遇到一些困難的問題，譬如告訴機器什麼是狗，這時候你就會發現很難用人為規則來描述它，有尾巴，可是是怎樣的尾巴？有耳朵，那這耳朵怎麼和貓的耳朵區分開來？此時要用人為寫出規則就太困難了，我們不這麼做，反過來我們設計架構讓機器自己去從Data中學習。</p>
<p>總結一下上面的重點，ML的最佳使用時機包含下面三種情形</p>
<ol>
<li><strong>你想要學習的技術存在一種模式</strong></li>
<li><strong>要學習的技術不容易簡單的列出規則</strong></li>
<li><strong>存在可以代表這個要學習的模式的Data</strong></li>
</ol>
<h3 id="_2">二元分類問題</h3>
<p><img alt="img" src="/media/MachineLearningFoundations/MachineLearningFoundations.000.01.jpeg"/></p>
<p>from: <a href="https://class.coursera.org/ntumlone-003/lecture/17">https://class.coursera.org/ntumlone-003/lecture/17</a></p>
<p>好! 大家現在應該對於機器學習有一些認識了，那接下來我們來實作一些例子來了解機器學習架構怎麼運作。像個小學生一樣，我們先從簡單的是非題來學起，是非題學究一點的講法就是「二元分類問題」。</p>
<p>舉個例子，今天有一家銀行想要開發一款ML的軟體，這個軟體可以根據過去信用卡核發用戶的資料，去判斷要不要核發信用卡給這個新的申請人，這些過去的資料可能包括：用戶年齡、用戶性別、用戶年薪等等，讓機器藉由這些資料去學習判斷要不要核發信用卡。把這樣的二元分類問題化作</p>
<p>Target Function：<span class="math">\(f: X → y\)</span></p>
<p><span class="math">\(X\)</span>有年齡、性別和年薪這些變數，而<span class="math">\(y\)</span>則是個二元類別，不是<span class="math">\(y=1\)</span>(核發)就是<span class="math">\(y= -1\)</span>(不核發)。</p>
<p>那接下來，我們就要決定我們的Learning Model，也就是Hypothesis Set。</p>
<p><img alt="MachineLearningFoundations.002" src="/media/MachineLearningFoundations/MachineLearningFoundations.002.jpeg"/></p>
<p>引入<strong>Perceptron(感知器) Hypothesis Set</strong>來當作我們的Hypothesis Set，如上圖，我們給予我們的輸入變數個別的權重，然後相加起來，並且看這個值是正還是負，來決定輸出值是<span class="math">\(+1\)</span>或<span class="math">\(-1\)</span>，<span class="math">\(sign\)</span>函數的作用是假設輸入的值為正則輸出<span class="math">\(+1\)</span>，反之則輸出<span class="math">\(-1\)</span>。</p>
<p>對應核發信用卡這個例子，</p>
<p><span class="math">\(x_1\)</span> = 用戶年齡; <span class="math">\(x_2\)</span> = 用戶性別; <span class="math">\(x_3\)</span> = 用戶年薪，</p>
<p>在分別乘上weight <span class="math">\(w_1\)</span>, <span class="math">\(w_2\)</span>, <span class="math">\(w_3\)</span>，這個變數前面的weight代表這個變數對於答案<span class="math">\(Y\)</span>有什麼影響，如果是正向影響，<span class="math">\(weight &gt; 0\)</span>，如果沒有影響，<span class="math">\(weight = 0\)</span>，如果負向影響，<span class="math">\(weight &lt; 0\)</span>，舉個例子，高年薪也許可以提升核發信用卡的機會，那它前面的weight應該就是正的，也許性別並不影響核發信用卡的機會，則<span class="math">\(weight = 0\)</span>，那麼考慮到這些input變數對結果影響的評估，我們會得到一個數值 <span class="math">\((w_1\times x_1+w_2\times x_2+...)\)</span>。</p>
<p>此時我們要用這個數值去做「二元分類」，也就是一分為二，怎麼做呢? 很簡單，給他一分水嶺，高於一個閥值我就給他 <span class="math">\(y=+1\)</span>，低於一個閥值我就給他<span class="math">\(y=-1\)</span>，假設這個閥值為<span class="math">\((-w_0)\)</span>，則分類依據就可以表示為 <span class="math">\(sign(w_0+w_1\times x_1+w_2\times x_2+...)\)</span> 。</p>
<p>上圖中的 <span class="math">\(s = w_0+w_1\times x_1+w_2\times x_2+...\)</span> 就像一個分數(score)一樣，高分 <span class="math">\(s&gt;0\)</span> 的我就核發(<span class="math">\(+1\)</span>)，低分 <span class="math">\(s &lt; 0\)</span> 的我就不核發(<span class="math">\(-1\)</span>)，其中權重 <span class="math">\(w_0, w_1, w_2, ...\)</span> 都可以由機器學習去調整，這些不同的weight就構成了Hypothesis Set，也就是Model，那接下來我們還需要Learning Algorithm來取出最佳參數，也就是決定一組最佳weight來選出最吻合數據的Hypothesis。</p>
<p><img alt="MachineLearningFoundations.003" src="/media/MachineLearningFoundations/MachineLearningFoundations.003.jpeg"/></p>
<p>如上圖所示，<strong>Perceptron Learning Algorithm(PLA)</strong>是用於處理Perceptron Hypothesis Set的一種演算法。</p>
<p>它的作法簡單來講是，藉由一筆一筆的數據去逐步的更新它的weight使得Model可以描述這筆數據，直到不需要再更新為止，此時所有的Data都可以用這個Model表示，更新的方法是先判斷進來的這筆數據是否符合目前的Model預測，如果不符合，此時<span class="math">\(\left[...\right]\)</span>為<span class="math">\(+ 1\)</span>，則必須朝變數向量<span class="math">\(X_n\)</span>的方向，前進或後退大小為Learning Rate的一步來更新weight，前進還是後退端看你的Data是<span class="math">\(y=-1\)</span>或<span class="math">\(+1\)</span>，<span class="math">\(y=+1\)</span>就往前進，<span class="math">\(y=-1\)</span>就往後退。</p>
<p>因此，這個跨步更新的動作必須可以使Model接近正確答案，這麼神奇，真的假的？不太直覺，先從score來想起，假設有一筆資料為<span class="math">\((X_n,y_n)\)</span>，則Score：<span class="math">\(s = W_t・X_n\)</span>，在<span class="math">\(W_t\)</span>和<span class="math">\(X_n\)</span>向量彼此有同向分量的情況下，<span class="math">\(s &gt; 0\)</span>，如果這個時候<span class="math">\(y_n\)</span>剛好為<span class="math">\(+1\)</span>，則<span class="math">\(sign(s)=y_n\)</span>，這個時候<span class="math">\(W_t\)</span>描述這個數據就很好啊，我們就不需要去更新它；如果相反<span class="math">\(y_n=-1\)</span>，這個<span class="math">\(W_t\)</span>描述這個數據就不正確，也就是說<span class="math">\(W_t\)</span> 和 <span class="math">\(X_n\)</span>不應該同向，所以我們讓<span class="math">\(W_t\)</span>加上<span class="math">\(-X_n\)</span>(<span class="math">\(=y_n\times X_n\)</span>)，把<span class="math">\(W_t\)</span>從原本與<span class="math">\(X_n\)</span>同向的狀態反向拉離開來。那如果在<span class="math">\(W_t\)</span>和<span class="math">\(X_n\)</span>向量彼此不同向的情況下，<span class="math">\(s &lt; 0\)</span>，這個時候如果<span class="math">\(y_n\)</span>剛好為<span class="math">\(-1\)</span>，則<span class="math">\(sign(s)=y_n\)</span>，很好我們不去更新它；如果相反<span class="math">\(y_n=+1\)</span>，這個<span class="math">\(W_t\)</span>描述這個數據不正確，也就是說<span class="math">\(W_t\)</span> 和 <span class="math">\(X_n\)</span>不應該反向，所以我們讓<span class="math">\(W_t\)</span>加上<span class="math">\(X_n\)</span>(<span class="math">\(=y_n\times X_n\)</span>)，把<span class="math">\(W_t\)</span>拉到和<span class="math">\(X_n\)</span>同向一點。這就是PLA找到更好<span class="math">\(W_t\)</span>的機制。</p>
<p><img alt="MachineLearningFoundations.004" src="/media/MachineLearningFoundations/MachineLearningFoundations.004.jpeg"/></p>
<p>Seeing is believing，上面這張圖帶我們來看PLA如何運作，</p>
<ul>
<li>Initially: 在最一開始的時候，我們weight <span class="math">\(W_t\)</span>先設成零向量</li>
<li>Update 1: PLA更新把零向量的<span class="math">\(W_t\)</span>拉成<span class="math">\(W_{t+1}\)</span></li>
<li>Update 2: 上一輪的<span class="math">\(W_{t+1}\)</span>已經是這一輪的<span class="math">\(W_t\)</span>，也就是紅色的那個向量，<span class="math">\(W_t\)</span>決定了一條壁壘分明的二元分類邊界，這條線的方程式其實就是 <span class="math">\(w_0+w_1x_1+... = 0\)</span>，如果你還記得高中數學的話，這條邊界必然會和<span class="math">\(W_t\)</span>垂直，如圖所示，而<span class="math">\(W_t\)</span>的方向是屬於<span class="math">\(y=+1\)</span>的區域，這一輪剛剛好找到一個圈(<span class="math">\(y=+1\)</span>)落在<span class="math">\(y=-1\)</span>的區域，因此我們需要更新weight，做法是把<span class="math">\(W_t\)</span> 和 <span class="math">\(y_n\times X_n\)</span>(=<span class="math">\(X_n\)</span>)相加成為新的weight <span class="math">\(W_{t+1}\)</span></li>
<li>...........以此類推</li>
</ul>
<p><strong>如果資料線性可分的話，PLA在迭代多次後，是可以用一條線完全區分兩種數據</strong>。但如果數據不是線性可分，不存在一條線來區分數據，此時最佳解就必須評估整體犯錯有多少，找出犯錯最少的那條直線就是最佳解，但可惜的是PLA方法並不會在迭代中趨向於犯錯最少的那條線，什麼時候該停止迭代是個世紀難解的NP-Hard問題（如果不了解這個名詞，<a href="/algorithm-complexity-theory.html">詳見</a>）。</p>
<p>因此要改變一下PLA，這個方法我們稱之為Pocket，當每次得到一組weight的時候，都拿它來評估它對所有Data的區分能力好或壞，而只留下一組最好的放進口袋裡，所以當迭代次數做多了，保留在口袋的這組解就可以看成是最佳解，就這麼簡單。</p>
<h3 id="_3">多元學習</h3>
<p>機器學習和人類學習一樣，有各式各樣的學習型態。剛剛的<strong>「二元分類問題」</strong>就像考「是非題」一樣，答案要嘛是Yes不然就是No，表示為 <strong><span class="math">\(y=\{-1, 1\}\)</span></strong>，這就像是機器在小學時代的問題，較為簡單。</p>
<p>現在機器脫離國小來到了國中，考試題目開始出現「選擇題」，這和機器學習中的<strong>「多元分類問題」</strong>一樣，必須從兩個以上有限的答案中作選擇，表示為 <strong><span class="math">\(y=\{1, 2, ... , k\}\)</span></strong>。</p>
<p>另外機器還可能遇到傷透腦筋的「計算題」，在機器學習裏頭稱為<strong>「Regression 問題」</strong>，這個時候答案已經放寬到整個實數系了，表示為 <strong><span class="math">\(y∈R\)</span></strong>，舉個例子，譬如利用過去天氣的數據去預測明日氣溫，或者利用歷史股價資料預測未來股價，都是Regression的應用。</p>
<p>此時，機器到了大學，開始碰到不那麼容易回答，甚至不存在單一答案的「申論題」，這在ML中像是<strong>「Structure Learning 問題」</strong>，答案的選擇換成了各種結構，表示為 <strong><span class="math">\(y=\{structures\}\)</span></strong>，舉個例子可能比較好理解，例如：自然語言，我們都希望有一天電腦可以理解我們的語言，我們可以不再需要以機器語言來和電腦溝通，而是用人類的語言直接和電腦溝通，聽起來很棒對吧! 這個部分的ML就需要Structure Learning來學習語言的文法結構。</p>
<p>我們教機器學習也有各種不同的教育方法。</p>
<p>有像是填鴨式教育的<strong>「Supervised Learning」(監督式學習）</strong>，直接告訴機器考題和答案，讓機器從中學習，這種情況下每筆資料<span class="math">\(X_n\)</span>對應的<span class="math">\(y_n\)</span>都有明確Label，Data中有明顯的答案。</p>
<p>有像是培養科學家教育方法一樣的<strong>「Unsupervised Learning」(非監督式學習）</strong>，此時每筆資料<span class="math">\(X_n\)</span>對應的<span class="math">\(y_n\)</span>都沒有Label，所以機器要自己歸納整理，然後從中學到規律，通常用於分群問題，對資料做分類找出規律性。</p>
<p>那還有折衷於上述兩種方法的啟發式教育，<strong>「Semi-supervised Learning」(半監督式學習）</strong>，在這個情形下有部分資料<span class="math">\(y_n\)</span>是有Label的，機器可以藉由有Label的正確答案和資料的規律性來做更好的學習，一個有名的例子是Facebook的人臉辨識標記功能，有部分已經被用戶標記的照片，這屬於有Label的<span class="math">\(y_n\)</span>，但有更多沒有標記的照片，這些照片也可以幫助ML學習。</p>
<p>那還有像是訓練小狗的方法，當我跟小狗說坐下，如果牠真的坐下了，這個時候我就給牠獎勵，譬如說餵牠好吃的食物，久而久之牠就會學會聽從這個命令，<strong>「Reinforcement Learning」(強化式學習）</strong>就是不直接表明<span class="math">\(y_n\)</span>的Label，但是機器能在嘗試中得到<span class="math">\(y_n\)</span>結果的好壞，再從這個好壞當作回饋去優化它的學習。</p>
<p>Data給的方法也可以有很多種類。</p>
<p>剛剛舉的ML例子都是屬於<strong>「Batch Learning」</strong>，也就是一次給你所有的Data。另外一種給Data的方法叫做<strong>「Online Learning」</strong>，這個情形下Data會一個一個以序列的方式餵給機器，這麼方式下的Model可以隨時更新。最後一種方式是<strong>「Active Learning」</strong>，機器不僅是被動的接受 Data，而是會根據它自己的需求向使用者索取它想要的Data。</p>
<p>另外，除了有輸出值<span class="math">\(y_n\)</span>有多種種類之外，輸入的變數<span class="math">\(X_n\)</span>的來源也有很多種，我們稱之為Features。</p>
<p>如果具有物理意義的輸入變數，稱之為<strong>「Concrete Features」</strong>，這些變數建立在人類知識的預先處理。還有輸入變數並不具有物理含意的情形，這稱之為<strong>「Abstract Features」</strong>。那有些情形下直接採用不加以處理的原始數據，稱為<strong>「Raw Features」</strong>。</p>
<p>而使用工人智慧由人力從Raw Features中萃取出Concrete Features，這叫做Feature Engineering。相反的，現在很夯的Deep Learning厲害的地方是他可以自行從Data中學習 Features。</p>
<p><strong>總結一下，機器學習有很多種型態，從Data的給予方式可分為Batch Learning、Online Learning和Active Learning。Data的表達形式由輸入變數<span class="math">\(X_n\)</span>和輸出值<span class="math">\(y_n\)</span>所決定，從輸入變數<span class="math">\(X_n\)</span>的來源可分為Concrete Features、Raw Features和Abstract Features，從輸出值<span class="math">\(y_n\)</span>的種類上可以分為二元分類、多元分類、Regression和Structured Learning 問題，從輸出值<span class="math">\(y_n\)</span>的Label給予情況可分為Supervised Learning、Unsupervised Learning、Semi-supervised Learning 和 Reinforcement Learning。</strong></p>
<p>順道一提，這16堂課裡頭主要聚焦在探討Batch Supervised Learning with Concrete Features。</p>
<h3 id="_4">後話</h3>
<p>這篇文章帶大家初探了一眼機器學習，介紹了機器學習的架構和種類，以及它的使用時機，還有介紹了整門課非常重要的二元分類問題。但是講這麼多，機器學習真的可能嗎? 那如果可以做到，會需要哪一些要素呢? 這就必須深入理論之中，才能找到答案，在下一篇文章裡，我將介紹這門課的第二個部分：Why Can Machines Learn? </p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "left",
        indent = "1em",
        linebreak = "true";

    if (true) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</div>
<div class="center social-share">
<p>Like this article? Share it with your friends!</p>
<div class="addthis_native_toolbox"></div>
<div class="addthis_sharing_toolbox"></div>
<div class="addthis_inline_share_toolbox"></div>
</div>
<div class="neighbors">
<a class="btn float-right" href="https://ycc.idv.tw/ml-course-foundations_2.html#anchor" title="機器學習基石 學習筆記 (2)：為什麼機器可以學習?">
      Next Post <i class="fa fa-angle-right"></i>
</a>
</div>
<div class="addthis_relatedposts_inline"></div>
<div class="related-posts">
<h4>You might enjoy</h4>
<ul class="related-posts">
<li><a href="https://ycc.idv.tw/ml-course-foundations_2.html">機器學習基石 學習筆記 (2)：為什麼機器可以學習?</a></li>
<li><a href="https://ycc.idv.tw/ml-course-foundations_3.html">機器學習基石 學習筆記 (3)：機器可以怎麼樣學習?</a></li>
<li><a href="https://ycc.idv.tw/ml-course-foundations_4.html">機器學習基石 學習筆記 (4)：機器可以怎麼學得更好?</a></li>
</ul>
</div>
<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'ycnote-1';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
    Please enable JavaScript to view comments.
</noscript>
<!-- End Disqus -->
</article>
<footer>
<p>
  © 2023  - This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" rel="license" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
<a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license" target="_blank">
<img alt="Creative Commons License" height="15" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" style="border-width:0" title="Creative Commons License" width="80"/>
</a>
</p></footer> </main>
<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " YC Note ",
  "url" : "https://ycc.idv.tw",
  "image": "",
  "description": "[ YC Note - ML/DL Tech Blog ] Hello, I am YC, an ML engineer/researcher with experience in CV, NLP/NLU, and Recommender. I built this blog for anyone interested in data science and machine learning."
}
</script><script async="async" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-63b4eabb5e84e9fb" type="text/javascript"></script>
<script>
    window.loadStorkIndex = async (input_obj) => {
      input_obj.disabled = true;
      input_obj.placeholder = 'Downloading index file, please wait ...'
      await stork.register("sitesearch", "https://ycc.idv.tw/search-index.st", { showProgress: false });
      input_obj.placeholder = 'Search ...'
      input_obj.disabled = false;
    }
  </script>
<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
</body>
</html>