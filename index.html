<!DOCTYPE html>
<html lang="zh">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="YC Note, 本網站內容包括機器學習(Machine Learning)、深度學習(Deep Learning)、類神經網路(Neural Network)、資料科學(Date Science)、Python、演算法(Algorithm)。">
        <meta name="keywords" content="">
        <link rel="icon" href="./static/img/favicon.png">

        <title>Homepage - YC Note</title>

        <!-- Stylesheets -->
        <link href="./theme/css/all.min.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <link href="YCNote/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="YC Note Full Atom Feed" />
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->



    </head>

    <body>

        <!-- Header -->
    <div class="header-container" style="background: linear-gradient(rgba(0, 0, 0, 0.2), rgba(0, 0, 0, 0.2)), url('./images/welcome_front_board.jpg'); background-position: center; background-size: cover;">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                        <a class="pull-left" href="./"><img class="logo" src="./static/img/favicon.png" alt="logo">YC Note</a>
                    </div>
                    <div class="nav pull-right">
                                <a href="./category/coding.html">Coding</a>
                                <a href="./category/aiml.html">AI.ML</a>
                                <a href="./category/reading.html">Reading</a>
                                <a href="./category/recording.html">Recording</a>
                                <a href="./about-me.html">About Me</a>
                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title">YC NOTE</h1>
                      <div class="header-underline"></div>
                      <p class="header-subtitle header-subtitle-homepage">想像力比知識更重要</p>
                  </div>
              </div>
        </div>
    </div>
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    
    <div class="archive-container">
        <div class="container content archive">
            <h2><a href="./index.html">Last Posts </a></h2>
            <dl class="dl-horizontal">
                <dt>2018 / 4月 14</dt>
                <dd><a href="./introduction-object-oriented-programming_3.html">物件導向武功秘笈（3）：內功篇 — 物件導向指導原則SOLID</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>物件導向怎麼用才能成就好的程式碼？</u></h5>
<p>一個好的工具，也要配合對於工具的理解，才能發揮效用。<a href="http://www.ycc.idv.tw/YCNote/post/48">在上一回中</a>，我們完整介紹了Java和Python的物件導向實現方式，我們講到了「封裝」、「繼承」、「多型」等等物件導向的特色，也講了「抽象類別」、「接口」等抽象化的方法，不過我並沒有告訴大家該怎麼用這些工具？使用這些工具是不是有什麼樣的法則？</p>
<p>在接下來的這一篇，我將會介紹物件導向的使用方式，我會提到物件導向著名的六大法則：</p>
<ol>
<li>單一職責原理</li>
<li>開閉原理</li>
<li>里氏替換原則</li>
<li>迪米特法則</li>
<li>依賴倒置原則</li>
<li>接口分隔原則</li>
</ol>
<p>在這之前我們先來介紹描述類別關係的UML類別圖。</p>
<h5><u>UML類別圖</u></h5>
<p>開始介紹各種原則之前，先來介紹UML類別圖，UML全名稱為Unified Modeling Language，是一種使用圖形來描繪軟體工程架構的方法，這邊準備介紹的是它的類別圖，這個工具有助於我們快速的了解物件與物件之間的關係。</p>
<ul>
<li>類別(Class): -代表<code>private</code>，+代表<code>public</code>，#代表<code>protected</code></li>
</ul>
<p><img alt="Class" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Class.png"></p>
<ul>
<li>抽象類別(Abstract Class)</li>
</ul>
<p><img alt="AbstractClass" src="https://www.ycc.idv.tw/media/SOLID_Introduction/AbstractClass.png"></p>
<ul>
<li>接口(Interface)</li>
</ul>
<p><img alt="Interface" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Interface.png"></p>
<ul>
<li>繼承關係(Inheritance)和抽象類、接口實現</li>
</ul>
<p><img alt="Inheritance" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Inheritance.png"></p>
<ul>
<li>關聯關係(Association)：A類中使用B類當作「成員變數」，但是A和B並沒有「擁有」的關係，只能說是「有個」的關係，就稱為：A關聯到B，英文為"has-a"的關係。</li>
</ul>
<p><img alt="Associatione" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Association.png"></p>
<ul>
<li>聚合關係(Aggregation)：A類中使用B類當作「成員變數」，而且A和B有一個弱的「擁有」關係，A包含B，但B不是A的一部分，拔掉B，A依然能存在，就稱為：A聚合到B，英文為"owns-a"關係。</li>
</ul>
<p><img alt="Aggregation" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Aggregation.png"></p>
<ul>
<li>合成（組合）關係(Composition)：A類中使用B類當作「成員變數」，而且A和B有一個強的「擁有」關係，B是A的組成的一部分，拔掉B，A就不完整，就稱為：A合成到B，英文為"is-part-of"關係。</li>
</ul>
<p><img alt="Composition" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Composition.png"></p>
<ul>
<li>依賴關係(Dependency)：A類中使用到B類，但僅僅是弱連結，譬如：B類作為A類方法的參數、B類作為A類的局域變數、A類調用B類的靜態方法、B類作為A類方法的回傳值，就稱為：A依賴B，英文為"uses-a"的關係。</li>
</ul>
<p><img alt="Dependency" src="https://www.ycc.idv.tw/media/SOLID_Introduction/Dependency.png"></p>
<h5><u>單一職責原則(Single Responsibility Principle, SRP)</u></h5>
<ul>
<li>
<p>定義：There should never be more than one reason for a class to change.（一個類別中不要有多於一個以上的變化理由）</p>
</li>
<li>
<p>簡單的說，就是一個類別中不要做超過一件事，要去切分直到不能再分割為止，如此一來可以提高內聚性。</p>
</li>
<li>
<p>乍看之下，這樣的原則很容易實現，但是魔鬼藏在細節裡，我們常常會沒注意到其實還可以繼續的切分。舉個例子，假設我想設計一個電話的接口，我可能是這樣設計的</p>
</li>
</ul>
<p><img alt="phone_1" src="https://www.ycc.idv.tw/media/SOLID_Introduction/phone_1.png"></p>
<p>乍看之下沒有問題，一個電話擁有撥號、掛號、數據傳送和接收，但是等等！連接的過程和數據的傳輸其實是兩個職責啊！它們之間沒有強烈的關聯性，完全是可以分開處理的，因此這個配置不符合「單一職責原則」，可以繼續切分下去，修改如下。</p>
<p><img alt="phone_2" src="https://www.ycc.idv.tw/media/SOLID_Introduction/phone_2.png"></p>
<ul>
<li>「單一職責原則」原文指的是類別的單一職責，但是務實上，類別如果切分到如此程度，程式碼會變得細碎不堪，這違反了程式碼的「可讀性」，所以我們一般只要求「接口必須保持單一原則」，而類別去套用接口，類別就盡量達成少的職責就好。</li>
</ul>
<h5><u>開閉原則(Open-Closed Principle, OCP)</u></h5>
<ul>
<li>
<p>定義：Software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification.（軟體中的實體，例如：類、模組、函數等等，都必須對延伸開放，但對修改封閉）</p>
</li>
<li>
<p>對延伸開放：實體在因應新的改變時，必須是可以靈活擴充的。</p>
</li>
<li>
<p>對修改封閉：實體一旦完成，就盡量不要再去修改它了。</p>
</li>
<li>
<p>綜合以上兩點，我們可以總結出：實體本身的內聚性要高，可以讓我們未來不需要再做修改，單一職責可以做到增強內聚性；實體間的耦合性要低，所以實體像是積木一樣可以因應各種需求去任意組合、擴充。所以「開閉原則」只是進一步的把「低耦合高內聚」再說的更清楚一點，實現「開閉原則」將有利於單元測試、提高維護和擴充能力。</p>
</li>
</ul>
<h5><u>里氏替換原則(Liskov Subsititution Principle, LSP)</u></h5>
<ul>
<li>
<p>定義：What is wanted here is something like the following substitution property: If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.（簡言之：子類對象能夠替換其父類對象，使用父類方法而不會有問題）</p>
</li>
<li>
<p>「里氏替換原則」用於規範繼承，子類繼承自父類的方法是保有彈性可以覆寫(Overriding)和多載(Overloading)的，但是應該怎麼做，程式碼才不會髒掉？「里氏替換原則」告訴我們一個簡單的法則，就是先寫一段父類的執行代碼，然後把父類替換成子類，然後再跑跑看能不能正常執行，如果正常執行代表這個繼承關係是健康的。</p>
</li>
<li>
<p>為什麼要這樣檢查？之前我們提過繼承主要是為了要避免Repeat Yourself而生，我們找出各種類別共享的屬性和方法，把它獨立出來，然後大家再一起繼承自它，所以我們要盡可能的避免父類出現不是共享的性質。也就是說在理想情況下「父類必須等於子類們的交集」，所以「父類必定是任一子類的子集合」，因此「使用子類來執行父類是不應該有問題的」，這就是「里氏替換原則」。</p>
</li>
<li>
<p>為了遵循「里氏替換原則」，則子類必須完全實現父類的方法。如果子類不能完整地實現父類的方法，或者父類的某些方法在子類中已經發生了「畸變」，則建議斷開父子繼承關係，採用依賴、聚集、組合等關係替代。</p>
</li>
<li>
<p>有了「里氏替換原則」，我們終於可以談談一個上一章沒提到的重要問題：什麼情況可以做繼承？有一些書籍會告訴你，繼承為"is-a"的關係，例如：瑪爾濟斯(B) is-a 狗(A)，所以瑪爾濟斯(B)可以繼承狗(A)，乍看之下沒問題，但這樣的說法存在缺陷，舉個例子，假設今天我先有了類別<code>Retangle</code>，也就是長方形，然後我想要弄一個新的類別<code>Square</code>，也就是正方形，我可以讓<code>Square</code>繼承自<code>Retangle</code>嗎？我們用"is-a"來檢視：正方形是一個長方形？答案是Yes，但是「里氏替換原則」持相反意見，來看一下，</p>
</li>
</ul>
<p><img alt="square_1" src="https://www.ycc.idv.tw/media/SOLID_Introduction/square_1.png"></p>
<p>依照「里氏替換原則」，<code>Square</code>不能繼承自<code>Retangle</code>，因為<code>Square</code>只需要<code>width</code>的成員變數，而<code>Retangle</code>則需要<code>width</code>和<code>height</code>兩個成員變數，當我們將子類<code>Square</code>放到父類<code>Retangle</code>的方法中，因為缺少<code>height</code>變數，必然會出錯，所以違反「里氏替換原則」，因此這兩類不適合作為「繼承」關係。我們可以這樣改善，讓<code>Square</code>應用<code>Retangle</code>來幫忙計算，使用「關聯」關係取代「繼承」關係。</p>
<p><img alt="square_2" src="https://www.ycc.idv.tw/media/SOLID_Introduction/square_2.png"></p>
<ul>
<li>下面這一張集合圖是我自創的，圖中清楚的指出「繼承」中的父類和子類應該是什麼樣的關係。</li>
</ul>
<p><img alt="Inheritance Principle.jpeg" src="https://www.ycc.idv.tw/media/SOLID_Introduction/inheritance_principle.jpeg"></p>
<h5><u>迪米特法則(Law of Demeter, LoD)</u></h5>
<ul>
<li>
<p>又稱為「最少知識原則」</p>
</li>
<li>
<p>定義：</p>
<ol>
<li>Each unit should have only limited knowledge about other units: only units "closely" related to the current unit.</li>
<li>Each unit should only talk to its friends; don't talk to strangers.</li>
<li>Only talk to your immediate friends.</li>
</ol>
</li>
<li>
<p>「朋友」的定義：對於類別C的所有方法M而言，在M的方法中僅能訪問以下物件的方法</p>
<ul>
<li><code>self</code>，類別C自身</li>
<li>M的輸入參數</li>
<li>C的成員變數</li>
<li>M的輸出物件</li>
<li>全域變數的物件</li>
</ul>
</li>
<li>
<p>白話總結：</p>
<ol>
<li>僅能訪問那些類別出現在自身、成員變數、方法的輸入和輸出參數中的方法。</li>
<li>減少類別的對外方法，將沒必要對外公布的方法隱藏起來。 </li>
</ol>
</li>
</ul>
<p><strong>（詳解）僅能訪問那些類別出現在自身、成員變數、方法的輸入和輸出參數中的方法。</strong></p>
<p>-- 例子: 假設今天一名老師給了學生名條想叫班長幫忙點名。</p>
<p>錯誤示範：</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Student</span><span class="p">:</span> <span class="c1">#friends: None</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

<span class="k">class</span> <span class="nc">Leader</span><span class="p">:</span> <span class="c1">#friends: Student</span>
    <span class="k">def</span> <span class="nf">countStudents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">student_list</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Total number of students is &quot;</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">student_list</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">Teacher</span><span class="p">:</span> <span class="c1">#friends: Leader</span>
    <span class="k">def</span> <span class="nf">command</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name_list</span><span class="p">,</span><span class="n">leader</span><span class="p">):</span>
        <span class="n">student_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">name_list</span><span class="p">:</span>
            <span class="n">student_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Student</span><span class="p">(</span><span class="n">name</span><span class="p">))</span> <span class="c1">#`Student` is not a friend</span>
        <span class="n">leader</span><span class="o">.</span><span class="n">countStudents</span><span class="p">(</span><span class="n">student_list</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">teacher</span> <span class="o">=</span> <span class="n">Teacher</span><span class="p">()</span>
    <span class="n">leader</span> <span class="o">=</span> <span class="n">Leader</span><span class="p">()</span>
    <span class="n">name_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;D&#39;</span><span class="p">,</span><span class="s1">&#39;E&#39;</span><span class="p">]</span>
    <span class="n">teacher</span><span class="o">.</span><span class="n">command</span><span class="p">(</span><span class="n">name_list</span><span class="p">,</span><span class="n">leader</span><span class="p">)</span>
</pre></div>


<p><img alt="teacher-leader-student_1" src="https://www.ycc.idv.tw/media/SOLID_Introduction/teacher-leader-student_1.png"></p>
<p>以上程式違反「迪米特法則」，因為在類別<code>Teacher</code>的方法<code>command</code>中訪問了不是朋友的<code>Student</code>，這會使得<code>Teacher</code>和<code>Student</code>會產生不必要的耦合，我們可以將創造<code>student_list</code>的權責轉移到<code>Leader</code>上，如此一來就可以斷開<code>Teacher</code>和<code>Student</code>的耦合。</p>
<p>正確示範：</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Student</span><span class="p">:</span> <span class="c1">#friends: None</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

<span class="k">class</span> <span class="nc">Leader</span><span class="p">:</span> <span class="c1">#friends: Student</span>
    <span class="k">def</span> <span class="nf">giveNameList</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name_list</span><span class="p">):</span>
        <span class="n">student_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">name_list</span><span class="p">:</span>
            <span class="n">student_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Student</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">__student_list</span> <span class="o">=</span> <span class="n">student_list</span>

    <span class="k">def</span> <span class="nf">countStudents</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Total number of students is &quot;</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__student_list</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">Teacher</span><span class="p">:</span> <span class="c1">#friends: Leader</span>
    <span class="k">def</span> <span class="nf">command</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name_list</span><span class="p">,</span><span class="n">leader</span><span class="p">):</span>
        <span class="n">leader</span><span class="o">.</span><span class="n">giveNameList</span><span class="p">(</span><span class="n">name_list</span><span class="p">)</span>
        <span class="n">leader</span><span class="o">.</span><span class="n">countStudents</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">teacher</span> <span class="o">=</span> <span class="n">Teacher</span><span class="p">()</span>
    <span class="n">leader</span> <span class="o">=</span> <span class="n">Leader</span><span class="p">()</span>
    <span class="n">name_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span><span class="s1">&#39;B&#39;</span><span class="p">,</span><span class="s1">&#39;C&#39;</span><span class="p">,</span><span class="s1">&#39;D&#39;</span><span class="p">,</span><span class="s1">&#39;E&#39;</span><span class="p">]</span>
    <span class="n">teacher</span><span class="o">.</span><span class="n">command</span><span class="p">(</span><span class="n">name_list</span><span class="p">,</span><span class="n">leader</span><span class="p">)</span>
</pre></div>


<p><img alt="teacher-leader-student_2" src="https://www.ycc.idv.tw/media/SOLID_Introduction/teacher-leader-student_2.png"></p>
<p>-- Why it works? </p>
<p>先來想想「朋友」有什麼共通之處？其實它們都是類別本身無法斷開耦合的物件，既然無法斷開耦合，何不運用到底，運用這些「朋友」來完成任務，不要再去增加其他的耦合性，也同時幫助提升類別的內聚性，這就是「迪米特法則」真正想做的事。</p>
<p>以這樣的方式去寫程式，也可以避免寫出像是<code>A.getB().getC()</code>的程式碼（A和C不是朋友），這樣冗長的程式碼不僅增加了無益的耦合，也讓程式變得不利於可讀性。</p>
<p><strong>（詳解）減少類別的對外方法，將沒必要對外公布的方法隱藏起來。</strong></p>
<p>-- 例子: 安裝程式。</p>
<p>錯誤範例：</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Wizard</span><span class="p">:</span> <span class="c1"># 3 public methods</span>
    <span class="k">def</span> <span class="nf">first</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Install first step of wizard at mode&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">second</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Install second step of wizard at mode &quot;</span><span class="o">+</span><span class="n">mode</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">third</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Install third step of wizard&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Install</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">install</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">wizard</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="n">wizard</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
        <span class="n">wizard</span><span class="o">.</span><span class="n">second</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="n">wizard</span><span class="o">.</span><span class="n">third</span><span class="p">()</span>
</pre></div>


<p>有太多沒必要對外公布的細節了，依照「迪米特法則」，我們應該將盡量減少對外公布的資訊，把不必要公布的細節私有化。</p>
<p>正確範例：</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Wizard</span><span class="p">:</span> <span class="c1"># only 1 public method</span>
    <span class="k">def</span> <span class="nf">install</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__first</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__second</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__third</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__first</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Install first step of wizard&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__second</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Install second step of wizard at mode &quot;</span><span class="o">+</span><span class="n">mode</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__third</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Install third step of wizard&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Install</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">install</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">wizard</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="n">wizard</span><span class="o">.</span><span class="n">install</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
</pre></div>


<h5><u>依賴倒置原則(Dependence Inversion Principle, DIP)</u></h5>
<ul>
<li>
<p>定義：High level modules should not depend upon low level modules. Both should depend upon abstractions. Abstractions should not depend upon details. Details should depend upon abstractions.（高層次模組不應該依賴低層次模組，兩者都應該依賴抽象。而抽象不應該依賴細節，反之細節應該要依賴抽象。）</p>
</li>
<li>
<p>範例：假設我們成立一家玩具車公司，開始著手設計我們的第一款車款A，設計的架構圖如下</p>
</li>
</ul>
<p><img alt="toycar_1" src="https://www.ycc.idv.tw/media/SOLID_Introduction/toycar_1.png"></p>
<p><code>ToyCarA</code>是我們的實體車子，可以使用<code>setRPM</code>來設定在幾秒之後到達什麼轉速，而控制他的是電腦模擬的虛擬車<code>VirtualCar</code>，虛擬車提供方法<code>setSpeeed</code>可以設定車速，當然！模擬的車速要和真實車速吻合，還需配合適當的調控實體車的轉速，所以<code>VirtualCarA</code>關聯到<code>ToyCarA</code>去做控制。然後我們公司會提供一個控制器<code>ControllerA</code>來控制車子，控制器上的搖桿分為五級，讓使用者可以控制速度，使用<code>controlBarLevel</code>方法根據級數去控制<code>VirtualCarA</code>的速度。</p>
<p>檢驗一下這個設計圖，它違反「依賴倒置原則」，<code>ControllerA</code>依賴<code>VirtualCarA</code>，<code>VirtualCarA</code>依賴<code>ToyCarA</code>，這些都是實體類別，高層次依賴了低層次。不過，公司的車子A還是賣得很好，沒有什麼大礙。</p>
<p>終於有一天災難降臨了，市場出現了比車子A馬力更強大的玩具車，我們公司如果不趕緊採用新的馬達推出新的車款，就會失去競爭力，我們需要採用新的玩具車<code>ToyCarB</code>，它擁有更好的馬達，我們需要為因應高速度而推出九級分級的搖桿，新的控制器<code>ControllerB</code>，結果回頭一看原本設計圖，完了！所有的A系列的程式碼都耦合在一起了，核心程式<code>VirtualCarA</code>原可以不需要大改，就建造出<code>VirtualCarB</code>的，但是現在程式碼全部耦合在一起，它已經變得不可擴張了。</p>
<p>如果我們一開始就依照「依賴倒置原則」，我們來看看擴張會有多容易</p>
<p><img alt="toycar_2" src="https://www.ycc.idv.tw/media/SOLID_Introduction/toycar_2.png"></p>
<p><code>VirtualCar</code>中的很多方法都可以在B車款上再重用，大大的減少重新開發的成本。</p>
<ul>
<li>
<p>依賴倒置原則又稱為「面向接口原則」，這裡的接口應該想的更廣義一點，不侷限在interface上，我認為只要藉由抽象化將架構擬定出來的這些抽象單元都可以稱作接口，「廣義的接口」可以是指</p>
</li>
<li>
<p>客戶端和業務邏輯的分離介面</p>
</li>
<li>物件的開放方法</li>
<li>抽象類別</li>
<li>定義行為的interface</li>
</ul>
<p>我們不讓作為實現的類別彼此依賴，而是使用接口將抽象架構擬定好，再讓類別去依賴接口實現目標。</p>
<h5><u>接口分隔原則(Interface Segregation Principle, ISP)</u></h5>
<ul>
<li>
<p>定義：Clients should not be forced to depend uponn interfaces that they don't use. The dependency of one class to another one should depend on the smallest possible interface.（客戶類不應該被強迫依賴那些它不需要的接口，類別間的彼此依賴應該建立在盡可能小的接口上）</p>
</li>
<li>
<p>這裡說的接口同樣的是剛剛所說的「廣義接口」，可以是客戶端和業務邏輯的分離介面、物件的開放方法、抽象類別和Interface。</p>
</li>
<li>
<p>接口分隔原則建議我們要讓這些廣義接口盡可能的細切，但在實務上，切的過細會導致程式碼非常零碎難以閱讀，所以YC的建議是切到遵守「單一職責原理」就足夠了，與剛剛的建議一致，Interface一定要遵守「單一職責原理」，但是類別就盡力而為吧！</p>
</li>
<li>
<p>範例：剛剛玩具車公司的設計圖其實還是不夠好，如果今天公司想要開發新的車款C，添加新「方向盤」的功能，你會發現夢魘又再次的降臨，抽象類別<code>ToyCar</code>、<code>VirtualCar</code>、<code>Controller</code>都需要改變，而且就算真的把「方向盤」的相關方法添加上去，抽象類別也會開始出現多於一的職責，所以我們用Interface來重新改寫架構，如下圖所示。不難看出，控制馬達、控制速度、控制搖桿的行為是彼此依賴的，我們可以將他們的行為由Interface獨立拉出並相互依賴。</p>
</li>
</ul>
<p><img alt="toycar_3" src="https://www.ycc.idv.tw/media/SOLID_Introduction/toycar_3.png"></p>
<p>如此一來，當我們想要開發新的車款C，添加新「方向盤」的功能，也能輕鬆的擴充，如下所示。<code>ToyCarPlus</code>、<code>VirtualCarPlus</code>、<code>ControllerPlus</code>是我們實作C車款的抽象類別，它現在可以直接套用<code>IMotor</code>、<code>ISpeed</code>、<code>IControlBar</code>的Interface。</p>
<p><img alt="toycar_4" src="https://www.ycc.idv.tw/media/SOLID_Introduction/toycar_4.png"></p>
<h5><u>總結：物件導向的指導原則—SOLID</u></h5>
<p>上面介紹的六大原理：</p>
<ol>
<li>Single Responsibility Principl</li>
<li>Open-Closed Principle</li>
<li>Liskov Subsititution Principle</li>
<li>Law of Demeter</li>
<li>Interface Segregation Principle</li>
<li>Dependence Inversion Principle</li>
</ol>
<p>剛剛好組成SOLID這個單字，所以又被統稱SOLID原則。</p>
<p>事實上，這些原則所要達到的目的，不外乎就是我們<a href="http://www.ycc.idv.tw/YCNote/post/47">第一篇</a>當中所介紹的好的程式碼特性：「正常執行」、「穩健」、「不重複撰寫」、「可讀性」、「可擴展」，或者是「低耦合、高內聚」，所以寫程式時如果能時時注意，說不定你也可以自己領會這六大法則。</p>
<p>我來快速的總結這六大法則告訴我們的事：</p>
<ol>
<li>在開發程式的初期，先定義好抽象架構，也就是廣義的接口，徹底的使客戶端與業務邏輯分離，將「行為」定義成Interface，將「類別的泛化」定義成Abstract Class。</li>
<li>所有的實體類別都依賴於抽象，細節依賴於抽象。</li>
<li>每個單元盡量達到：單一權責、對延伸開放但對修改封閉、盡可能少的對外方法。</li>
<li>牽涉「繼承」，必須要問自己：子類可以替換父類執行嗎？父類是不是為子類的交集？</li>
<li>類別中的方法僅能訪問那些類別出現在自身、成員變數、方法的輸入和輸出參數中的。</li>
</ol>
<p>如此一來，我們心中就有一個準則去使用物件導向。</p>
<p>在一般情形下，這三篇的內容應該就足夠讓你寫出好的程式碼，但是實際面上使用仍然會碰到許多問題，於是乎有人將問題整理並總結出一些套路，這就是「設計模式」，我們以後再來談談吧！今天就先到這。</p>
<h5><u>Reference</u></h5>
<ol>
<li><a href="https://www.tenlong.com.tw/products/9789866761799">大話設計模式</a></li>
<li><a href="https://www.tenlong.com.tw/products/9787111437871">設計模式之禪</a></li>
</ol></dd>
                <dt>2018 / 4月 10</dt>
                <dd><a href="./introduction-object-oriented-programming_2.html">物件導向武功秘笈（2）：招式篇 — Python與Java的物件導向編程介紹</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>物件導向編程</u></h5>
<p><a href="http://www.ycc.idv.tw/YCNote/post/47">在上一章當中</a>，我們藉由好的程式碼的特性：「正常執行」、「穩健」、「不重複撰寫」、「可讀性」、「可擴展」，自然而然引出物件導向的概念。在這一章當中YC會接續介紹完整的物件導向要如何實現，包括物件導向三大特性：封裝、繼承和多型。</p>
<p>在本章我會採用兩種語言交叉作說明，一種是靜態型別的語言Java，另一種是動態型別的語言Python，這兩種語言都是可以實現物件導向的語言，而所謂型別的動態與靜態可以用一個簡單的方法來區分：型別檢查(Type Checking)發生在什麼時候？像Java這類的靜態型別語言，它的型別檢查是在編譯時期(Compile Time)完成的，而像是Python這類的動態型別語言，它的型別檢查則是在執行時期(Runtime)才去做，所以Python可以不事先宣告變數型別，這點使得Python在開發上方便許多。</p>
<p>雖然Python和Java都是支援物件導向的語言，但在使用上有很大的差異，首先，因為Python的動態型別，所以有些物件導向的性質對它來說就不是那麼重要，另外，因為Python追求簡潔，簡化了相當多的東西，所以很多的使用方法不同於傳統的物件導向，需要認識到這些差異才可以讓你使用Python的物件導向不會顯得很彆扭。Java是一套對物件導向支援非常完整的語言，而Python是一套易於快速開發的語言，使用兩種語言說明物件導向是為了讓讀者更能了解物件導向的本質，而非語言本身。</p>
<p>本篇採用『<a href="https://www.tenlong.com.tw/products/9789866761799">大話設計模式</a>』書中的物件導向篇範例。</p>
<h5><u>類別(Class)與物件(Object)</u></h5>
<p>首先來看物件導向的基本組成，類別(Class)與物件(Object)。
<em> 類別：建立物件的藍圖，描述所建立的物件共同的屬性和方法。
</em> 物件：一個自我包含的實體，物件包括屬性（Properties）和方法（Methods），屬性就是需要記憶的資訊，方法就是物件能夠提供的服務。</p>
<p>舉個例子，我想要創造一隻有名字的貓，她有喵喵叫的能力，在Java中可以寫成</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">class</span> <span class="nc">Cat</span> <span class="o">{</span>  <span class="c1">//{1}</span>
    <span class="kd">private</span> <span class="n">String</span> <span class="n">name</span><span class="o">;</span> <span class="c1">//{2}</span>

    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//{3}</span>
        <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span> <span class="c1">//{4}</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span> <span class="c1">//{5}</span>
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. meow~&quot;</span><span class="o">;</span> <span class="c1">//{6}</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Test</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//{7}</span>
        <span class="n">Cat</span> <span class="n">cat</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Cat</span><span class="o">(</span><span class="s">&quot;May&quot;</span><span class="o">);</span> <span class="c1">//{8}</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">cat</span><span class="o">.</span><span class="na">shout</span><span class="o">());</span> <span class="c1">//{9}</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="c1">// output:</span>
<span class="c1">// My name is May. meow~</span>
</pre></div>


<p>{1} 建構一個<code>Cat</code>的類別，類別不是物件，類別只是物件的藍圖。</p>
<p>{2} 建立一個私有變數<code>name</code>，用來代表貓的名字，我們使用<code>private</code>的修飾詞讓它是私有的，也就是說外部環境沒辦法去讀取到這個變數，只有物件內部才可以讀取的到</p>
<p>{3} 提供建造方法(constructor)來初始化這一個物件，初始化需要<code>name</code>的參數。</p>
<p>{4} 在初始化的過程中，我們會將從外部讀取的<code>name</code>存入私有變數<code>this.name</code>裡，在Java裡頭，如果外部變數名稱與本地變數名稱相同，需要使用<code>this</code>來特別區分。</p>
<p>{5} 創造一個公開的類別方法<code>shout()</code>。</p>
<p>{6} 使用私有變數<code>name</code>讓貓可以自我介紹，再發出喵喵叫的聲音。</p>
<p>{7} Java只要遇到<code>main</code>就會去執行，方法<code>main</code>具有靜態方法的修飾詞<code>static</code>，也就是說<code>Test</code>不需要被實體化也能執行<code>main</code>這個方法。</p>
<p>{8} 使用<code>new</code>來創造一個物件，在創造的過程會執行初始化，所以必須放入初始化需要的參數<code>name</code>，所以上面的新的物件有了<code>"May"</code>的名字。</p>
<p>{9} 接下來使用<code>cat.shout()</code>去執行喵喵叫的動作，這個方法會回傳字串，再利用<code>System.out.println</code>的方法將字串顯示出來。注意！在物件導向的習慣中，會用<code>.</code>來表示在那物件中的方法或屬性，所以<code>cat.shout()</code>就是執行在物件<code>cat</code>中的方法<code>shout()</code>。</p>
<p>再來看Python怎麼表示，</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">:</span> <span class="c1">#{1}</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">):</span> <span class="c1">#{2}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__name</span> <span class="o">=</span> <span class="n">name</span> <span class="c1">#{3}</span>

    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1">#{4}</span>
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="o">+</span><span class="s2">&quot;. meow~&quot;</span> <span class="c1">#{5}</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">cat</span> <span class="o">=</span> <span class="n">Cat</span><span class="p">(</span><span class="s2">&quot;May&quot;</span><span class="p">)</span> <span class="c1">#{6}</span>
    <span class="k">print</span><span class="p">(</span><span class="n">cat</span><span class="o">.</span><span class="n">shout</span><span class="p">())</span> <span class="c1">#{7}</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span> <span class="c1">#{8}</span>
    <span class="n">main</span><span class="p">()</span>

<span class="c1"># output:</span>
<span class="c1"># My name is May. meow~</span>
</pre></div>


<p>{1} 建構<code>Cat</code>的類別，這是Python3的表示方法，如果是使用Python2.7的話，要寫成<code>class Cat(object):</code>才可以。</p>
<p>{2} Python的初始化方法，Python在初始化之前會先自行執行<code>__new__</code>的方法，這個過程會產生一個新的物件，也就是實體化，而這個新的物件會以第一個參數的方法被帶入<code>__init__</code>的方法裡進行初始化，我們通常會命名這個變數為<code>self</code>，這裡的<code>self</code>已經是個物件而不是類別，那初始化的過程需要引入外部資訊<code>name</code>的參數來進行命名，所以第二個參數就要設<code>name</code>，記住喔！第一個參數是Python自動產生的，不是由外部帶入的，所以外部只要給<code>name</code>一個參數就足夠了。</p>
<p>{3} 創造一個私有本地變數<code>__name</code>來將<code>name</code>存入，在Python當中以雙底線<code>__</code>開頭的變數會被視為是「私有的」，效果和Java的<code>private</code>接近，不過Python並沒有這麼嚴格禁止外部去讀取私有變數，所以需要配合工程師的自我規範。</p>
<p>{4} 類別方法<code>shout()</code>，只要你不是靜態的類別方法，Python都會自動幫你帶入物件資訊當作第一個參數，通常命名為<code>self</code>，那為什麼靜態方法沒有自動帶入，因為靜態方法不用實體化，所以根本不擁有物件的資訊。</p>
<p>{5} 使用到本地的<code>self.__name</code>變數</p>
<p>{6} 創造一個物件，在創造的過程會執行初始化，所以必須放入初始化需要的參數<code>name</code>，所以上面的新的物件有了<code>"May"</code>的名字。</p>
<p>{7} 接下來使用<code>cat.shout()</code>去執行喵喵叫的動作，這個方法會回傳字串，再利用<code>print</code>的方法將字串顯示出來。注意！在物件導向的習慣中，會用<code>.</code>來表示在那物件中的方法或屬性，所以<code>cat.shout()</code>就是執行在物件<code>cat</code>中的方法<code>shout()</code>。</p>
<p>{8} 在Python程式執行時，它的<code>__name__</code>會是<code>"__main__"</code>，也就是說會去執行這個<code>if</code>判斷式下面的程式。</p>
<h5><u>方法多載（Method Overloading）</u></h5>
<p>物件導向允許「使用不同的參數形式去實現同一個方法」，這就稱之為方法多載，這個方法涵蓋一般方法和構造初始化方法。</p>
<p>來延伸剛剛的貓的例子，假設今天我們允許用戶不去設定貓咪的名字，而程式會預先給貓咪No-Name的預設值，所以我們需要另外一個初始化方法是不用貓咪名字的參數形式。</p>
<p>Java的實現程式碼如下所示，如此一來只要碰到沒有參數的形式，程式會給予<code>"No-Name"</code>的名字去當作貓咪的名字，並進行初始化。</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">class</span> <span class="nc">Cat</span> <span class="o">{</span>  
    <span class="kd">private</span> <span class="n">String</span> <span class="n">name</span><span class="o">;</span> 

    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span> 
        <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span> 
    <span class="o">}</span>
    <span class="c1">// method overloading</span>
    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">(</span><span class="s">&quot;No-Name&quot;</span><span class="o">);</span> <span class="c1">// given &quot;No-Name&quot; as its name</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span> 
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. meow~&quot;</span><span class="o">;</span> 
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Test</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span> 
        <span class="n">Cat</span> <span class="n">cat</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Cat</span><span class="o">();</span> <span class="c1">// no-argumant format</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">cat</span><span class="o">.</span><span class="na">shout</span><span class="o">());</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="c1">// output:</span>
<span class="c1">// My name is No-Name. meow~</span>
</pre></div>


<p>但在Python當中，不允許這種「相同方法名稱，卻又不同參數形式」，Python採用其他的方式來產生同樣的方法多載效果，如以下所示，我們可以看到Python使用default方法來實現多載，只要我們不給予<code>name</code>，它的default就是<code>"No-Name"</code>。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">:</span> 
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;No-Name&quot;</span><span class="p">):</span> <span class="c1"># name&#39;s default is &quot;No-Name&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__name</span> <span class="o">=</span> <span class="n">name</span> 

    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> 
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="o">+</span><span class="s2">&quot;. meow~&quot;</span> 

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">cat</span> <span class="o">=</span> <span class="n">Cat</span><span class="p">()</span> <span class="c1"># no-argument format</span>
    <span class="k">print</span><span class="p">(</span><span class="n">cat</span><span class="o">.</span><span class="n">shout</span><span class="p">())</span> 

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span> 
    <span class="n">main</span><span class="p">()</span>

<span class="c1"># output:</span>
<span class="c1"># My name is No-Name. meow~</span>
</pre></div>


<h5><u>物件導向三大特性—封裝(Encapsulation)</u></h5>
<p>還記得「低耦合，高內聚」的原則嗎？為了符合這原則，每個物件都要盡可能的去包含需要用到的屬性和方法，並且使得外部不能以不合理的方法去影響物件，這就稱之為「封裝」。</p>
<p>我們來看看上次的成果，我們就用這個例子來說明「封裝」。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">class</span> <span class="nc">Calculation</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">nums</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span> <span class="o">=</span> <span class="n">nums</span> <span class="c1">#{1}</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__checkPositiveInteger</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__checkPositiveInteger</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span> <span class="c1">#{2}</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="n">num</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid positive integer: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__primeFactorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span> <span class="c1">#{3}</span>
        <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">while</span><span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">num</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">prime_factorize</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">num</span> <span class="o">/=</span> <span class="n">i</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">prime_factorize</span>

    <span class="k">def</span> <span class="nf">findGCF</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span><span class="p">:</span>
            <span class="n">prime_factorize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__primeFactorize</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

        <span class="n">common_prime</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">prime_factorize</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">common_prime</span> <span class="o">&amp;=</span> <span class="nb">set</span><span class="p">(</span><span class="n">pf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="n">gcf</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">prime</span> <span class="ow">in</span> <span class="n">common_prime</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>
            <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">prime_factorize</span><span class="p">:</span>
                <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">pf</span><span class="p">[</span><span class="n">prime</span><span class="p">])</span>
            <span class="n">gcf</span> <span class="o">=</span> <span class="n">gcf</span> <span class="o">*</span> <span class="p">(</span><span class="n">prime</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">gcf</span>

    <span class="k">def</span> <span class="nf">findLCM</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">gcf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">findGCF</span><span class="p">()</span>
        <span class="n">lcm</span> <span class="o">=</span> <span class="n">gcf</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span><span class="p">:</span>
            <span class="n">lcm</span> <span class="o">*=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num</span><span class="o">/</span><span class="n">gcf</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lcm</span>
</pre></div>


<p>{1} 使用私有變數，讓外部不能任意的改變<code>self.__name</code>變數，在這個例子當中，如果<code>self.__name</code>被任意改變，它將會逃過<code>__checkPositiveInteger</code>的檢查。
{2}&amp;{3} 不需要由外部讀取的方法，就盡量讓它是私有的。</p>
<p>再回到貓咪的這個例子，如果我們想要可以調控「叫聲次數」的話，可以這樣實現。</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">class</span> <span class="nc">Cat</span> <span class="o">{</span>
    <span class="kd">private</span> <span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">(</span><span class="s">&quot;No-Name&quot;</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">private</span> <span class="kt">int</span> <span class="n">shout_num</span> <span class="o">=</span> <span class="mi">3</span><span class="o">;</span> <span class="c1">//{1}</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getShoutNum</span><span class="o">()</span> <span class="o">{</span> <span class="k">return</span> <span class="n">shout_num</span><span class="o">;</span> <span class="o">}</span> <span class="c1">//{2}</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setShoutNum</span><span class="o">(</span><span class="kt">int</span> <span class="n">num</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//{3}</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="k">throw</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">IllegalArgumentException</span><span class="o">();</span>
        <span class="n">shout_num</span> <span class="o">=</span> <span class="n">num</span><span class="o">;</span> 
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">String</span> <span class="n">result</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">shout_num</span><span class="o">;</span> <span class="n">i</span><span class="o">++){</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s">&quot;meow~ &quot;</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Test</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">Cat</span> <span class="n">cat</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Cat</span><span class="o">(</span><span class="s">&quot;May&quot;</span><span class="o">);</span>
        <span class="n">cat</span><span class="o">.</span><span class="na">setShoutNum</span><span class="o">(</span><span class="mi">5</span><span class="o">);</span> <span class="c1">//{4}</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">cat</span><span class="o">.</span><span class="na">shout</span><span class="o">());</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="c1">// output:</span>
<span class="c1">// My name is May. meow~ meow~ meow~ meow~ meow~</span>
</pre></div>


<p>{1} 設置私有變數<code>shout_num</code>來決定叫聲次數。</p>
<p>{2} 為了做到封裝，外部不能直接去讀取<code>shout_num</code>，而是經由<code>getShoutNum</code>的外部方法來得到叫聲次數，這個<code>getXXX</code>的形式在物件導向裡頭被稱為Getter。</p>
<p>{3} 為了做到封裝，外部不能直接去改變<code>shout_num</code>，而是經由<code>setShoutNum</code>的外部方法來以合理的方法改變叫聲次數，在這個方法中，我們會先檢查再設定，如果是直接的改變<code>shout_num</code>將會少了這一份檢查，這個<code>setXXX</code>的形式在物件導向裡頭被稱為Setter。</p>
<p>{4} 使用Setter方法由外部來改變叫聲次數。</p>
<p>在Python中，Getter和Setter被簡化了。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;No-Name&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__shout_num</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="nd">@property</span>  <span class="c1">#{1}</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__shout_num</span>

    <span class="nd">@shoutNum.setter</span>  <span class="c1">#{2}</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__shout_num</span> <span class="o">=</span> <span class="n">num</span>

    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__shout_num</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s2">&quot;meow~ &quot;</span>
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="o">+</span><span class="s2">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">cat</span> <span class="o">=</span> <span class="n">Cat</span><span class="p">(</span><span class="s2">&quot;May&quot;</span><span class="p">)</span>
    <span class="n">cat</span><span class="o">.</span><span class="n">shout_num</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1">#{3}</span>
    <span class="k">print</span><span class="p">(</span><span class="n">cat</span><span class="o">.</span><span class="n">shout</span><span class="p">())</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

<span class="c1"># output:</span>
<span class="c1"># My name is May. meow~ meow~ meow~ meow~ meow~</span>
</pre></div>


<p>{1} Python使用Decorator<code>@property</code>來創造Getter，一旦加上了<code>@property</code>，當下的函數方法就會變成一種性質。</p>
<p>{2} 再使用<code>shout_num.setter</code>來替<code>shout_num</code>這個特性加上Setter。</p>
<p>{3} 然後我們就可以以像是修改一般變數的方式來修改<code>shout_num</code>，但實際上<code>shout_num</code>是有被封裝的，如此一來就可以更為簡潔，不用去寫<code>getXX</code>和<code>setXXX</code>等囉唆的寫法。</p>
<h5><u>物件導向三大特性—繼承(Inheritance)</u></h5>
<p>還記得「Don't Repeat Yourself」原則嗎？物件導向同樣提供了這個選項，「繼承」可以讓子類擁有父類的屬性和方法，避免不必要的重寫，但同時也會增加父類和子類之間的耦合，所以使用時要去評估它影響了多少耦合性。</p>
<p>子類可以先繼承父類的屬性和方法，再去新增屬於子類自己的屬性和方法，甚至還可以去覆寫父類的方法，這稱之為方法覆寫(Method Overriding)，有了這些方法，子類可以在不重複撰寫父類方法的情況下，去增加自己的特色和自己的功能。</p>
<p>依循著剛剛的例子，如果我們今天想要增加狗的類別，但是又不想重複撰寫相同的部分，所以我們可以選擇創造動物的類別，再讓貓和狗繼承自動物。</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">class</span> <span class="nc">Animal</span> <span class="o">{</span>
    <span class="kd">protected</span> <span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span> <span class="c1">//{1}</span>

    <span class="kd">public</span> <span class="nf">Animal</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="nf">Animal</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">(</span><span class="s">&quot;No-Name&quot;</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">protected</span> <span class="kt">int</span> <span class="n">shout_num</span> <span class="o">=</span> <span class="mi">3</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getShoutNum</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">shout_num</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setShoutNum</span><span class="o">(</span><span class="kt">int</span> <span class="n">num</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="k">throw</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">IllegalArgumentException</span><span class="o">();</span>
        <span class="n">shout_num</span> <span class="o">=</span> <span class="n">num</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">class</span> <span class="nc">Cat</span> <span class="kd">extends</span> <span class="n">Animal</span><span class="o">{</span>
    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">(</span><span class="n">name</span><span class="o">);</span> <span class="c1">//{2}</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="nf">Cat</span><span class="o">()</span> <span class="o">{</span>
        <span class="kd">super</span><span class="o">();</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">String</span> <span class="n">result</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">shout_num</span><span class="o">;</span> <span class="n">i</span><span class="o">++){</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s">&quot;meow~ &quot;</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="kd">class</span> <span class="nc">Dog</span> <span class="kd">extends</span> <span class="n">Animal</span><span class="o">{</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">String</span> <span class="n">result</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">shout_num</span><span class="o">;</span> <span class="n">i</span><span class="o">++){</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s">&quot;woof~ &quot;</span><span class="o">;</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>


<p>{1} <code>protected</code>的效果和<code>private</code>一樣，讓外部無法讀取到內部的私有化，但是<code>private</code>無法被「繼承」，而<code>protected</code>可以被繼承，所以如果希望可以被繼承的私有變數或方法，就使用<code>protected</code>。</p>
<p>{2} <code>super</code>指的是父類，這裡我們使用父類來做初始化，事實上這邊可以不用再初始化一次，子類本身就會繼承父類的初始化方法，所以可以像<code>Dog</code>一樣省略不寫。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="k">class</span> <span class="nc">Animal</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;No-Name&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1">#{1}</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span>
    <span class="nd">@shout_num.setter</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span> <span class="o">=</span> <span class="n">num</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;No_Name&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>  <span class="c1">#{2}</span>

    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s2">&quot;meow~ &quot;</span>
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="o">+</span><span class="s2">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span>
<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="s2">&quot;woof~ &quot;</span>
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="o">+</span><span class="s2">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span>
</pre></div>


<p>{1} Python的<code>protected</code>使用單底線<code>_</code>開頭表示。</p>
<p>{2} <code>super</code>指的是父類，這裡我們使用父類來做初始化，事實上這邊可以不用再初始化一次，子類本身就會繼承父類的初始化方法，所以可以像<code>Dog</code>一樣省略不寫。</p>
<h5><u>抽象化：抽象類別(Abstract Class)、抽象方法(Abstract Method)和接口(Interface)</u></h5>
<p>事實上，剛剛使用<code>Animal</code>的方法並不是很正確，我們將<code>Animal</code>當作一個類別處理，所以<code>Animal</code>其實是可以被實例化的，但是<code>Animal</code>根本沒有什麼有用的方法，它必須被繼承後再添加方法才有用處，所以我們其實可以把<code>Animal</code>抽象化，將<code>Animal</code>視為抽象類別，其中擁有一些方法需要在子類實現的，稱為抽象方法，我們直接看怎麼做。</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">Animal</span> <span class="o">{</span> <span class="c1">//{1}</span>
    <span class="kd">protected</span> <span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">Animal</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="nf">Animal</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">(</span><span class="s">&quot;No-Name&quot;</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">protected</span> <span class="kt">int</span> <span class="n">shout_num</span> <span class="o">=</span> <span class="mi">3</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getShoutNum</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">shout_num</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setShoutNum</span><span class="o">(</span><span class="kt">int</span> <span class="n">num</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="k">throw</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">IllegalArgumentException</span><span class="o">();</span>
        <span class="n">shout_num</span> <span class="o">=</span> <span class="n">num</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span> <span class="c1">//{2}</span>
        <span class="n">String</span> <span class="n">result</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">shout_num</span><span class="o">;</span> <span class="n">i</span><span class="o">++){</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">getShoutSound</span><span class="o">()+</span><span class="s">&quot; &quot;</span><span class="o">;</span> <span class="c1">//{3}</span>
        <span class="o">}</span>
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">abstract</span> <span class="kd">protected</span> <span class="n">String</span> <span class="nf">getShoutSound</span><span class="o">();</span> <span class="c1">//{4}</span>
<span class="o">}</span>

<span class="kd">class</span> <span class="nc">Cat</span> <span class="kd">extends</span> <span class="n">Animal</span><span class="o">{</span>
    <span class="kd">protected</span> <span class="n">String</span> <span class="nf">getShoutSound</span><span class="o">()</span> <span class="o">{</span> <span class="c1">//{5}</span>
        <span class="k">return</span> <span class="s">&quot;meow~&quot;</span><span class="o">;</span> 
    <span class="o">}</span>
<span class="o">}</span>
<span class="kd">class</span> <span class="nc">Dog</span> <span class="kd">extends</span> <span class="n">Animal</span><span class="o">{</span>
    <span class="kd">protected</span> <span class="n">String</span> <span class="nf">getShoutSound</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="s">&quot;woof~&quot;</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>


<p>{1} 使用<code>abstract class</code>修飾詞來創建抽象類別，只有在抽象類別中才可以擁有抽象方法，抽象類別不能直接被實例化。</p>
<p>{2} 抽象類別也可以有一般的具體方法。</p>
<p>{3} 這裡使用的<code>getShoutSound()</code>方法要等在子類才會被實現。</p>
<p>{4} 使用<code>abstract</code>設置抽象方法，繼承自抽象類別的子類必須要完全實現所有的抽象方法。</p>
<p>{5} 實現抽象方法。</p>
<p>在Python中沒有原生的抽象類別和方法，必須<code>import abc</code>。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="kn">import</span> <span class="nn">abc</span>
<span class="k">class</span> <span class="nc">Animal</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span> <span class="c1">#{1}</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;No-Name&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span>
    <span class="nd">@shout_num.setter</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span> <span class="o">=</span> <span class="n">num</span>

    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getShoutSound</span><span class="p">()</span><span class="o">+</span><span class="s2">&quot; &quot;</span>
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="o">+</span><span class="s2">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span>  
    <span class="nd">@abc.abstractmethod</span>  <span class="c1">#{2}</span>
    <span class="k">def</span> <span class="nf">_getShoutSound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_getShoutSound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1">#{3}</span>
        <span class="k">return</span> <span class="s2">&quot;meow~&quot;</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_getShoutSound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;woof~&quot;</span>
</pre></div>


<p>{1} 繼承<code>abc.ABC</code>來建立抽象類別。</p>
<p>{2} 使用<code>@abc.abstractmethod</code>來建立抽象方法。</p>
<p>{3} 實現抽象方法。</p>
<p>還有一種類型抽象化的更為徹底，稱之為「接口」，「接口」上的所有方法都是抽象未實現的，「接口」不能擁有任何具體的方法。雖然「接口」很像是完全抽象化的「抽象類別」，也確實可以利用「抽象類別」來創造「接口」，但是兩者的意義是不同的，「抽象類別」是從子類中發現共通的東西，而泛化出現的，但是「接口」可以根本不預先知道子類是什麼，而僅僅事先定義行為本身，換句話說，「抽象類別」是類別的抽象化，而「接口」則是行為的抽象化。</p>
<p>例如，我想要讓某些動物擁有「飛」的能力，這是一個行為，而不會事先知道它會套用到哪一個類別上面。</p>
<p>在Java之中只允許單一繼承，但是卻可以有多個「接口」；而Python沒有現成的「接口」可以使用，我們必須使用「抽象方法」來創造「接口」，所以開發者要謹記「接口」的限制：不能有任何的具體方法，因為Python允許多重繼承，所以就可以直接將模擬「接口」的抽象類別直接疊加上去。</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">interface</span> <span class="nc">IFly</span> <span class="o">{</span> <span class="c1">//{1}</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="nf">flyTo</span><span class="o">(</span><span class="n">String</span> <span class="n">place</span><span class="o">);</span> <span class="c1">//{2}</span>
<span class="o">}</span>
<span class="kd">class</span> <span class="nc">FlyingCat</span> <span class="kd">extends</span> <span class="n">Cat</span> <span class="kd">implements</span> <span class="n">IFly</span> <span class="o">{</span> <span class="c1">//{3}</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="nf">flyTo</span><span class="o">(</span><span class="n">String</span> <span class="n">place</span><span class="o">)</span> <span class="o">{</span> <span class="c1">//{4}</span>
        <span class="k">return</span> <span class="n">shout</span><span class="o">()+</span><span class="s">&quot; I&#39;m going to fly to &quot;</span><span class="o">+</span><span class="n">place</span><span class="o">+</span><span class="s">&quot;.&quot;</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Test</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">FlyingCat</span> <span class="n">cat</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FlyingCat</span><span class="o">(</span><span class="s">&quot;May&quot;</span><span class="o">);</span>
        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">cat</span><span class="o">.</span><span class="na">flyTo</span><span class="o">(</span><span class="s">&quot;Taiwan&quot;</span><span class="o">));</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="c1">// output: </span>
<span class="c1">// My name is May. meow~ meow~ meow~ I&#39;m going to fly to Taiwan.</span>
</pre></div>


<p>{1} 使用<code>interface</code>創建「接口」，我們習慣會使用開頭大寫I來表示Interface(接口)。</p>
<p>{2} 「接口」定義未實現的抽象方法<code>flyTo</code>。</p>
<p>{3} <code>FlyingCat</code>繼承自<code>Cat</code>並且裝上<code>IFly</code>的「接口」。</p>
<p>{4} 必須實現「接口」上所有的抽象方法。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="kn">import</span> <span class="nn">abc</span>
<span class="k">class</span> <span class="nc">IFly</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span> <span class="c1">#{1}</span>
    <span class="nd">@abc.abstractmethod</span> <span class="c1">#{2}</span>
    <span class="k">def</span> <span class="nf">flyTo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">place</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">class</span> <span class="nc">FlyingCat</span><span class="p">(</span><span class="n">Cat</span><span class="p">,</span><span class="n">IFly</span><span class="p">):</span> <span class="c1">#{3}</span>
    <span class="k">def</span> <span class="nf">flyTo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">place</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shout</span><span class="p">()</span><span class="o">+</span><span class="s2">&quot; I&#39;m going to fly to &quot;</span><span class="o">+</span><span class="n">place</span><span class="o">+</span><span class="s2">&quot;.&quot;</span><span class="p">;</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">cat</span> <span class="o">=</span> <span class="n">FlyingCat</span><span class="p">(</span><span class="s2">&quot;May&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">cat</span><span class="o">.</span><span class="n">fly</span><span class="p">(</span><span class="s2">&quot;Taiwan&quot;</span><span class="p">))</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

<span class="c1"># output: </span>
<span class="c1"># My name is May. meow~ meow~ meow~ I&#39;m going to fly to Taiwan.</span>
</pre></div>


<p>{1} 使用抽象類別來創造「接口」。</p>
<p>{2} 要注意！「接口」裡頭不能有具體方法。</p>
<p>{3} 直接使用多重繼承，將<code>IFly</code>安裝上去。</p>
<h5><u>物件導向三大特性—多型(Polymorphism)</u></h5>
<p>最後，來講講物件導向的最後一個特性，那就是「多型」。「多型」的涵義是指「子類可以以父類的身分出現」，而因為是以父類的角色出現，所以只能執行父類擁有的方法，也就是只能執行這些子類共同泛化分享的方法，當然不同的子類實現後的效果會不一樣，不然使用「多型」的意義就不大了，至於子類自己的特殊方法則不可以使用「多型」去執行。</p>
<p>直接來看範例，假設今天我要邀請三隻貓貓狗狗來參加叫聲比賽，分別請他們叫個幾聲來聽聽，此時就需要使用到「多型」的方法。</p>
<div class="highlight"><pre><span></span><span class="cm">/* Java */</span>

<span class="kd">abstract</span> <span class="kd">class</span> <span class="nc">Animal</span> <span class="o">{</span> 
    <span class="kd">protected</span> <span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">Animal</span><span class="o">(</span><span class="n">String</span> <span class="n">name</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="nf">Animal</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">(</span><span class="s">&quot;No-Name&quot;</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="kd">protected</span> <span class="kt">int</span> <span class="n">shout_num</span> <span class="o">=</span> <span class="mi">3</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getShoutNum</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">shout_num</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setShoutNum</span><span class="o">(</span><span class="kt">int</span> <span class="n">num</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="k">throw</span> <span class="k">new</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">IllegalArgumentException</span><span class="o">();</span>
        <span class="n">shout_num</span> <span class="o">=</span> <span class="n">num</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="nf">shout</span><span class="o">()</span> <span class="o">{</span> 
        <span class="n">String</span> <span class="n">result</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">shout_num</span><span class="o">;</span> <span class="n">i</span><span class="o">++){</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="n">getShoutSound</span><span class="o">()+</span><span class="s">&quot; &quot;</span><span class="o">;</span> 
        <span class="o">}</span>
        <span class="k">return</span> <span class="s">&quot;My name is &quot;</span><span class="o">+</span><span class="n">name</span><span class="o">+</span><span class="s">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="kd">abstract</span> <span class="kd">protected</span> <span class="n">String</span> <span class="nf">getShoutSound</span><span class="o">();</span> 
<span class="o">}</span>

<span class="kd">class</span> <span class="nc">Cat</span> <span class="kd">extends</span> <span class="n">Animal</span><span class="o">{</span>
    <span class="kd">protected</span> <span class="n">String</span> <span class="nf">getShoutSound</span><span class="o">()</span> <span class="o">{</span> 
        <span class="k">return</span> <span class="s">&quot;meow~&quot;</span><span class="o">;</span> 
    <span class="o">}</span>
<span class="o">}</span>
<span class="kd">class</span> <span class="nc">Dog</span> <span class="kd">extends</span> <span class="n">Animal</span><span class="o">{</span>
    <span class="kd">protected</span> <span class="n">String</span> <span class="nf">getShoutSound</span><span class="o">()</span> <span class="o">{</span>
        <span class="k">return</span> <span class="s">&quot;woof~&quot;</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">ShoutGame</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">Animal</span><span class="o">[]</span> <span class="n">arrayAnimal</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Animal</span><span class="o">[</span><span class="mi">3</span><span class="o">];</span> <span class="c1">//{1}</span>
        <span class="c1">// polymorphism</span>
        <span class="n">arrayAnimal</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Cat</span><span class="o">(</span><span class="s">&quot;May&quot;</span><span class="o">);</span> <span class="c1">//{2}</span>
        <span class="n">arrayAnimal</span><span class="o">[</span><span class="mi">1</span><span class="o">]</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Dog</span><span class="o">(</span><span class="s">&quot;Linda&quot;</span><span class="o">);</span>
        <span class="n">arrayAnimal</span><span class="o">[</span><span class="mi">2</span><span class="o">]</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Cat</span><span class="o">(</span><span class="s">&quot;Joy&quot;</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">Animal</span> <span class="n">animal</span><span class="o">:</span> <span class="n">arrayAnimal</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">animal</span><span class="o">.</span><span class="na">shout</span><span class="o">());</span> <span class="c1">//{3}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
<span class="c1">// output: </span>
<span class="c1">// My name is May. meow~ meow~ meow~</span>
<span class="c1">// My name is Linda. woof~ woof~ woof~</span>
<span class="c1">// My name is Joy. meow~ meow~ meow~</span>
</pre></div>


<p>{1} 創建<code>Animal</code>的Array，Animal是抽象類別不能實體化，這裡預定要放的是它的繼承實現類別。</p>
<p>{2} 將<code>Cat</code>和<code>Dog</code>任意放到<code>Animal</code>的Array是可以的，此時就套用「多型」，不管是<code>Cat</code>和<code>Dog</code>都是以<code>Animal</code>的形式出現，只能執行<code>Animal</code>有的方法。</p>
<p>{3} <code>shout()</code>是父類<code>Animal</code>有的方法，可以被執行。</p>
<p>而在Python當中，「多型」就沒這麼重要了，因為Python具有「鴨子型別」（Duck Typing），什麼是「鴨子型別」呢？有一句話道出它的意義：「當看到一隻鳥走起來像鴨子、游泳起來像鴨子、叫起來也像鴨子，那麼這隻鳥就可以被稱為鴨子」，因為Python是動態型別的語言，變數型態不需要事先宣告，所以一個變數具有彈性可以放入任意型別，直到出現不合適的使用方法，才會報錯，所以在Python中變數可以任意放入不同的類別的物件，只要確保這些類別都具有這些變數所需要用到的方法，就可以了，這不正是接近「多型」的概念。</p>
<div class="highlight"><pre><span></span><span class="c1">### Python3.4</span>

<span class="kn">import</span> <span class="nn">abc</span>
<span class="k">class</span> <span class="nc">Animal</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span> 
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;No-Name&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span>
    <span class="nd">@shout_num.setter</span>
    <span class="k">def</span> <span class="nf">shout_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span> <span class="o">=</span> <span class="n">num</span>

    <span class="k">def</span> <span class="nf">shout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shout_num</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_getShoutSound</span><span class="p">()</span><span class="o">+</span><span class="s2">&quot; &quot;</span>
        <span class="k">return</span> <span class="s2">&quot;My name is &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="o">+</span><span class="s2">&quot;. &quot;</span><span class="o">+</span><span class="n">result</span>  
    <span class="nd">@abc.abstractmethod</span>
    <span class="k">def</span> <span class="nf">_getShoutSound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="k">class</span> <span class="nc">Cat</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_getShoutSound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;meow~&quot;</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">Animal</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_getShoutSound</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;woof~&quot;</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Shout Game</span>
    <span class="n">arrayAnimal</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#{1}</span>
    <span class="n">arrayAnimal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Cat</span><span class="p">(</span><span class="s2">&quot;May&quot;</span><span class="p">))</span> 
    <span class="n">arrayAnimal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Dog</span><span class="p">(</span><span class="s2">&quot;Linda&quot;</span><span class="p">))</span>
    <span class="n">arrayAnimal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Cat</span><span class="p">(</span><span class="s2">&quot;Joy&quot;</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">animal</span> <span class="ow">in</span> <span class="n">arrayAnimal</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">animal</span><span class="p">,</span><span class="n">Animal</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">TypeError</span> <span class="c1">#not necessary #{2}</span>
        <span class="k">print</span><span class="p">(</span><span class="n">animal</span><span class="o">.</span><span class="n">shout</span><span class="p">())</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

<span class="c1"># output: </span>
<span class="c1"># My name is May. meow~ meow~ meow~</span>
<span class="c1"># My name is Linda. woof~ woof~ woof~</span>
<span class="c1"># My name is Joy. meow~ meow~ meow~</span>
</pre></div>


<p>{1} 要存入多型的List不需要特別處理。</p>
<p>{2} 可以檢查是不是繼承自<code>Animal</code>，以確保多型的嚴格定義，但這個過程是非必要的。</p>
<h5><u>總結：物件導向使用方法</u></h5>
<p>好！我們花了好大的力氣，終於了解如何在Java和Python中使用物件導向。從一開始的「類別」和「物件」講起，再來談到物件導向的三大特性：「封裝」、「繼承」和「多型」，還談到方法可以「多載」也可以「覆寫」，以及一些抽象化的東西，包括「抽象類別」、「抽象方法」和「接口」。</p>
<p>但是等等！你知道該怎麼運用這些技巧嗎？沒錯，僅僅是了解這些招式不足以讓你寫出卓越的程式碼，你還需要了解如何使用，就像是外功招式還得配合內功才可以是一套完整的功夫，否則只是半吊子而已，我們將在下一章節中來帶大家了解如何去使用這些招式。</p></dd>
                <dt>2018 / 4月 05</dt>
                <dd><a href="./introduction-object-oriented-programming_1.html">物件導向武功秘笈（1）：認知篇 — 什麼是好的程式？</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>物件導向為何重要？</u></h5>
<p>我相信很多朋友一定像YC我一樣，想要學某個程式語言，就去買那個程式語言的簡介書籍，然後一章一章的唸下去，這種書通常會先教變數怎麼設定？然後再教if、while、for、function等程式邏輯。</p>
<p>那如果你學的是「物件導向」的語言，譬如：Java、C++、Python，接下來的章節就會開始介紹「類別」、「物件」等等難懂的東西，然後就會陷入一種霧煞煞的狀態，然後心中就會出現一種聲音：為什麼寫個程式你跟我扯什麼「物件」？我原本用前面所學的方法就可以完成所有事情啦！為何要把事情弄的這麼複雜？這東西到底有什麼好處啊？</p>
<p>YC一開始也是充滿著疑惑，然後一知半解的就把這些定義記在心中，然後天真的認為「物件導向」只是讓程式比較整齊的方法罷了！直到後來學了資料結構與演算法，然後又學了一點設計模式，然後又有過幾個大型軟體開發的經驗，一路走過才漸漸的了解「物件導向」是怎麼一回事？</p>
<p>所以我打算把這些收穫用三篇文章來說明，好讓讀者們可以少走一點冤枉路，在第一篇中，也就是本篇，我會帶大家認識好的程式是長什麼樣子的，它擁有什麼樣的特點，有了正確的認知，除了可以讓我們避免寫出糟糕的程式之外，我們也才能漸漸的認識到「物件導向」為何重要。</p>
<h5><u>程式的好壞？</u></h5>
<p>一開始，我們必須要對程式培養出鑑賞能力，我曾經聽過電視上有一位歌唱老師說過：「好的歌手必須先練他的聽力」，我覺得相同的，一個好的Programmer要先培養出對於程式的鑑賞能力。</p>
<p>首先，一個好的程式當然要「能正常執行」，要能滿足客戶的需求，這是基本款，所以一般而言我們會使用很多的測試去看看程式是否可以正常運作，我們會找一些一般的條件來測試，我們也會找一些合法但是位於極端條件的例子，也就是邊界條件（Edge Case）來測試，或者找一些不合法的例子試試程式是否可以排除錯誤條件。</p>
<p>測試可以即早的發現Bug，即早的治療，如果真的發現有Bug的話，接下來就是去找出Bug的源頭，這可就相當的困難，這裡想像一下喔！如果你的程式總共有1000行，而當你測試時發現有Bug，那想從這麼多行當中找出Bug的來源是相當困難的，所以好的方法是這樣的，先將一個大任務分解成為幾個小任務，然後完成這幾個小任務後，逐一的進行測試，稱之為「單元測試」，最後在將這些測試完成的小任務組合成為大任務，然後再做最後的總測試，這麼一來就可以避免在大範圍中找尋Bug，又可以做到對程式從裡到外的完整測試以達到程式「能正常執行」的目的。</p>
<p>這裡提出一個問題讓大家思考，究竟要使用什麼方法去解析問題？讓我們可以有條理的拆解出小「單元」，來組合出最後的目標，有沒有一個系統化的思考方法？</p>
<p>第二點，一個好的程式必須是「穩健的」(Robust)，程式原本能用的功能，不會因為更新、不會因為添加新功能，就出現錯誤！要做到這一點，除了剛剛說的「單元」拆分以外，還要讓「單元」和「單元」之間不會有太多的彼此影響，這麼一來在原先的功能所調用的「單元」不被動到的前提下，我還可以新增新的功能，才能做到「穩健的」特質。</p>
<p>第三點，一個好的程式必須具備「不重複撰寫」的特性，有一句經典的法則叫做「Don't Repeat Yourself」，不要去重複寫已經寫過的程式碼，如果是重複需要用到的「單元」我們就把它獨立出來，讓其他程式去調用它，對於工程師來說，「不重複撰寫」意味著可以少寫一點程式碼，增加開發的速度，更重要的是，調用公享的程式碼可以讓程式更有邏輯，更具一致性，能夠減少出錯的可能性。</p>
<p>第四點，好的程式要具有「可讀性」，軟體開發常常是長時間、多人合作、龐大的程式碼，如果程式碼沒有具備清晰的邏輯、沒有在該註解的部分寫清楚、沒有一個統一的規範，這樣的開發終就會陷入泥坑，永遠解不完的Bug會不斷的出現，解了一個又產生一個，永無止盡的輪迴，而且最慘的是完全不清楚真正的源頭在哪裡，這可是軟體工程師的夢魘啊！</p>
<p>第五點，一個好的程式要具備「可擴展」，工程師最討厭的一句話應該就是客戶說：「我突然想到我還需要XXX功能，這只是在這邊再多一點而已，應該不難吧！」呵呵～通常「這多一點」就要大大的修改整個程式碼，弄不好還可能把原本的功能給搞壞，所以工程師應該在設計的一開始就考慮到會有什麼潛在需要更改的部分，而先採取因應措施，好讓程式易於擴展，好讓自己不會因此而加班！</p>
<h5><u>低耦合、高內聚</u></h5>
<p>再重複一次，一個好的程式要具備「正常執行」、「穩健」、「不重複撰寫」、「可讀性」、「可擴展」的特性，請將這些原則記在心裡，隨時的檢視自己的程式是不是有違反這些規則。</p>
<p>而剛剛我們有了一個大致的想法：將任務分成幾個小的「單元」是一個很好的策略，而為了讓程式「穩健」，這些「單元」之間不能有太多的相依性；但是站在另外一個角度看，為了讓程式「不重複撰寫」，我們需要讓一個「單元」使用另外一個「單元」，好讓工程師可以做到「Don't Repeat Yourself」，如此一來則是增加了「單元」間的相依性，這兩者是一個Trade-off。</p>
<p>有關「單元」的相依性有兩個重要術語—耦合性(Coupling)和聚合性(Cohesion)，耦合性指的是「單元」和「單元」之間資訊或參數依賴的程度，所以我們要追求「低耦合」。聚合性指的是「單元」內使用到自身資訊或參數的程度，所以我們要追求「高內聚」，通常「低耦合」都會伴隨著「高內聚」。</p>
<h5><u>程式碼精練之旅</u></h5>
<p>來看個例子，假設今天我想要實現一個求最大公因數的計算機，使用<strong>Python</strong>隨便寫一段程式碼可能是這樣的。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">str_numA</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer A: &quot;</span><span class="p">)</span>
    <span class="n">str_numB</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer B: &quot;</span><span class="p">)</span>

    <span class="n">numA</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numA</span><span class="p">)</span>
    <span class="n">numB</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numB</span><span class="p">)</span>

    <span class="n">prime_factorize_A</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span><span class="p">(</span><span class="n">numA</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">numA</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prime_factorize_A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize_A</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">numA</span> <span class="o">/=</span> <span class="n">i</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">prime_factorize_B</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span><span class="p">(</span><span class="n">numB</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">numB</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prime_factorize_B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize_B</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">numB</span> <span class="o">/=</span> <span class="n">i</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>    

    <span class="n">common_prime</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize_A</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize_B</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">gcf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">prime</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">common_prime</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">prime_factorize_A</span><span class="p">[</span><span class="n">prime</span><span class="p">],</span><span class="n">prime_factorize_B</span><span class="p">[</span><span class="n">prime</span><span class="p">])</span>
        <span class="n">gcf</span> <span class="o">=</span> <span class="n">gcf</span> <span class="o">*</span> <span class="p">(</span><span class="n">prime</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Greatest Common Factor: &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gcf</span><span class="p">))</span>
</pre></div>


<p>好！那接下來用剛剛的規則來檢視看看這個程式，第一點，有沒有「可正常執行」？上述的例子，沒有考慮到一些Edge Case，當輸入的值不是正整數，必須要報錯，所以我們將程式修改一下。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">str_numA</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer A: &quot;</span><span class="p">)</span>
    <span class="n">str_numB</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer B: &quot;</span><span class="p">)</span>

    <span class="n">numA</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numA</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">numA</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid positive integer: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">numA</span><span class="p">))</span>
    <span class="n">numB</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numB</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">numB</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid positive integer: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">numB</span><span class="p">))</span>

    <span class="n">prime_factorize_A</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span><span class="p">(</span><span class="n">numA</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">numA</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prime_factorize_A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize_A</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">numA</span> <span class="o">/=</span> <span class="n">i</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">prime_factorize_B</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span><span class="p">(</span><span class="n">numB</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">numB</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prime_factorize_B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize_B</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">numB</span> <span class="o">/=</span> <span class="n">i</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>    

    <span class="n">common_prime</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize_A</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize_B</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">gcf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">prime</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">common_prime</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">prime_factorize_A</span><span class="p">[</span><span class="n">prime</span><span class="p">],</span><span class="n">prime_factorize_B</span><span class="p">[</span><span class="n">prime</span><span class="p">])</span>
        <span class="n">gcf</span> <span class="o">=</span> <span class="n">gcf</span> <span class="o">*</span> <span class="p">(</span><span class="n">prime</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Greatest Common Factor: &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gcf</span><span class="p">))</span>
</pre></div>


<p>再來檢查一下是不是具有「不重複撰寫」的特性？也就是Don't Repeat Yourself，顯然是沒有遵守，<code>numA</code>和<code>numB</code>處理方法幾乎一模一樣，這會造成程式碼很冗長，來稍做修改。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">checkPositiveInteger</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="n">num</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid positive integer: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">primeFactorize</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="n">checkPositiveInteger</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

    <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span><span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prime_factorize</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">num</span> <span class="o">/=</span> <span class="n">i</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">prime_factorize</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">str_numA</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer A: &quot;</span><span class="p">)</span>
    <span class="n">str_numB</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer B: &quot;</span><span class="p">)</span>

    <span class="n">numA</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numA</span><span class="p">)</span>
    <span class="n">numB</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numB</span><span class="p">)</span>

    <span class="n">prime_factorize_A</span> <span class="o">=</span> <span class="n">primeFactorize</span><span class="p">(</span><span class="n">numA</span><span class="p">)</span>
    <span class="n">prime_factorize_B</span> <span class="o">=</span> <span class="n">primeFactorize</span><span class="p">(</span><span class="n">numB</span><span class="p">)</span>

    <span class="n">common_prime</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize_A</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize_B</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">gcf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">prime</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">common_prime</span><span class="p">):</span>
        <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">prime_factorize_A</span><span class="p">[</span><span class="n">prime</span><span class="p">],</span><span class="n">prime_factorize_B</span><span class="p">[</span><span class="n">prime</span><span class="p">])</span>
        <span class="n">gcf</span> <span class="o">=</span> <span class="n">gcf</span> <span class="o">*</span> <span class="p">(</span><span class="n">prime</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Greatest Common Factor: &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gcf</span><span class="p">))</span>
</pre></div>


<p>接下來來檢查一下「穩健度」和「可擴展」，也就是程式是否符合：低耦合、高內聚，其實上面的程式碼有一個大問題，客戶端邏輯和業務邏輯混為一談，客戶端邏輯就是實現功能的部分，而業務邏輯就是實作的細節，所以上面的程式碼把所有的實作的細節全部攤在客戶端，這是相當不好的，這會造成不易更改，因此我們將程式作單元的拆分，讓業務邏輯和客戶端邏輯相分離，讓不直接實現客戶端的程式碼可以隱藏起來，減少客戶端和業務邏輯的耦合。然後順道加入求取最小公倍數的功能。</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="k">def</span> <span class="nf">checkPositiveInteger</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="n">num</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid positive integer: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">primeFactorize</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="n">checkPositiveInteger</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

    <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span><span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">num</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prime_factorize</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">num</span> <span class="o">/=</span> <span class="n">i</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">prime_factorize</span>

<span class="k">def</span> <span class="nf">findGCF</span><span class="p">(</span><span class="n">nums</span><span class="p">):</span>
    <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">nums</span><span class="p">:</span>
        <span class="n">prime_factorize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">primeFactorize</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

    <span class="n">common_prime</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">prime_factorize</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">common_prime</span> <span class="o">&amp;=</span> <span class="nb">set</span><span class="p">(</span><span class="n">pf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">gcf</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">prime</span> <span class="ow">in</span> <span class="n">common_prime</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>
        <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">prime_factorize</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">pf</span><span class="p">[</span><span class="n">prime</span><span class="p">])</span>
        <span class="n">gcf</span> <span class="o">=</span> <span class="n">gcf</span> <span class="o">*</span> <span class="p">(</span><span class="n">prime</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gcf</span>

<span class="k">def</span> <span class="nf">findLCM</span><span class="p">(</span><span class="n">nums</span><span class="p">):</span>
    <span class="n">gcf</span> <span class="o">=</span> <span class="n">findGCF</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>
    <span class="n">lcm</span> <span class="o">=</span> <span class="n">gcf</span>
    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">nums</span><span class="p">:</span>
        <span class="n">lcm</span> <span class="o">*=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num</span><span class="o">/</span><span class="n">gcf</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lcm</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">str_numA</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer A: &quot;</span><span class="p">)</span>
    <span class="n">str_numB</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer B: &quot;</span><span class="p">)</span>

    <span class="n">numA</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numA</span><span class="p">)</span>
    <span class="n">numB</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numB</span><span class="p">)</span>

    <span class="n">nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">numA</span><span class="p">,</span><span class="n">numB</span><span class="p">]</span>    
    <span class="n">gcf</span> <span class="o">=</span> <span class="n">findGCF</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>
    <span class="n">lcm</span> <span class="o">=</span> <span class="n">findLCM</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Greatest Common Factor: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gcf</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Lowest Common Multiple: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">lcm</span><span class="p">))</span>
</pre></div>


<p>如此一來程式碼就看起來乾淨很多，function和function之間的耦合性被降低了，而function本身的內聚性提高了，程式碼達到了低耦合、高內聚，但是似乎還可以更好。</p>
<h5><u>形塑出物件導向</u></h5>
<p>剛剛我們已經完成了一個看起來很乾淨的程式碼了，但是其實還可以更好，在這裡我們就必須形塑出物件導向，才有辦法再前進一步。</p>
<p>剛剛的程式碼當中的<code>checkPositiveInteger(num)</code>, <code>primeFactorize(num)</code>, <code>findGCF(nums)</code>, <code>findLCM(nums)</code>函數其實都是實現同一個目標—因式計算，但卻是被寫成一個一個獨立的函數，這裡的內聚性還可以再更好。</p>
<p>而且<code>checkPositiveInteger(num)</code>, <code>primeFactorize(num)</code>並不是用來實現主要的目的，而只是實現目的過程中，為了避免重複而產生的，這樣寫很容易讓人不清楚什麼是重要的函數，而什麼只是中繼的函數，這裡的「可讀性」應該還可以再提升。</p>
<p>輸入的數字<code>nums</code>對於<code>findGCF</code>和<code>findLCM</code>，應該是一模一樣的，有沒有一個方法可以讓<code>nums</code>避免重複呢？以增強「不要重複撰寫」的原則。</p>
<p>要擁有以上的功能，我們需要一個「物件」，這個「物件」能夠保有屬於它的變數，才可以儲存<code>nums</code>等參數，變數可以是對外公布的，也可以是私有的。另外,這個「對象」擁有屬於它的函數方法，而方法一樣可以是對外公布的，也可以是私有的，所以我們可以公布<code>findGCF(nums)</code>, <code>findLCM(nums)</code>，而私有化
<code>checkPositiveInteger(num)</code>, <code>primeFactorize(num)</code>。我們使用「藍圖」去建構「物件」的模版，再由「藍圖」配合不同的輸入參數去生成一個一個獨立的「物件」，以因應不同的狀況。</p>
<p>這就是物件導向！</p>
<p>接下來，我將上面程式碼引入物件導向改寫如下。（看不懂～沒關係！未來會詳述）</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="k">class</span> <span class="nc">Calculation</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">nums</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span> <span class="o">=</span> <span class="n">nums</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__checkPositiveInteger</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__checkPositiveInteger</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span><span class="nb">int</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="n">num</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;invalid positive integer: &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__primeFactorize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">num</span><span class="p">):</span>
        <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">while</span><span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">num</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">prime_factorize</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prime_factorize</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">num</span> <span class="o">/=</span> <span class="n">i</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">prime_factorize</span>

    <span class="k">def</span> <span class="nf">findGCF</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">prime_factorize</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span><span class="p">:</span>
            <span class="n">prime_factorize</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__primeFactorize</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

        <span class="n">common_prime</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">prime_factorize</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">prime_factorize</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">common_prime</span> <span class="o">&amp;=</span> <span class="nb">set</span><span class="p">(</span><span class="n">pf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="n">gcf</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">prime</span> <span class="ow">in</span> <span class="n">common_prime</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>
            <span class="k">for</span> <span class="n">pf</span> <span class="ow">in</span> <span class="n">prime_factorize</span><span class="p">:</span>
                <span class="n">m</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">pf</span><span class="p">[</span><span class="n">prime</span><span class="p">])</span>
            <span class="n">gcf</span> <span class="o">=</span> <span class="n">gcf</span> <span class="o">*</span> <span class="p">(</span><span class="n">prime</span> <span class="o">**</span> <span class="n">m</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">gcf</span>

    <span class="k">def</span> <span class="nf">findLCM</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">gcf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">findGCF</span><span class="p">()</span>
        <span class="n">lcm</span> <span class="o">=</span> <span class="n">gcf</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__nums</span><span class="p">:</span>
            <span class="n">lcm</span> <span class="o">*=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num</span><span class="o">/</span><span class="n">gcf</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lcm</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">str_numA</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer A: &quot;</span><span class="p">)</span>
    <span class="n">str_numB</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;Positive Integer B: &quot;</span><span class="p">)</span>

    <span class="n">numA</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numA</span><span class="p">)</span>
    <span class="n">numB</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">str_numB</span><span class="p">)</span>

    <span class="n">nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">numA</span><span class="p">,</span><span class="n">numB</span><span class="p">]</span>
    <span class="n">calc</span> <span class="o">=</span> <span class="n">Calculation</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>
    <span class="n">gcf</span> <span class="o">=</span> <span class="n">calc</span><span class="o">.</span><span class="n">findGCF</span><span class="p">()</span>
    <span class="n">lcm</span> <span class="o">=</span> <span class="n">calc</span><span class="o">.</span><span class="n">findLCM</span><span class="p">()</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Greatest Common Factor: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">gcf</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Lowest Common Multiple: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">lcm</span><span class="p">))</span>
</pre></div>


<h5><u>總結：程式碼鑑賞能力</u></h5>
<p>本章YC帶大家建立一種品味，像是藝術評論家一樣，我們學會了如何鑑賞好的程式碼，我們提到了好的程式碼須要符合「正常執行」、「穩健」、「不重複撰寫」、「可讀性」、「可擴展」的特性，並且提到我們要追求低耦合、高內聚，但是「不重複撰寫」的這個原則會和低耦合相互違和，所以工程師要小心拿捏！有了鑑賞能力，我們開始精練我們的程式，而自然而然就可以引出物件導向的概念。當然，物件導向不只如此啦！我們下章就會看到物件導向還有什麼花拳繡腿。</p></dd>
                <dt>2018 / 2月 03</dt>
                <dd><a href="./the-selfish-gene.html">自私的基因：基因觀點下的天擇</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>物競天擇？</u></h5>
<p>『自私的基因』是當代相當重要的一本書，它在生物學上的地位等同於在物理學上的『時間簡史』。作者理察·道金斯（Richard Dawkins）是一個跨領域的通才，曾獲得動物學學士學位、文學碩士、哲學博士以及科學博士，我認為也是因為這樣的跨領域學習，才能讓他完成這樣一本創作俱佳的好書。</p>
<p>達爾文的天擇說提出後，生物學開始有了一個思考的脈絡來描述生物的演化，天擇說告訴我們「物競天擇，適者生存、不適者淘汰」，地球上目前存在的物種是多年來環境盲目篩選後的結果，但我們會發現如果以物種為單位來說明天擇會有一些說不清的地方。</p>
<p>舉個例子，物種的利他行為，例如許多小型鳥類遇到老鷹時會發出警訊給同伴，通知同伴趕快逃跑，這毫無疑問的是一種利他行為，發出警訊將會使自己暴露在危險之中，而換取到的是其他同伴的安全，針對這樣的利他行為，「群體選擇」理論會說生物會因演化而做出對種族有利的事，作者認為這是一種謬誤，生物間應該無法輕易的區分種族，就算可以，那我們又如何去劃分層次，要從界、門、綱、目、科、屬、種哪個層面下手去有意識的幫助自己的種族呢？以物種為單位的天擇說僅能說明生物本身的自利行為，但是解釋不清楚利他行為如何形成。</p>
<p>作者道金斯受到魏斯曼（A. Weismann）的學說「生殖細胞的延續性」所啟蒙，提出了天擇利己主義的基本單位，既非種，也非群體，亦非個體，而是「基因」（Gene）這個遺傳的基本單位。而也正是基因的自私行為才造就個體的利他行為，基因傾向於保全與自己基因相似的個體，以獲得基因本身的延續，基因是自私的，所以本書的書名才會叫做『自私的基因』。</p>
<h5><u>生命源自於複製</u></h5>
<p>為了說清楚基因觀點下的演化，我們回到四十億年前的地球，那時的地球海洋已經形成，稱之為太古混湯（primeval soup），海洋中存在著大量的基本化合物，譬如：水、二氧化碳、甲烷和氮。這些基本化合物會因為化學作用，而可能有機會合併形成更大、更複雜的化合物，在那個時候大的有機化合物因為沒有存在細菌可以分解它，所以是可以被完整保存下來的，直到有一天出現了一種可以自我複製的化合物，它就開始大量形成相同的化學結構，而且方便的是太古混湯擁有大量的垂手可得的建材，所以可以大量的複製出更多的複製者，這樣的複製就開始擴張開來。</p>
<p>當然像這類的複製者不只一種，太古混湯中夾雜許多可以自我複製的化合物種類，而且就連複製者在複製的過程當中都可能會出錯而產生出其他形式的複製者，當複製者越來越多，造成太古混湯開始缺乏素材而無法供養所有的複製者，競爭就開始了，天擇就開始了！而能存活的複製者必須符合長命、生產力大、複製正確度高等特性，否則將無法在歷史的長河中留下。</p>
<p>競爭只會隨著時間日益增加而不會減少，為了存活（不是有意識的，而是天擇的結果）複製者開始改良自身，增加自身的穩定性，瓦解對手的穩定度，譬如：形成蛋白質保護自己、形成可以分解對手分子鍵結的能力以得到更多的建材，為了生存，複製者走向發展出更精細的、更複雜的求生機器。</p>
<p>四十億年過去了，這些複製者在今日被稱之為基因，多個基因組成DNA，DNA可以轉譯成蛋白質分子來打造出求生機器，求生機器是承載基因的「工具」，承載數千、數萬個基因，每具肉體都是基因精巧的共同傑作，想要區分這個基因和另一個基因的貢獻，幾乎是做不到的。</p>
<p>書中作者用划船來作比喻，划船人員就像是基因，而這艘船就像是個體，當個體無法繁殖，這組團隊就像是輸了比賽就會被淘汰，而獲勝的團隊將可能在未來與其他的基因合作繼續的比賽下去，這艘船的每個船員都有適合他的位置，可能有船首、舵手或尾槳，把人放在適合的位置才可以發揮最好的實力，那麼最後存活下來的物種就是擁有好基因彼此之間合作無間的成果。</p>
<h5><u>基因的代理人—神經網絡</u></h5>
<p>動物和植物不同之處，動物擁有快速的行為，譬如遇到敵人就要拔腿就跑、看到獵物就要採取攻擊，這一些快速的行為不可能由基因直接控制，因為基因的影響速度太慢了，可能需要幾個月的時間，所以基因依造它們的需求打造出了神經網絡，然後神經網絡就接管了個體每時每刻的行為，才能因應各種環境的變化去做出相應的行為，使得個體得以生存，幫助基因可以繼續繁衍下去，如果用電腦來比喻的話，圍棋程式AlphaGo在比賽之前是由人類打造而成的，但是在真正比賽時，它會依照當下狀況去自行下決定，基因也是一樣的，基因先打造好神經網絡，接下來個體的行為就由這些神經網絡來代理了。</p>
<h5><u>再談利他行為</u></h5>
<p>好的基因產生的神經網絡所造就的動物行為，是要可以幫助基因複製自身的，基因是自私的，但不是有意識的，而是天擇造就了自私的基因得以存活下來，也正是這一層關係，物種的利他行為仍然是基因自私的結果。</p>
<p>像是一開始舉例的，小鳥會發出叫聲來提醒其他同伴，這樣的行為對個體是不利的，但是犧牲的個體可以保全其他相似的基因存活，這個基因就會延續下去。在人類社會，父母親給予子女的愛是無私的，但是這還是基因自私的結果，對子女無私的基因傾向讓子女更容易活下去，所以這樣的基因存活下來，相反的會拋下子女的基因，如果不能配合嬰兒時期可以自行生存的基因，這些子女也就會提早夭折，這樣的基因就會消失在歷史的長河裡頭。</p>
<p>因此，所有的生物行為都只有一個目的—讓基因複製下去，而環境會做出審判，作者還進一步的使用賽局理論來解釋哪些行為會是有利的、哪些行為會造成不利，譬如說某個族群50%的個體不喜歡起衝突而50%的個體喜歡追殺到底，想當然爾，如果這個種族在競爭食物時，喜歡追殺到底的個體比較有利，所以不喜歡起衝突的個體會數量減少，所以接下來可能是存在20%的個體不喜歡起衝突而80%的個體喜歡追殺到底，因此喜歡追殺到底的個體很容易遇到一樣喜歡追殺到底的個體，這些喜歡衝突的個體可能會弄的兩拜俱傷，而不喜歡衝突的個體可能使用逃跑的方式躲避反而是存活下來了，此時就會出現數量上的反轉，最後會形成一種平衡，稱為「演化穩定策略」（evolutionary stable strategy, ESS），那當然不會有全然不喜歡衝突和喜歡衝突的個體，所以這樣的平衡是反應在基因上面的，基因在編寫神經網絡的時候就會擬定一個對它最有利的穩定策略，當這個策略奏效，這樣的基因就得以存活。</p>
<p>這個部分讓我想起一個遊戲叫做<a href="https://audreyt.github.io/trust-zh-TW/">信任的演化</a>，這個遊戲是一個欺騙和合作的遊戲，當雙方都彼此合作時，會出現雙贏，而一方欺騙的情況下，欺騙者得利，另一方損失，如果雙方都欺騙則雙方都得不到好處。遊戲中有多個角色採取不同的策略，其中：「紅嬰仔」會一直信任對方，「黑到底」則會一直欺騙，「模仿貓」則是一開始採取合作的態度，當對方欺騙時在下一回合欺騙他，當對方合作時在下一回合就與他合作。當我們將這些角色丟進去進行多次的賽局，失敗者淘汰，成功者複製，在多次賽局之後你會發現「模仿貓」會勝出，利用這個遊戲你就能了解有限度的利他行為是如何勝出的，而基因所產生行為也就是在這樣多次的賽局下修正成有限度的利他行為。</p>
<h5><u>文化的複製者—迷因（Meme）</u></h5>
<p>基因為了自己的利益編寫出了神經網絡來幫助自己存活下去，但基因萬萬沒想到它所開發的東西居然會反過來對它不利！</p>
<p>人類的基因產生了非常厲害的人腦，的確是有助於基因的繁衍，你看地球上的人口數量就知道了，但是大腦複雜到一個程度，就產生了思想，人類發展出了語言作溝通，文化得以使用語言或文字傳承下去，這在定義上也是一種複製者，這種文化的複製因子，作者將它稱之為迷因（Meme）。</p>
<p>迷因（Meme）也是彼此競爭著，它們競爭的是你有限的大腦，如果你的大腦有資本主義，可能就容不下共產主義，而迷因也會不斷的改善自己，讓它們可以贏得競爭，然後傳播出去並大量的被複製。而有些時候迷因的競爭對手可能不只是其他迷因，也有可能會和基因作對，譬如說使用保險套的迷因，正阻止了基因的複製，激烈的宗教信仰的迷因，使人走向自殺式攻擊，同樣也是不利於基因的繁衍。</p>
<p>這讓我想起最近人工智慧的興起，很多人對人工智慧開始產生擔憂，擔心機器人會反撲人類，如果依照上述的觀點看，這個可能是有機會發生的，程式設計師就像是基因，為了我們自身的目的去創造人工智慧來為我們服務，但是如果人工智慧越來越聰明，而且它的運算速度又比人類快，我們會根本無法理解人工智慧在想什麼，但是它們也確實是幫助人類解決很多問題，所以就算無法理解也就繼續的使用著，直到有一天，這些人工智慧在運作中突變出一種可以複製自己的複製者，也許是一種病毒，而這樣的複製者又能快速在人工智慧溝通中被傳遞出去，它就有可能回頭做出不利於人類的事。</p>
<h5><u>結語：複製與競爭</u></h5>
<p>本書讓我們重新認識了演化論，有了可以自己複製自己的複製者，就會有擴張，擴張的結果就是資源的稀缺，因此就自然產生競爭，在競爭的過程中，成功的策略符合ESS使得複製者得以存活下來，而失敗的複製者則會被淘汰、無法複製下去，這就是天擇的適者生存。從這一層的思想讓我們對於演化有了更深的認識，如果是生物的演化這個複製者就是基因，如果是文化的演化這個複製者就是迷因，也許你能想到其他的複製者，歡迎在下面留言讓大家知道。</p></dd>
                <dt>2017 / 11月 25</dt>
                <dd><a href="./tensorflow-tutorial_6.html">實作Tensorflow (6)：RNN and LSTM</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p>如果我們想要處理的問題是具有時序性的，該怎麼辦呢？本章將會介紹有時序性的Neurel Network。</p>
<p>本單元程式碼LSTM部分可於<a href="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/06_LSTM.py">Github</a>下載。</p>
<h5><u>概論RNN</u></h5>
<p>當我們想使得Neurel Network具有時序性，我們的Neurel Network就必須有記憶的功能，然後在我不斷的輸入新資訊時，也能同時保有歷史資訊的影響，最簡單的作法就是將Output的結果保留，等到新資訊進來時，將新的資訊和舊的Output一起考量來訓練Neurel Network。</p>
<p><img alt="unrolling" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.010.jpeg"></p>
<p>這種將舊有資訊保留的Neurel Network統稱為Recurrent Neural Networks (RNN)，這種不斷回饋的網路可以攤開來處理，如上圖，如果我有5筆數據，拿訓練一個RNN 5個回合並做了5次更新，其實就等效於攤開來一次處理5筆數據並做1次更新，這樣的手法叫做Unrolling，我們實作上會使用Unrolling的手法來增加計算效率。</p>
<p><img alt="RNN" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.011.jpeg"></p>
<p>接下來來看RNN內部怎麼實現的，上圖是最簡單的RNN形式，我們將上一回產生的Output和這一回的Input一起評估出這一回的Output，詳細式子如下：</p>
<p>new_o = tanh( i*W<sub>i</sub> + o*W<sub>o</sub> + B )</p>
<p>如此一來RNN就具有時序性了，舊的歷史資料將可以被「記憶」起來，你可以把RNN的「記憶」看成是「短期記憶」，因為它只會記得上一回的Output而已。</p>
<h5><u>梯度消失與梯度爆炸</u></h5>
<p>但這種形式的RNN在實作上會遇到很大的問題，還記得第二章當中，我們有講過像是tanh這類有飽和區的函數，會造成梯度消失的問題，而我們如果使用Unrolling的觀點來看RNN，將會發現這是一個超級深的網路，Backpapagation必須一路通到t0的RNN，想當然爾，有些梯度將會消失，部分權重就更新不到了，那有一些聰明的讀者一定會想到，那就使用Relu就好啦！不過其實還有一個重要的因素造成梯度消失，同時也造成梯度爆炸。</p>
<p>注意喔！雖然我們使用Unrolling的觀點，把網路看成是一個Deep網路的連接，但是和之前DNN不同之處，這些RNN彼此間是共享同一組權重的，這會造成梯度消失和梯度爆炸兩個問題，在RNN的結構裡頭，一個權重會隨著時間不斷的加強影響一個單一特徵，因為不同時間之下的RNN Cell共用同一個權重，這麼一來若是權重大於1，影響將會隨時間放大到梯度爆炸，若是權重小於1，影響將會隨時間縮小到梯度消失，就像是蝴蝶效應一般，微小的差異因為回饋的機制，而不合理的放大或是消失，因此RNN的Error Surface將會崎嶇不平，這會造成我們無法穩定的找到最佳解，難以收斂。這才是RNN難以使用的重要原因，把Activation Function換成Relu不會解決問題，文獻上反而告訴我們會變更差。</p>
<p>解決梯度爆炸有一個聽起來很廢但廣為人們使用的方法，叫做Gradient Clipping，也就是只要在更新過程梯度超過一個值，我就切掉讓梯度維持在這個上限，這樣就不會爆炸啦，待會會講到的LSTM只能夠解決梯度消失問題，但不能解決梯度爆炸問題，因此我們還是需要Gradient Clipping方法的幫忙。</p>
<p>在Tensorflow怎麼做到Gradient Clipping呢？作法是這樣的，以往我們使用<code>optimizer.minimize(loss)</code>來進行更新，事實上我們可以把這一步驟拆成兩部分，第一部分計算所有參數的梯度，第二部分使用這些梯度進行更新。因此我們可以從中作梗，把gradients偷天換日一番，一開始使用<code>optimizer.compute_gradients(loss)</code>來計算出個別的梯度，然後使用<code>tf.clip_by_global_norm(gradients, clip_norm)</code>來切梯度，最後再使用<code>optimizer.apply_gradients</code>把新的梯度餵入進行更新。</p>
<h5><u>Long Short-Term Memory (LSTM)</u></h5>
<p>LSTM是現今RNN的主流，它可以解決梯度消失的問題，我們先來看看結構，先預告一下，LSTM是迄今為止這系列課程當中看過最複雜的Neurel Network。</p>
<p><img alt="LSTM" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.012.jpeg"></p>
<p>最一開始和RNN一樣，Input會和上一回的Output一起評估一個「短期記憶」，</p>
<p>f<sub>m</sub> = tanh( i*W<sub>mi</sub> + o*W<sub>mo</sub> + B<sub>m</sub> )</p>
<p>但接下來不同於RNN直接輸出，LSTM做了一個類似於轉換成「長期記憶」的機制，「長期記憶」在這裡稱為State，State的狀態由三道門所控制，Input Gate負責控管哪些「短期記憶」可以進到「長期記憶」，Forget Gate負責調配哪一些「長期記憶」需要被遺忘，Output Gate則負責去決定需要從「長期記憶」中輸出怎樣的內容，先不要管這些Gate怎麼來，我們可以把這樣的記憶機制寫成以下的式子，假設State為f<sub>state</sub>、Input Gate為G<sub>i</sub>、Forget Gate為G<sub>f</sub>和Output Gate為G<sub>o</sub>。</p>
<p>new_f<sub>state</sub> = G<sub>i</sub> * f<sub>m</sub> + G<sub>f</sub> * f<sub>state</sub></p>
<p>new_o = G<sub>o</sub>*tanh( new_f<sub>state</sub> )</p>
<p>如果我們要使得上面中Gates的部分具有開關的功能的話，我們會希望Gates可以是0到1的值，0代表全關，1代表全開，sigmoid正可以幫我們做到這件事，那哪些因素會決定Gates的關閉與否呢？不妨考慮所有可能的因素，也就是所有輸入這個Cell的資訊都考慮進去，但上一回的State必須被剔除於外，因為上一回的State來決定下一個State的操作是不合理的，因此我們就可以寫下所有Gates的表示式了。</p>
<p>G<sub>i</sub> = Sigmoid(i*W<sub>ii</sub> + o*W<sub>io</sub> + B<sub>i</sub>)</p>
<p>G<sub>f</sub> = Sigmoid(i*W<sub>fi</sub> + o*W<sub>fo</sub> + B<sub>f</sub>)</p>
<p>G<sub>o</sub> = Sigmoid(i*W<sub>oi</sub> + o*W<sub>oo</sub> + B<sub>o</sub>)</p>
<p>這就是LSTM，「長期記憶」的出現可以解決掉梯度消失的問題，RNN只有「短期記憶」，所以一旦認為一個特徵不重要，經過幾回連乘，這個特徵的梯度就會消失殆盡，但是LSTM保留State，並且使用「加」的方法更新State，所以有一些重要的State得以留下來持續影響著Output，解決了梯度消失的問題。但是，不幸的LSTM還是免不了梯度爆炸，為什麼呢？如果一個特徵真的很重要，State會記住，Input也會強調，所以幾輪下來還是有可能出現爆炸的情況，這時候我們就需要Gradient Clipping的幫忙。</p>
<h5><u>使用LSTM實作文章產生器</u></h5>
<p>接下來我們來實作LSTM，目標是做一個文章產生器，我們希望機器可以不斷的根據前文猜測下一個「字母」(Letters)應該要下什麼，如此一來我只要給個開頭字母，LSTM就可以幫我腦補成一篇文章。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves.urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">LETTER_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># [a-z] + &#39; &#39;</span>
<span class="n">FIRST_LETTER_ASCII</span> <span class="o">=</span> <span class="nb">ord</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">maybe_download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">filename</span><span class="p">,</span> <span class="n">expected_bytes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Download a file if not present, and make sure it&#39;s the right size.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="n">filename</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="n">statinfo</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">stat</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span> <span class="o">==</span> <span class="n">expected_bytes</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Found and verified </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
          <span class="s1">&#39;Failed to verify &#39;</span> <span class="o">+</span> <span class="n">filename</span> <span class="o">+</span> <span class="s1">&#39;. Can you get to it with a browser?&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">filename</span>

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">namelist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">as_str</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">char2id</span><span class="p">(</span><span class="n">char</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">ord</span><span class="p">(</span><span class="n">char</span><span class="p">)</span> <span class="o">-</span> <span class="n">FIRST_LETTER_ASCII</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">char</span> <span class="o">==</span> <span class="s1">&#39; &#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Unexpected character: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">char</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">id2char</span><span class="p">(</span><span class="n">dictid</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">dictid</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">chr</span><span class="p">(</span><span class="n">dictid</span> <span class="o">+</span> <span class="n">FIRST_LETTER_ASCII</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39; &#39;</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Downloading text8.zip&quot;</span><span class="p">)</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">maybe_download</span><span class="p">(</span><span class="s1">&#39;http://mattmahoney.net/dc/text8.zip&#39;</span><span class="p">,</span><span class="s1">&#39;./text8.zip&#39;</span><span class="p">,</span> <span class="mi">31344016</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;=====&quot;</span><span class="p">)</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Data size </span><span class="si">%d</span><span class="s1"> letters&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;=====&quot;</span><span class="p">)</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">valid_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="n">valid_size</span><span class="p">]</span>
<span class="n">train_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">valid_size</span><span class="p">:]</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Train Dataset: size:&#39;</span><span class="p">,</span><span class="n">train_size</span><span class="p">,</span><span class="s1">&#39;letters,</span><span class="se">\n</span><span class="s1">  first 64:&#39;</span><span class="p">,</span><span class="n">train_text</span><span class="p">[:</span><span class="mi">64</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Validation Dataset: size:&#39;</span><span class="p">,</span><span class="n">valid_size</span><span class="p">,</span><span class="s1">&#39;letters,</span><span class="se">\n</span><span class="s1">  first 64:&#39;</span><span class="p">,</span><span class="n">valid_text</span><span class="p">[:</span><span class="mi">64</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span></span>Downloading text8.zip
Found and verified ./text8.zip
=====
Data size 100000000 letters
=====
Train Dataset: size: 99999000 letters,
  first 64: ons anarchists advocate social relations based upon voluntary as
Validation Dataset: size: 1000 letters,
  first 64:  anarchism originated as a term of abuse first used against earl
</pre></div>


<p>上面操作我們建制完成了字母庫，接下來就可以產生我們訓練所需要的Batch Data，所以我們來看看究竟要產生怎樣格式的資料。</p>
<p><img alt="LSTM Implement" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.013.jpeg"></p>
<p>如上圖所示，有點小複雜，假設我要設計一個LSTM Model，它的Unrolling Number為3，Batch Size為2，然後遇到的字串是"abcde fghij klmno pqrst"，接下來就開始產生每個Round要用的Data，產生的結果如上圖所示，你會發現產生的Data第0軸表示的是考慮unrolling需要取樣的資料，總共應該會有(Unrolling Number+1)筆，如上圖例，共有4筆，3筆當作輸入而3筆當作Labels，中間有2筆重疊使用，另外還有一點，我們會保留最後一筆Data當作下一個回合的第一筆，這是為了不浪費使用每一個字母前後的組合。而第1軸則是餵入單一LSTM需要的資料，我們一次可以餵多組不相干的字母進去，如上圖例，Batch Size=2所以餵2個字母進去，那這些不相干的字母在取樣的時候，我們會盡量讓它平均分配在文字庫，才能確保彼此之間不相干，以增加LSTM的訓練效率和效果。</p>
<p>因此，先產生Batch Data吧！</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">characters</span><span class="p">(</span><span class="n">probabilities</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Turn a 1-hot encoding or a probability distribution over the possible</span>
<span class="sd">    characters back into its (most likely) character representation.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">id2char</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">batches2string</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert a sequence of batches back into their (most likely) string</span>
<span class="sd">    representation.&quot;&quot;&quot;</span>
    <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">characters</span><span class="p">(</span><span class="n">b</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">s</span>

<span class="k">def</span> <span class="nf">rnn_batch_generator</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_unrollings</span><span class="p">):</span>
    <span class="n">text_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1">### initialization</span>
    <span class="n">segment</span> <span class="o">=</span> <span class="n">text_size</span> <span class="o">//</span> <span class="n">batch_size</span>
    <span class="n">cursors</span> <span class="o">=</span> <span class="p">[</span> <span class="n">offset</span> <span class="o">*</span> <span class="n">segment</span> <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batch_initial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">cursor</span> <span class="o">=</span> <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">id_</span> <span class="o">=</span> <span class="n">char2id</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">cursor</span><span class="p">])</span>
        <span class="n">batch_initial</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">id_</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="c1">#move cursor</span>
        <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">text_size</span>

    <span class="n">batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_initial</span><span class="p">)</span> 

    <span class="c1">### generate loop</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="p">[</span> <span class="n">batches</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_unrollings</span><span class="p">):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">cursor</span> <span class="o">=</span> <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">id_</span> <span class="o">=</span> <span class="n">char2id</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">cursor</span><span class="p">])</span>
                <span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">id_</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

                <span class="c1">#move cursor</span>
                <span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cursors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">text_size</span>
            <span class="n">batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="k">yield</span> <span class="n">batches</span>  <span class="c1"># [last batch of previous batches] + [unrollings]</span>


<span class="c1"># demonstrate generator</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span>
<span class="n">num_unrollings</span><span class="o">=</span><span class="mi">10</span>

<span class="n">train_batches</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">train_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_unrollings</span><span class="p">)</span>
<span class="n">valid_batches</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">valid_text</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;*** train_batches:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">train_batches</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">train_batches</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;*** valid_batches:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">valid_batches</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches2string</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">valid_batches</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span></span>*** train_batches:
[&#39;ons anarchi&#39;, &#39;when milita&#39;, &#39;lleria arch&#39;, &#39; abbeys and&#39;, &#39;married urr&#39;, &#39;hel and ric&#39;, &#39;y and litur&#39;, &#39;ay opened f&#39;, &#39;tion from t&#39;, &#39;migration t&#39;, &#39;new york ot&#39;, &#39;he boeing s&#39;, &#39;e listed wi&#39;, &#39;eber has pr&#39;, &#39;o be made t&#39;, &#39;yer who rec&#39;, &#39;ore signifi&#39;, &#39;a fierce cr&#39;, &#39; two six ei&#39;, &#39;aristotle s&#39;, &#39;ity can be &#39;, &#39; and intrac&#39;, &#39;tion of the&#39;, &#39;dy to pass &#39;, &#39;f certain d&#39;, &#39;at it will &#39;, &#39;e convince &#39;, &#39;ent told hi&#39;, &#39;ampaign and&#39;, &#39;rver side s&#39;, &#39;ious texts &#39;, &#39;o capitaliz&#39;, &#39;a duplicate&#39;, &#39;gh ann es d&#39;, &#39;ine january&#39;, &#39;ross zero t&#39;, &#39;cal theorie&#39;, &#39;ast instanc&#39;, &#39; dimensiona&#39;, &#39;most holy m&#39;, &#39;t s support&#39;, &#39;u is still &#39;, &#39;e oscillati&#39;, &#39;o eight sub&#39;, &#39;of italy la&#39;, &#39;s the tower&#39;, &#39;klahoma pre&#39;, &#39;erprise lin&#39;, &#39;ws becomes &#39;, &#39;et in a naz&#39;, &#39;the fabian &#39;, &#39;etchy to re&#39;, &#39; sharman ne&#39;, &#39;ised empero&#39;, &#39;ting in pol&#39;, &#39;d neo latin&#39;, &#39;th risky ri&#39;, &#39;encyclopedi&#39;, &#39;fense the a&#39;, &#39;duating fro&#39;, &#39;treet grid &#39;, &#39;ations more&#39;, &#39;appeal of d&#39;, &#39;si have mad&#39;]
[&#39;ists advoca&#39;, &#39;ary governm&#39;, &#39;hes nationa&#39;, &#39;d monasteri&#39;, &#39;raca prince&#39;, &#39;chard baer &#39;, &#39;rgical lang&#39;, &#39;for passeng&#39;, &#39;the nationa&#39;, &#39;took place &#39;, &#39;ther well k&#39;, &#39;seven six s&#39;, &#39;ith a gloss&#39;, &#39;robably bee&#39;, &#39;to recogniz&#39;, &#39;ceived the &#39;, &#39;icant than &#39;, &#39;ritic of th&#39;, &#39;ight in sig&#39;, &#39;s uncaused &#39;, &#39; lost as in&#39;, &#39;cellular ic&#39;, &#39;e size of t&#39;, &#39; him a stic&#39;, &#39;drugs confu&#39;, &#39; take to co&#39;, &#39; the priest&#39;, &#39;im to name &#39;, &#39;d barred at&#39;, &#39;standard fo&#39;, &#39; such as es&#39;, &#39;ze on the g&#39;, &#39;e of the or&#39;, &#39;d hiver one&#39;, &#39;y eight mar&#39;, &#39;the lead ch&#39;, &#39;es classica&#39;, &#39;ce the non &#39;, &#39;al analysis&#39;, &#39;mormons bel&#39;, &#39;t or at lea&#39;, &#39; disagreed &#39;, &#39;ing system &#39;, &#39;btypes base&#39;, &#39;anguages th&#39;, &#39;r commissio&#39;, &#39;ess one nin&#39;, &#39;nux suse li&#39;, &#39; the first &#39;, &#39;zi concentr&#39;, &#39; society ne&#39;, &#39;elatively s&#39;, &#39;etworks sha&#39;, &#39;or hirohito&#39;, &#39;litical ini&#39;, &#39;n most of t&#39;, &#39;iskerdoo ri&#39;, &#39;ic overview&#39;, &#39;air compone&#39;, &#39;om acnm acc&#39;, &#39; centerline&#39;, &#39;e than any &#39;, &#39;devotional &#39;, &#39;de such dev&#39;]
*** valid_batches:
[&#39; a&#39;]
[&#39;an&#39;]
</pre></div>


<p>定義一下待會會用到的函數。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample_distribution</span><span class="p">(</span><span class="n">distribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample one element from a distribution assumed to be an array of normalized</span>
<span class="sd">    probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">distribution</span><span class="p">)):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">distribution</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">s</span> <span class="o">&gt;=</span> <span class="n">r</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">i</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">distribution</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">prediction</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Turn a (column) prediction into 1-hot encoded samples.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">sample_distribution</span><span class="p">(</span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">p</span>

<span class="k">def</span> <span class="nf">logprob</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Log-probability of the true labels in a predicted batch.&quot;&quot;&quot;</span>
    <span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-10</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">predictions</span><span class="p">)))</span> <span class="o">/</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>


<p>開始建制LSTM Model。</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_unrollings</span><span class="p">,</span><span class="n">n_memory</span><span class="p">,</span><span class="n">n_train_batch</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span> <span class="o">=</span> <span class="n">n_unrollings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span> <span class="o">=</span> <span class="n">n_memory</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saved</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c1"># initialize new grap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">n_train_batch</span><span class="p">)</span> <span class="c1"># building graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="c1"># create session by the graph </span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">n_train_batch</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="c1">### Input      </span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">n_train_batch</span><span class="p">,</span><span class="n">LETTER_SIZE</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># labels are inputs shifted by one time step.</span>


            <span class="c1">### Optimalization</span>
            <span class="c1"># build neurel network structure and get their loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span> <span class="n">inputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">,</span>
                                                 <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">,</span>
                                                 <span class="n">n_batch</span><span class="o">=</span><span class="n">n_train_batch</span><span class="p">,</span>
                                               <span class="p">)</span>

            <span class="c1"># define training operation</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdagradOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

            <span class="c1"># gradient clipping</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">))</span> <span class="c1"># output gradients one by one</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_global_norm</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">)</span> <span class="c1"># clip gradient</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span> <span class="c1"># apply clipped gradients</span>


            <span class="c1">### Sampling and validation eval: batch 1, no unrolling.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">])</span>

            <span class="n">saved_sample_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]))</span>
            <span class="n">saved_sample_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_sample_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span>     <span class="c1"># reset sample state operator</span>
                <span class="n">saved_sample_output</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
                <span class="n">saved_sample_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])))</span>

            <span class="n">sample_output</span><span class="p">,</span> <span class="n">sample_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_cell</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">,</span> <span class="n">saved_sample_output</span><span class="p">,</span> <span class="n">saved_sample_state</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">saved_sample_output</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">sample_output</span><span class="p">),</span>
                                          <span class="n">saved_sample_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">sample_state</span><span class="p">)]):</span>
                <span class="c1"># use tf.control_dependencies to make sure &quot;saving&quot; before &quot;prediction&quot;</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">sample_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">sample_output</span><span class="p">,</span> 
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;classifier&#39;</span><span class="p">],</span> 
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;classifier&#39;</span><span class="p">]))</span>

            <span class="c1">### Initialization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  

    <span class="k">def</span> <span class="nf">lstm_cell</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">o</span><span class="p">,</span><span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf</span>
<span class="sd">        Note that in this formulation, we omit the various connections between the</span>
<span class="sd">        previous state and the gates.&quot;&quot;&quot;</span>
        <span class="c1">## Build Input Gate</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;input_gate_i&#39;</span><span class="p">]</span>
        <span class="n">im</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;input_gate_o&#39;</span><span class="p">]</span>
        <span class="n">ib</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;input_gate&#39;</span><span class="p">]</span>
        <span class="n">input_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ix</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">im</span><span class="p">)</span> <span class="o">+</span> <span class="n">ib</span><span class="p">)</span>
        <span class="c1">## Build Forget Gate</span>
        <span class="n">fx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;forget_gate_i&#39;</span><span class="p">]</span>
        <span class="n">fm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;forget_gate_o&#39;</span><span class="p">]</span>
        <span class="n">fb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;forget_gate&#39;</span><span class="p">]</span>        
        <span class="n">forget_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">fx</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">fm</span><span class="p">)</span> <span class="o">+</span> <span class="n">fb</span><span class="p">)</span>
        <span class="c1">## Memory</span>
        <span class="n">cx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;memory_i&#39;</span><span class="p">]</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;memory_o&#39;</span><span class="p">]</span>
        <span class="n">cb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span>
        <span class="n">update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cx</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">cm</span><span class="p">)</span> <span class="o">+</span> <span class="n">cb</span>
        <span class="c1">## Update State</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">forget_gate</span> <span class="o">*</span> <span class="n">state</span> <span class="o">+</span> <span class="n">input_gate</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>
        <span class="c1">## Build Output Gate        </span>
        <span class="n">ox</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;output_gate_i&#39;</span><span class="p">]</span>
        <span class="n">om</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;output_gate_o&#39;</span><span class="p">]</span>
        <span class="n">ob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;output_gate&#39;</span><span class="p">]</span>
        <span class="n">output_gate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ox</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">om</span><span class="p">)</span> <span class="o">+</span> <span class="n">ob</span><span class="p">)</span>
        <span class="c1">## Ouput</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output_gate</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">structure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">inputs</span><span class="p">,</span><span class="n">labels</span><span class="p">,</span><span class="n">n_batch</span><span class="p">):</span>
        <span class="c1">### Variable</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">saved</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
              <span class="s1">&#39;input_gate_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;input_gate_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;forget_gate_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;forget_gate_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;output_gate_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;output_gate_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;memory_i&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;memory_o&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>
              <span class="s1">&#39;classifier&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">,</span> <span class="n">LETTER_SIZE</span><span class="p">],</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)),</span>

            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
              <span class="s1">&#39;input_gate&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s1">&#39;forget_gate&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s1">&#39;output_gate&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s1">&#39;memory&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">])),</span>
              <span class="s1">&#39;classifier&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">LETTER_SIZE</span><span class="p">])),</span>
            <span class="p">}</span>

        <span class="c1"># Variables saving state across unrollings.</span>
        <span class="n">saved_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">saved_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_memory</span><span class="p">]),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="c1">### Structure</span>
        <span class="c1"># Unrolled LSTM loop.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">saved_output</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">saved_state</span>
        <span class="k">for</span> <span class="n">input_</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_cell</span><span class="p">(</span><span class="n">input_</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="c1"># State saving across unrollings.</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">saved_output</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">output</span><span class="p">),</span>
                                      <span class="n">saved_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">state</span><span class="p">)]):</span>
            <span class="c1"># use tf.control_dependencies to make sure &quot;saving&quot; before &quot;calculating loss&quot;</span>

            <span class="c1"># Classifier</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> 
                                     <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;classifier&#39;</span><span class="p">],</span> 
                                     <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;classifier&#39;</span><span class="p">])</span>
            <span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
                        <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">y_</span><span class="p">,</span> <span class="n">loss</span>


    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">online_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>      
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_unrollings</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>    
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">perplexity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">sum_logprob</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">sample_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_sample_state</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample_size</span><span class="p">):</span>
                <span class="n">sample_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">],</span><span class="n">newshape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">sample_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">],</span><span class="n">newshape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_prediction</span><span class="p">,</span>
                                            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">:</span> <span class="n">sample_input</span><span class="p">})</span>
                <span class="n">sum_logprob</span> <span class="o">+=</span> <span class="n">logprob</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">sample_label</span><span class="p">)</span>
        <span class="n">perplexity</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sum_logprob</span> <span class="o">/</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="n">sample_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">perplexity</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">len_generate</span><span class="p">):</span>
        <span class="n">feed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">id2char</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">==</span><span class="n">c</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">LETTER_SIZE</span><span class="p">)]])</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">characters</span><span class="p">(</span><span class="n">feed</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_sample_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_generate</span><span class="p">):</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_prediction</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_input</span><span class="p">:</span> <span class="n">feed</span><span class="p">})</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
            <span class="n">sentence</span> <span class="o">+=</span> <span class="n">characters</span><span class="p">(</span><span class="n">feed</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sentence</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># build training batch generator</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">train_text</span><span class="p">,</span>
                                      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                      <span class="n">num_unrollings</span><span class="o">=</span><span class="n">num_unrollings</span><span class="p">)</span>

<span class="c1"># build validation data</span>
<span class="n">valid_batches</span> <span class="o">=</span> <span class="n">rnn_batch_generator</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">valid_text</span><span class="p">,</span> 
                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                    <span class="n">num_unrollings</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">valid_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">valid_batches</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_size</span><span class="p">)]</span>

<span class="c1"># build LSTM model</span>
<span class="n">model_LSTM</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">n_unrollings</span><span class="o">=</span><span class="n">num_unrollings</span><span class="p">,</span>
                  <span class="n">n_memory</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                  <span class="n">n_train_batch</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="c1"># initial model</span>
<span class="n">model_LSTM</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

<span class="c1"># online training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">num_batchs_in_epoch</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">valid_freq</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batchs_in_epoch</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model_LSTM</span><span class="o">.</span><span class="n">online_fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span>

    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="n">num_batchs_in_epoch</span>

    <span class="n">train_perplexity</span> <span class="o">=</span> <span class="n">model_LSTM</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">: </span><span class="si">%d</span><span class="s2">s loss = </span><span class="si">%6.4f</span><span class="s2">, perplexity = </span><span class="si">%6.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span>
                                                   <span class="n">avg_loss</span><span class="p">,</span> <span class="n">train_perplexity</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">valid_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;=============== Validation ===============&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;validation perplexity = </span><span class="si">%6.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Generate From &#39;a&#39;:  &quot;</span><span class="p">,</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Generate From &#39;h&#39;:  &quot;</span><span class="p">,</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Generate From &#39;m&#39;:  &quot;</span><span class="p">,</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;==========================================&quot;</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Epoch 1/30: 96s loss = 1.8350, perplexity = 6.0744
Epoch 2/30: 93s loss = 1.5473, perplexity = 5.9950
Epoch 3/30: 96s loss = 1.4832, perplexity = 5.7988
Epoch 4/30: 95s loss = 1.4460, perplexity = 5.5873
Epoch 5/30: 93s loss = 1.4268, perplexity = 6.0196

=============== Validation ===============
validation perplexity = 3.7728
Generate From &#39;a&#39;:   a addressed trojp herregore efforts taxothers of fi
Generate From &#39;h&#39;:   h a one nine one s personalt god tranant of genuali
Generate From &#39;m&#39;:   m with the of retrintuutar one five zero and even t
==========================================

Epoch 6/30: 92s loss = 1.4116, perplexity = 5.8374
Epoch 7/30: 92s loss = 1.3958, perplexity = 5.7529
Epoch 8/30: 91s loss = 1.3911, perplexity = 5.8161
Epoch 9/30: 92s loss = 1.3670, perplexity = 5.6386
Epoch 10/30: 92s loss = 1.3871, perplexity = 5.5209

=============== Validation ===============
validation perplexity = 3.6448
Generate From &#39;a&#39;:   as mark but use the church management seniorie othe
Generate From &#39;h&#39;:   h mathum it layor j cape not pac feloghaokurg the a
Generate From &#39;m&#39;:   ment condition christmishem the reasons obaging out
==========================================

Epoch 11/30: 92s loss = 1.3772, perplexity = 5.4907
Epoch 12/30: 92s loss = 1.3782, perplexity = 6.1908
Epoch 13/30: 92s loss = 1.3713, perplexity = 5.7394
Epoch 14/30: 92s loss = 1.3722, perplexity = 6.5244
Epoch 15/30: 92s loss = 1.3665, perplexity = 6.5655

=============== Validation ===============
validation perplexity = 3.6228
Generate From &#39;a&#39;:   ans in the first glds for exclusively assistance es
Generate From &#39;h&#39;:   h south and the w cops and goat right as known the 
Generate From &#39;m&#39;:   m charges has a properties keit was in second state
==========================================

Epoch 16/30: 362s loss = 1.3627, perplexity = 5.3342
Epoch 17/30: 95s loss = 1.3674, perplexity = 5.2295
Epoch 18/30: 93s loss = 1.3513, perplexity = 6.6203
Epoch 19/30: 94s loss = 1.3637, perplexity = 5.9332
Epoch 20/30: 94s loss = 1.3561, perplexity = 6.0590

=============== Validation ===============
validation perplexity = 3.4923
Generate From &#39;a&#39;:   a the problems in mind types in one strieging call 
Generate From &#39;h&#39;:   huragre ray fundament lost knishera claokhen nalony
Generate From &#39;m&#39;:   m for five one nine four zero market hell one nine 
==========================================

Epoch 21/30: 93s loss = 1.3569, perplexity = 5.9601
Epoch 22/30: 93s loss = 1.3516, perplexity = 6.9727
Epoch 23/30: 92s loss = 1.3676, perplexity = 5.5722
Epoch 24/30: 94s loss = 1.3603, perplexity = 6.1140
Epoch 25/30: 92s loss = 1.3649, perplexity = 6.2638

=============== Validation ===============
validation perplexity = 3.5306
Generate From &#39;a&#39;:   an experimenting meaning as dosil smold seven eight
Generate From &#39;h&#39;:   h one nine seven biero shimm in died this theorothy
Generate From &#39;m&#39;:   m to threat loss away a roon b one six four nine fa
==========================================

Epoch 26/30: 95s loss = 1.3533, perplexity = 6.1450
Epoch 27/30: 75s loss = 1.3568, perplexity = 6.3603
Epoch 28/30: 93s loss = 1.3719, perplexity = 5.4497
Epoch 29/30: 96s loss = 1.3620, perplexity = 6.1687
Epoch 30/30: 95s loss = 1.3660, perplexity = 5.9484

=============== Validation ===============
validation perplexity = 3.4477
Generate From &#39;a&#39;:   ates in weaved to has be five six zero song in the 
Generate From &#39;h&#39;:   h a neil and would lockspry short there is attempte
Generate From &#39;m&#39;:   man one nine zero eight moming between language yea
==========================================
</pre></div>


<p>最後來產生一篇以"t"為開頭的1000字文章吧！</p>
<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">model_LSTM</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">,</span><span class="n">len_generate</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>tifician linulation fromsantinated inscriptions have been followne members of gomewhokeno science and direct to player by the xh music the work mercing a completely categories following were now shrries the graduate painters but three limil bp inversing to in show monasteria ziver buriale hollesthea or universities contains one nine five three villes on in wolf from home with alimon del wi tallation austry five he is generate three visitiral spectring greece of many proper six one would frequently to be along two zero zero one aberrieds him hockel alphaliatiss r kabif figant in jock final click hospite michael hetrion as the equations were feature to notably algebraic important but better can requires of the same since the many bag among the mastic five official with the homes abertosiar of game mi romannessas nine pp which based for a secrition in one nine five seven recent issannallies algorithm rigarborsphy inctmm information as provides an enjakitine on moll s bodies fit immeble one
</pre></div>


<p>看得出來LSTM想表達什麼嗎，哈哈！</p></dd>
                <dt>2017 / 11月 19</dt>
                <dd><a href="./tensorflow-tutorial_5.html">實作Tensorflow (5)：Word2Vec</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p>機器有辦法自行從文本中觀察出詞彙間的相似度嗎？是可以的，word2vec是"word to vector"的縮寫，代表的正是將每個字轉換成向量，而一旦兩個字的向量越是靠近，就代表它的相似度越高，我們究竟要如何得到這些向量呢？方法簡單但出奇有效，文章的最後會向大家呈現它的精彩的結果。</p>
<p>本單元程式碼Skip-Gram Word2Vec部分可於<a href="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/05_1_word2vec_SkipGram.py">Github</a>下載，CBOW Word2Vec部分可於<a href="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/05_2_word2vec_CBOW.py">Github</a>下載。</p>
<p><br/></p>
<h5><u>Word2Vec觀念解析</u></h5>
<p>Word2Vec的形式和Autoencoder有點像，一樣是從高維度的空間轉換到低維度的空間，再轉換回去原本的維度，只是這一次轉回去的東西不再是原本一模一樣的東西了。</p>
<p>Word2Vec的Input和Output這次變成是上下文的文字組合，舉個例子，"by the way"這個用法如果多次被機器看過的話，機器是有辦法去學習到這樣的規律的，此時"by"與"the"和"way"便會產生一個上下文的關聯性，為了將這樣的關聯性建立起來，我們希望當我輸入"by"時，機器有辦法預測並輸出"the"或"way"，這代表在機器內部它已經學習到了上下文的關聯性。</p>
<p>那如果今天這個機器也同時看到很多次的"on the way"這種用法，所以當我輸入"on"時，機器要有辦法預測並輸出"the"或"way"，但是我們不希望"on"和"by"兩個詞在學習時是分開學習的，我們希望機器可以因為"by the way"和"on the way"的結構很相似，所以有辦法抓出"on"和"by"是彼此相似的結論。</p>
<p>如何做到呢？答案就是限縮這個上下文的關聯性的儲存維度，如果我的字彙量有1000個，這1000個字彙彼此有上下文的關聯性，最完整表示上下文關聯性的方法就是設置一個1000x1000或者更大的表格，把所有字彙間的上下文關聯性全部存起來，但我們不想要這麼做，我要求機器用更小的表格來儲存上下文的關聯性，此時機器被迫將一些詞彙使用同樣的表格位置，同樣的轉換。一旦限縮了上下文關聯性的儲存維度，"on the way"和"by the way"中的"on"和"by"就會被迫分為同一類，因此我們成功的建立了字詞間的相似性關係。</p>
<h5><u>Word2Vec的架構</u></h5>
<p><img alt="word2vec" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.008.jpeg"></p>
<p>實作上如上圖所示，我們輸入一個字詞，譬如"cat"，通常會將他轉成One-hot encoding表示，但要注意喔！文本的字彙量是非常龐大的，所以當我們使用One-hot encoding表示時，將會出現一個非常長但Sparse的向量，相同的輸出層也同樣是一個很長的One-hot encoding，它的維度會和輸入層一樣大，因為我們要分析的字彙在輸入和輸出是一樣多的。</p>
<p>然後，和Autoencoder使用一樣的手法，中間的Hidden Layer放置低維度、少神經元的一層，但不同於Autoencoder，Word2Vec所有的轉換都是線性的，沒有非線性的Activation Function夾在其中，為什麼呢？因為我們的輸入是Sparse的而且只有0和1的差別，所以每一條通路就變成只有導通或不導通的差別，Activation Function有加等於沒加，使用線性就足夠了。</p>
<p>這個中間的Hidden Layer被稱為Embedding Matrix，它做了一個線性的Dimension Reduction，將原本高維度的One-hot encoding降低成低維度，然後再透過一個線性模型轉換回去原本的維度。假設字彙的數量有N個，所以輸入矩陣X是一個1xN的矩陣，輸出的矩陣同樣也是1xN的矩陣，當我先做一個線性的Dimension Reduction，將維度降到d維，此時Embedding Matrix會是一個Nxd的矩陣V，然後再由線性模型轉換回去原本的維度，這個轉換矩陣W是一個Nxd矩陣，因此綜合上述，可用一個簡潔的表示式表示：Y=W<sup>T</sup>VX，我們的目標就是找出這個W和V矩陣的每個元素。</p>
<p>你會想說線性模型很簡單啊！就是仿照Autoencoder的作法，然後把Activation Function拿掉不就了事了，並且因為輸出是One-hot Encoding所以最後套用Softmax，那不就輕鬆完成！但是真正的大魔王就出在字彙量，字彙量一旦很大，事情就變得不可收拾了，而且字彙量是一定小不得的，那怎麼辦？</p>
<p>在Dimension Reduction我們可以採取一個快速的方法，因為除了我要表示的字的位置是1以外其他都是0，所以其他都可以不看，我們就直接看是在第幾個位置上是1，然後再到Embedding Matrix上找到相應的行直接取出就是答案了，這樣查詢的動作，在Tensorflow中可以使用<code>tf.nn.embedding_lookup</code>來辦到。</p>
<p>再接下來最後的Cross-Entropy Loss計算也非常龐大，因為有幾個字彙就需要累加幾組數字，我們有一招偷吃步的方法叫做「Sampled Softmax」，作法是這樣的，我們不去計算全部詞彙的Cross-Entropy，而是選擇幾組詞彙來評估Cross-Entropy，在選擇上我們會隨機挑選一些Labels和預測結果差異度很大的詞彙(稱為Negative Examples)來算Cross-Entropy，我們在Tensorflow可以使用<code>tf.nn.sampled_softmax_loss</code>來辦到「Sampled Softmax」。</p>
<p>我們先不管輸入和輸出究竟怎麼取得，如果我們成功的建立了輸入和輸出的上下文關係，此時中間的Embedding空間正是精華的所在，經過剛剛推論，我們預期在這個空間當中，相似的詞彙會彼此靠近，我們評估兩個向量的相似性可以使用Cosine來評估，當兩向量的夾角越小代表它們越是相似，待會的實作當中我們將會利用Cosine來建立Similarity的大小，藉此來找到前幾個和它很靠近的詞彙。</p>
<p>另外，經研究指出這個Embedding空間的效果不只是可以算出詞彙間的相似性，還可以顯示詞彙間的比較關係，例如：北京之於中國，等同於台北之於台灣，這樣的比較關係也顯示在這個Embedding空間裡頭，所以在這空間裡會有以下的向量關係式：V<sub>北京</sub>-V<sub>中國</sub>+V<sub>台灣</sub>=V<sub>台北</sub>，是不是很神奇啊！</p>
<p><br/></p>
<h5><u>Word2Vec的兩種常用方法：Skip-Gram和CBOW</u></h5>
<p><img alt="Skip-Gram和CBOW" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.009.jpeg"></p>
<p>剛剛一直在講的是中間的結構應該怎麼建立，現在來看看我們可以輸入和輸出哪些詞彙來建立起上下文的關係，有兩種常用的類別：Skip-Gram和CBOW。</p>
<p>Skip-Gram如上圖所示，當我輸入一個word(t)時，我希望它能輸出它的前文和後文，這是相當直覺的建立上下文的方法，所以如果我希望用前一個字和後一個字來訓練我的Word2Vec，我就會有兩組數據：(w(t),w(t-1))和(w(t),w(t+1))，相當好理解。</p>
<p>而CBOW(Continuous Bag of Words)使用另外一種方法來建立上下文關係，它將一排字挖掉中間一個字，然後希望由上下文的關係有辦法猜出中間那個字，就像是填空題，此時輸入層就變成會有多於1個字，那該怎麼處理，答案是轉換到Embedding空間後再相加平均，因為是線性轉換，所以直接線性累加就可以了。</p>
<p><br/></p>
<h5><u>準備文本語料庫</u></h5>
<p>先帶入一些待會會用到的函式庫，並且決定我們要取用多少<code>VOCABULARY_SIZE</code>個詞彙量來做訓練。</p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">generators</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">six.moves.urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">VOCABULARY_SIZE</span> <span class="o">=</span> <span class="mi">100000</span>
</pre></div>


<p>接下來下載Dataset，並做一些前處理。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">maybe_download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">filename</span><span class="p">,</span> <span class="n">expected_bytes</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Download a file if not present, and make sure it&#39;s the right size.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">filename</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
  <span class="n">statinfo</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">stat</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span> <span class="o">==</span> <span class="n">expected_bytes</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Found and verified </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
      <span class="s1">&#39;Failed to verify &#39;</span> <span class="o">+</span> <span class="n">filename</span> <span class="o">+</span> <span class="s1">&#39;. Can you get to it with a browser?&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">filename</span>

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Extract the first file enclosed in a zip file as a list of words&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">as_str</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">namelist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">,</span><span class="n">vocabulary_size</span><span class="o">=</span><span class="n">VOCABULARY_SIZE</span><span class="p">):</span>
  <span class="n">count</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;UNK&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
  <span class="n">count</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">vocabulary_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">dictionary</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">count</span><span class="p">:</span>
    <span class="n">dictionary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
  <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
  <span class="n">unk_count</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
      <span class="n">index</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># dictionary[&#39;UNK&#39;]</span>
      <span class="n">unk_count</span> <span class="o">=</span> <span class="n">unk_count</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
  <span class="n">count</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">unk_count</span>
  <span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span> 
  <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Downloading text8.zip&quot;</span><span class="p">)</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">maybe_download</span><span class="p">(</span><span class="s1">&#39;http://mattmahoney.net/dc/text8.zip&#39;</span><span class="p">,</span><span class="s1">&#39;./text8.zip&#39;</span><span class="p">,</span> <span class="mi">31344016</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;=====&quot;</span><span class="p">)</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Data size </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;First 10 words: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">words</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;=====&quot;</span><span class="p">)</span>
<span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="n">build_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">,</span>
                                                            <span class="n">vocabulary_size</span><span class="o">=</span><span class="n">VOCABULARY_SIZE</span><span class="p">)</span>
<span class="k">del</span> <span class="n">words</span>  <span class="c1"># Hint to reduce memory.</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Most common words (+UNK)&#39;</span><span class="p">,</span> <span class="n">count</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Sample data&#39;</span><span class="p">,</span> <span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span></span>Downloading text8.zip
Found and verified ./text8.zip
=====
Data size 17005207
First 10 words: [&#39;anarchism&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;a&#39;, &#39;term&#39;, &#39;of&#39;, &#39;abuse&#39;, &#39;first&#39;, &#39;used&#39;, &#39;against&#39;]
=====
Most common words (+UNK) [[&#39;UNK&#39;, 189230], (&#39;the&#39;, 1061396), (&#39;of&#39;, 593677), (&#39;and&#39;, 416629), (&#39;one&#39;, 411764)]
Sample data [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156]
</pre></div>


<p>我們取用<code>VOCABULARY_SIZE = 100000</code>，也是說我們將文本中的詞彙按出現次數的多寡來排列，取前面<code>VOCABULARY_SIZE</code>個保留，其餘詞彙皆歸類到「UNK Token」裡頭，UNK代表UNKnown的縮寫。</p>
<p>我們文本的字詞數量總共有17005207個字，開頭前十個字的句子是'anarchism originated as a term of abuse first used against'。所有的這17005207個字會依照<code>dictionary</code>給予每個字Index，而文本會被表示為一個由整數所構成的List，這會放在<code>data</code>裡頭，而這個Index也就直接當作One-hot Encoding中代表這個詞彙的維度位置。當我想要把Index轉換回去我們看得懂的字的時候，就需要<code>reverse_dictionary</code>的幫忙，有了這些，我們的語料庫就已經建立完成了。</p>
<p><br/></p>
<h5><u>實作Skip-Gram</u></h5>
<p>有了語料庫，我們就可以產生出我想要的輸入和輸出，在Skip-Gram方法，如果我的輸入是<code>target word</code>，我會先從<code>target word</code>向前、向後看出去<code>skip_window</code>的大小，所以可以選擇當作輸出的字有<code>skip_window*2</code>個，接下來我從這<code>skip_window*2</code>個中選擇<code>num_skips</code>個當作輸出，所以一個<code>target word</code>會產生<code>num_skips</code>筆數據，如果我一個batch需要<code>batch_size</code>筆數據，我就必須有<code>batch_size//num_skips</code>個<code>target word</code>，依照這樣的規則下面建立一個Generator來掃描文本，並輸出要訓練使用的Batch Data。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">skip_gram_batch_generator</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="n">num_skips</span><span class="p">,</span><span class="n">skip_window</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">num_skips</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">num_skips</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">skip_window</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">span</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">skip_window</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># [ skip_window target skip_window ]</span>
    <span class="nb">buffer</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">span</span><span class="p">)</span>

    <span class="c1"># initialization</span>
    <span class="n">data_index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">span</span><span class="p">):</span>
        <span class="nb">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">])</span>
        <span class="n">data_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># generate</span>
    <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">skip_window</span>  <span class="c1"># target label at the center of the buffer</span>
        <span class="n">targets_to_avoid</span> <span class="o">=</span> <span class="p">[</span> <span class="n">target</span> <span class="p">]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_skips</span><span class="p">):</span>
            <span class="k">while</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">targets_to_avoid</span><span class="p">:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">span</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">targets_to_avoid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">[</span><span class="n">skip_window</span><span class="p">]</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
            <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Recycle </span>
        <span class="k">if</span> <span class="n">data_index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span> <span class="n">data_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># scan data</span>
        <span class="nb">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">])</span>
        <span class="n">data_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Enough num to output</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

<span class="c1"># demonstrate generator</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;data:&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">]])</span>

<span class="k">for</span> <span class="n">num_skips</span><span class="p">,</span> <span class="n">skip_window</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]:</span>
    <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">skip_gram_batch_generator</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">num_skips</span><span class="o">=</span><span class="n">num_skips</span><span class="p">,</span><span class="n">skip_window</span><span class="o">=</span><span class="n">skip_window</span><span class="p">)</span>
    <span class="n">batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">with num_skips = </span><span class="si">%d</span><span class="s1"> and skip_window = </span><span class="si">%d</span><span class="s1">:&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_skips</span><span class="p">,</span> <span class="n">skip_window</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;    batch:&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;    labels:&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">li</span><span class="p">]</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="n">labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">)])</span>
</pre></div>


<div class="highlight"><pre><span></span>data: [&#39;anarchism&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;a&#39;, &#39;term&#39;, &#39;of&#39;, &#39;abuse&#39;, &#39;first&#39;, &#39;used&#39;, &#39;against&#39;]

with num_skips = 2 and skip_window = 1:
    batch: [&#39;originated&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;as&#39;, &#39;a&#39;, &#39;a&#39;, &#39;term&#39;, &#39;term&#39;]
    labels: [&#39;as&#39;, &#39;anarchism&#39;, &#39;originated&#39;, &#39;a&#39;, &#39;as&#39;, &#39;term&#39;, &#39;a&#39;, &#39;of&#39;]

with num_skips = 4 and skip_window = 2:
    batch: [&#39;as&#39;, &#39;as&#39;, &#39;as&#39;, &#39;as&#39;, &#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;a&#39;]
    labels: [&#39;term&#39;, &#39;anarchism&#39;, &#39;originated&#39;, &#39;a&#39;, &#39;originated&#39;, &#39;term&#39;, &#39;as&#39;, &#39;of&#39;]
</pre></div>


<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SkipGram</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_vocabulary</span><span class="p">,</span><span class="n">n_embedding</span><span class="p">,</span><span class="n">reverse_dictionary</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span> <span class="o">=</span> <span class="n">n_vocabulary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span> <span class="o">=</span> <span class="n">n_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="n">reverse_dictionary</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c1"># initialize new grap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span> <span class="c1"># building graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="c1"># create session by the graph </span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="c1">### Input</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span>  <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

            <span class="c1">### Optimalization</span>
            <span class="c1"># build neurel network structure and get their loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span> <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                                        <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">,</span>
                                      <span class="p">)</span>

            <span class="c1"># normalize embeddings</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                          <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                            <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;embeddings&#39;</span><span class="p">]),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;embeddings&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span>

            <span class="c1"># define training operation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdagradOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1">### Prediction</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_labels</span>  <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span> <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">,</span>
                                            <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">new_labels</span><span class="p">,</span>
                                          <span class="p">)</span>

            <span class="c1"># similarity</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_similarity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_embed</span><span class="p">,</span> 
                                            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span><span class="p">))</span>

            <span class="c1">### Initialization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  

    <span class="k">def</span> <span class="nf">structure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataset</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
        <span class="c1">### Variable</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;embeddings&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span><span class="p">],</span> 
                                                  <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)),</span>
                <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
                             <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span><span class="p">],</span>
                               <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span><span class="p">)))</span>
            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">]))</span>
            <span class="p">}</span>


        <span class="c1">### Structure</span>
        <span class="c1"># Look up embeddings for inputs.</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;embeddings&#39;</span><span class="p">],</span> <span class="n">dataset</span><span class="p">)</span>

        <span class="c1"># Compute the softmax loss, using a sample of the negative labels each time.</span>
        <span class="n">num_softmax_sampled</span> <span class="o">=</span> <span class="mi">64</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
                 <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sampled_softmax_loss</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;softmax&#39;</span><span class="p">],</span> 
                                            <span class="n">biases</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;softmax&#39;</span><span class="p">],</span> 
                                            <span class="n">inputs</span><span class="o">=</span><span class="n">embed</span><span class="p">,</span>
                                            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> 
                                            <span class="n">num_sampled</span><span class="o">=</span><span class="n">num_softmax_sampled</span><span class="p">,</span> 
                                            <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">loss</span>


    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">online_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">):</span>      
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
                     <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">:</span> <span class="n">Y</span><span class="p">}</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">nearest_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">top_nearest</span><span class="p">):</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_similarity</span><span class="p">,</span>
                                   <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>
        <span class="n">X_size</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">valid_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">nearests</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_size</span><span class="p">):</span>
            <span class="n">valid_word</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_word</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">valid_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_word</span><span class="p">)</span>    

            <span class="c1"># select highest similarity word</span>
            <span class="n">nearest</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">similarity</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="n">top_nearest</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>  
            <span class="n">nearests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">find_word</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">nearest</span><span class="p">)))</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">valid_words</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nearests</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">new_labels</span><span class="p">:</span> <span class="n">Y</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">embedding_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">find_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</pre></div>


<p>以上就是我建立的Model，這裡我採取<code>online_fit</code>的方法，不同於之前的<code>fit</code>，<code>online_fit</code>可以不用事先將所有Data一次餵進去，而是可以陸續的餵入Data，所以我會從上面的Generator陸續產生Batch Data並餵入Model裡來做訓練。</p>
<div class="highlight"><pre><span></span><span class="c1"># build skip-gram batch generator</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">skip_gram_batch_generator</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                                            <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                                            <span class="n">num_skips</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                            <span class="n">skip_window</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># build skip-gram model</span>
<span class="n">model_SkipGram</span> <span class="o">=</span> <span class="n">SkipGram</span><span class="p">(</span><span class="n">n_vocabulary</span><span class="o">=</span><span class="n">VOCABULARY_SIZE</span><span class="p">,</span>
                          <span class="n">n_embedding</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                          <span class="n">reverse_dictionary</span><span class="o">=</span><span class="n">reverse_dictionary</span><span class="p">,</span>
                          <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># initial model</span>
<span class="n">model_SkipGram</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

<span class="c1"># online training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_batchs_in_epoch</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batchs_in_epoch</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model_SkipGram</span><span class="o">.</span><span class="n">online_fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                                         <span class="n">Y</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="n">num_batchs_in_epoch</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">: </span><span class="si">%d</span><span class="s2">s loss = </span><span class="si">%9.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span>
                                                   <span class="n">avg_loss</span> <span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>Epoch 1/50: 18s loss =    4.2115
Epoch 2/50: 17s loss =    3.7554
Epoch 3/50: 15s loss =    3.6211
Epoch 4/50: 15s loss =    3.5072
Epoch 5/50: 15s loss =    3.5084
Epoch 6/50: 15s loss =    3.4988
Epoch 7/50: 15s loss =    3.5165
Epoch 8/50: 15s loss =    3.3949
Epoch 9/50: 15s loss =    3.4382
Epoch 10/50: 15s loss =    3.4121
Epoch 11/50: 15s loss =    3.4027
Epoch 12/50: 15s loss =    3.4074
Epoch 13/50: 15s loss =    3.3222
Epoch 14/50: 15s loss =    3.3448
Epoch 15/50: 16s loss =    3.3616
Epoch 16/50: 15s loss =    3.3389
Epoch 17/50: 15s loss =    3.3729
Epoch 18/50: 15s loss =    3.3911
Epoch 19/50: 15s loss =    3.3512
Epoch 20/50: 15s loss =    3.3107
Epoch 21/50: 16s loss =    3.3046
Epoch 22/50: 15s loss =    3.3103
Epoch 23/50: 15s loss =    3.3042
Epoch 24/50: 15s loss =    3.2634
Epoch 25/50: 15s loss =    3.3181
Epoch 26/50: 15s loss =    3.2808
Epoch 27/50: 15s loss =    3.2464
Epoch 28/50: 15s loss =    3.2246
Epoch 29/50: 15s loss =    3.2666
Epoch 30/50: 15s loss =    3.2275
Epoch 31/50: 15s loss =    3.2312
Epoch 32/50: 15s loss =    3.3022
Epoch 33/50: 15s loss =    3.2504
Epoch 34/50: 15s loss =    3.2484
Epoch 35/50: 15s loss =    3.2368
Epoch 36/50: 15s loss =    3.2693
Epoch 37/50: 15s loss =    3.2177
Epoch 38/50: 15s loss =    3.2395
Epoch 39/50: 15s loss =    3.2151
Epoch 40/50: 15s loss =    3.0505
Epoch 41/50: 15s loss =    2.9364
Epoch 42/50: 15s loss =    3.1546
Epoch 43/50: 15s loss =    3.1810
Epoch 44/50: 15s loss =    3.2778
Epoch 45/50: 15s loss =    3.1340
Epoch 46/50: 15s loss =    3.2218
Epoch 47/50: 15s loss =    3.2395
Epoch 48/50: 15s loss =    3.2422
Epoch 49/50: 15s loss =    3.0131
Epoch 50/50: 15s loss =    3.1287
</pre></div>


<p>我們來看看效果如何，我們使用Embedding Vectors彼此間的Cosine來定義出字詞間的相關性，並且列出8個最為靠近的字詞。</p>
<div class="highlight"><pre><span></span><span class="n">valid_words_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">210</span><span class="p">,</span><span class="mi">239</span><span class="p">,</span><span class="mi">392</span><span class="p">,</span><span class="mi">396</span><span class="p">])</span>

<span class="n">valid_words</span><span class="p">,</span> <span class="n">nearests</span> <span class="o">=</span> <span class="n">model_SkipGram</span><span class="o">.</span><span class="n">nearest_words</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">valid_words_index</span><span class="p">,</span><span class="n">top_nearest</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_words</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Nearest to &#39;{}&#39;: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_words</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="n">nearests</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span></span>Nearest to &#39;two&#39;:  [&#39;three&#39; &#39;four&#39; &#39;five&#39; &#39;eight&#39; &#39;six&#39; &#39;seven&#39; &#39;nine&#39; &#39;one&#39;]
Nearest to &#39;that&#39;:  [&#39;which&#39; &#39;however&#39; &#39;eophona&#39; &#39;clemency&#39; &#39;invariants&#39; &#39;ratchet&#39; &#39;what&#39;
 &#39;fiona&#39;]
Nearest to &#39;his&#39;:  [&#39;her&#39; &#39;their&#39; &#39;my&#39; &#39;your&#39; &#39;its&#39; &#39;our&#39; &#39;thy&#39; &#39;witchcraft&#39;]
Nearest to &#39;were&#39;:  [&#39;are&#39; &#39;was&#39; &#39;include&#39; &#39;have&#39; &#39;cyanobacterial&#39; &#39;seem&#39; &#39;be&#39; &#39;those&#39;]
Nearest to &#39;all&#39;:  [&#39;both&#39; &#39;various&#39; &#39;many&#39; &#39;counting&#39; &#39;some&#39; &#39;every&#39; &#39;several&#39; &#39;risked&#39;]
Nearest to &#39;area&#39;:  [&#39;region&#39; &#39;areas&#39; &#39;suctoria&#39; &#39;regions&#39; &#39;island&#39; &#39;pwned&#39; &#39;territory&#39;
 &#39;plains&#39;]
Nearest to &#39;east&#39;:  [&#39;west&#39; &#39;eastern&#39; &#39;southeast&#39; &#39;south&#39; &#39;southwest&#39; &#39;curable&#39; &#39;north&#39;
 &#39;hispaniolan&#39;]
Nearest to &#39;himself&#39;:  [&#39;him&#39; &#39;themselves&#39; &#39;them&#39; &#39;itself&#39; &#39;megalith&#39; &#39;herself&#39; &#39;successfully&#39;
 &#39;armas&#39;]
Nearest to &#39;white&#39;:  [&#39;red&#39; &#39;black&#39; &#39;blue&#39; &#39;yellow&#39; &#39;green&#39; &#39;overdraft&#39; &#39;horse&#39; &#39;dark&#39;]
</pre></div>


<p>結果相當驚人，與'two'靠近的真的都是數字類型的文字，與'that'靠近的都是文法功能性的詞彙，與'his'靠近的都是所有格代名詞，與'were'靠近的是be動詞，與'all'最靠近的是'both'，與'east'靠近的都是一些代表方向的詞彙，與'white'靠近的都是一些顏色的詞彙，真的是太神奇了！</p>
<p>接下來直接來觀察Embedding空間，以下使用t-SNE來圖像化Embedding空間。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="s1">&#39;More labels than embeddings&#39;</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>  <span class="c1"># in inches</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span>
        <span class="n">pylab</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
        <span class="n">pylab</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">,</span>
                   <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">visualization_words</span> <span class="o">=</span> <span class="mi">800</span>
<span class="c1"># transform embeddings to 2D by t-SNE</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">model_SkipGram</span><span class="o">.</span><span class="n">embedding_matrix</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="n">visualization_words</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">perplexity</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;exact&#39;</span><span class="p">)</span>
<span class="n">two_d_embed</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
<span class="c1"># list labels</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_SkipGram</span><span class="o">.</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">visualization_words</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="c1"># plot</span>
<span class="n">plot</span><span class="p">(</span><span class="n">two_d_embed</span><span class="p">,</span><span class="n">words</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/05_output_13_0.png"></p>
<p>如此一來你將可以簡單的看出，哪些詞彙彼此相似而靠近。</p>
<p><br/></p>
<h5><u>實作CBOW (Continuous Bag of Words)</u></h5>
<p>接著看CBOW的方法，如果我預期輸出的字是<code>target word</code>，從<code>target word</code>向前向後看出去<code>context_window</code>的大小，看到的字都當作我的輸入，所以我輸入的字總共需要<code>context_window*2</code>個，一個<code>target word</code>只會產生一筆數據，如果我一個batch需要<code>batch_size</code>筆數據，我就必須有<code>batch_size</code>個<code>target word</code>，依照這樣的規則下面建立一個Generator來掃描文本，並輸出要訓練使用的Batch Data。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cbow_batch_generator</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="n">context_window</span><span class="p">):</span>
    <span class="n">span</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">context_window</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># [ context_window target context_window ]</span>
    <span class="n">num_bow</span> <span class="o">=</span> <span class="n">span</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_bow</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="nb">buffer</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">span</span><span class="p">)</span>

    <span class="c1"># initialization</span>
    <span class="n">data_index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">span</span><span class="p">):</span>
        <span class="nb">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">])</span>
        <span class="n">data_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># generate</span>
    <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">context_window</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>        
        <span class="n">bow</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">bow</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bow</span><span class="p">):</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Recycle </span>
        <span class="k">if</span> <span class="n">data_index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span> <span class="n">data_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># scan data</span>
        <span class="nb">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">])</span>
        <span class="n">data_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Enough num to output</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>



<span class="c1"># demonstrate generator</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;data:&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">di</span><span class="p">]</span> <span class="k">for</span> <span class="n">di</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">]])</span>

<span class="k">for</span> <span class="n">context_window</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]:</span>
    <span class="n">batch_generator</span> <span class="o">=</span> <span class="n">cbow_batch_generator</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                           <span class="n">context_window</span><span class="o">=</span><span class="n">context_window</span><span class="p">)</span>
    <span class="n">batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">with context_window = </span><span class="si">%d</span><span class="s1">:&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">context_window</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;batch:&#39;</span><span class="p">)</span>
    <span class="n">show_batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]])</span>
        <span class="n">show_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">show_batch</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;labels:&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">li</span><span class="p">]</span> <span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="n">labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">8</span><span class="p">)])</span>
</pre></div>


<div class="highlight"><pre><span></span>data: [&#39;anarchism&#39;, &#39;originated&#39;, &#39;as&#39;, &#39;a&#39;, &#39;term&#39;, &#39;of&#39;, &#39;abuse&#39;, &#39;first&#39;, &#39;used&#39;, &#39;against&#39;]

with context_window = 1:
batch:
[[&#39;anarchism&#39;, &#39;as&#39;], [&#39;originated&#39;, &#39;a&#39;], [&#39;as&#39;, &#39;term&#39;], [&#39;a&#39;, &#39;of&#39;], [&#39;term&#39;, &#39;abuse&#39;], [&#39;of&#39;, &#39;first&#39;], [&#39;abuse&#39;, &#39;used&#39;], [&#39;first&#39;, &#39;against&#39;]]
labels: [&#39;originated&#39;, &#39;as&#39;, &#39;a&#39;, &#39;term&#39;, &#39;of&#39;, &#39;abuse&#39;, &#39;first&#39;, &#39;used&#39;]

with context_window = 2:
batch:
[[&#39;anarchism&#39;, &#39;originated&#39;, &#39;a&#39;, &#39;term&#39;], [&#39;originated&#39;, &#39;as&#39;, &#39;term&#39;, &#39;of&#39;], [&#39;as&#39;, &#39;a&#39;, &#39;of&#39;, &#39;abuse&#39;], [&#39;a&#39;, &#39;term&#39;, &#39;abuse&#39;, &#39;first&#39;], [&#39;term&#39;, &#39;of&#39;, &#39;first&#39;, &#39;used&#39;], [&#39;of&#39;, &#39;abuse&#39;, &#39;used&#39;, &#39;against&#39;], [&#39;abuse&#39;, &#39;first&#39;, &#39;against&#39;, &#39;early&#39;], [&#39;first&#39;, &#39;used&#39;, &#39;early&#39;, &#39;working&#39;]]
labels: [&#39;as&#39;, &#39;a&#39;, &#39;term&#39;, &#39;of&#39;, &#39;abuse&#39;, &#39;first&#39;, &#39;used&#39;, &#39;against&#39;]
</pre></div>


<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CBOW</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_vocabulary</span><span class="p">,</span><span class="n">n_embedding</span><span class="p">,</span><span class="n">context_window</span><span class="p">,</span><span class="n">reverse_dictionary</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span> <span class="o">=</span> <span class="n">n_vocabulary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span> <span class="o">=</span> <span class="n">n_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_window</span> <span class="o">=</span> <span class="n">context_window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="n">reverse_dictionary</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c1"># initialize new grap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span> <span class="c1"># building graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="c1"># create session by the graph </span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="c1">### Input</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_window</span><span class="o">*</span><span class="mi">2</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span>  <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

            <span class="c1">### Optimalization</span>
            <span class="c1"># build neurel network structure and get their predictions and loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span> <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
                                        <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">,</span>
                                      <span class="p">)</span>

            <span class="c1"># normalize embeddings</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                          <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                            <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;embeddings&#39;</span><span class="p">]),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;embeddings&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span>

            <span class="c1"># define training operation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdagradOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1">### Prediction</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_labels</span>  <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

            <span class="c1"># similarity</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">new_similarity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_embed</span><span class="p">,</span> 
                                            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span><span class="p">))</span>

            <span class="c1">### Initialization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  

    <span class="k">def</span> <span class="nf">structure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dataset</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
        <span class="c1">### Variable</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;embeddings&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
                                <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span><span class="p">],</span>
                                                  <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)),</span>
                <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
                             <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span><span class="p">],</span>
                               <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_embedding</span><span class="p">)))</span>
            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;softmax&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">]))</span>
            <span class="p">}</span>


        <span class="c1">### Structure</span>
        <span class="c1"># Look up embeddings for inputs.</span>
        <span class="n">embed_bow</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;embeddings&#39;</span><span class="p">],</span> <span class="n">dataset</span><span class="p">)</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">embed_bow</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute the softmax loss, using a sample of the negative labels each time.</span>
        <span class="n">num_softmax_sampled</span> <span class="o">=</span> <span class="mi">64</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
                 <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sampled_softmax_loss</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;softmax&#39;</span><span class="p">],</span> 
                                            <span class="n">biases</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;softmax&#39;</span><span class="p">],</span> 
                                            <span class="n">inputs</span><span class="o">=</span><span class="n">embed</span><span class="p">,</span>
                                            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> 
                                            <span class="n">num_sampled</span><span class="o">=</span><span class="n">num_softmax_sampled</span><span class="p">,</span> 
                                            <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vocabulary</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">loss</span>


    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">online_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">):</span>      
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
                     <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">:</span> <span class="n">Y</span><span class="p">}</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">nearest_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">top_nearest</span><span class="p">):</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_similarity</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>
        <span class="n">X_size</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">valid_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">nearests</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_size</span><span class="p">):</span>
            <span class="n">valid_word</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_word</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">valid_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_word</span><span class="p">)</span>    

            <span class="c1"># select highest similarity word</span>
            <span class="n">nearest</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">similarity</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="n">top_nearest</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">nearests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">find_word</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">nearest</span><span class="p">)))</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">valid_words</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nearests</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_dataset</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">new_labels</span><span class="p">:</span> <span class="n">Y</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">embedding_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">normalized_embeddings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">find_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">context_window</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># build CBOW batch generator</span>
<span class="n">batch_generator</span> <span class="o">=</span> <span class="n">cbow_batch_generator</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                                       <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                                       <span class="n">context_window</span><span class="o">=</span><span class="n">context_window</span><span class="p">)</span>

<span class="c1"># build CBOW model</span>
<span class="n">model_CBOW</span> <span class="o">=</span> <span class="n">CBOW</span><span class="p">(</span><span class="n">n_vocabulary</span><span class="o">=</span><span class="n">VOCABULARY_SIZE</span><span class="p">,</span>
                  <span class="n">n_embedding</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                  <span class="n">context_window</span><span class="o">=</span><span class="n">context_window</span><span class="p">,</span>
                  <span class="n">reverse_dictionary</span><span class="o">=</span><span class="n">reverse_dictionary</span><span class="p">,</span>
                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># initialize model</span>
<span class="n">model_CBOW</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

<span class="c1"># online training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_batchs_in_epoch</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batchs_in_epoch</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model_CBOW</span><span class="o">.</span><span class="n">online_fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
                                     <span class="n">Y</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="n">num_batchs_in_epoch</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">: </span><span class="si">%d</span><span class="s2">s loss = </span><span class="si">%9.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span>
                                                   <span class="n">avg_loss</span> <span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>Epoch 1/50: 14s loss =    3.8643
Epoch 2/50: 14s loss =    3.2952
Epoch 3/50: 14s loss =    3.1950
Epoch 4/50: 14s loss =    3.1204
Epoch 5/50: 14s loss =    3.0737
Epoch 6/50: 14s loss =    3.0243
Epoch 7/50: 14s loss =    2.9382
Epoch 8/50: 14s loss =    2.9539
Epoch 9/50: 14s loss =    2.9690
Epoch 10/50: 14s loss =    2.9003
Epoch 11/50: 14s loss =    2.8737
Epoch 12/50: 14s loss =    2.8308
Epoch 13/50: 14s loss =    2.8444
Epoch 14/50: 14s loss =    2.7676
Epoch 15/50: 14s loss =    2.7811
Epoch 16/50: 14s loss =    2.7926
Epoch 17/50: 14s loss =    2.7528
Epoch 18/50: 14s loss =    2.7552
Epoch 19/50: 14s loss =    2.7353
Epoch 20/50: 14s loss =    2.6232
Epoch 21/50: 14s loss =    2.5206
Epoch 22/50: 14s loss =    2.7120
Epoch 23/50: 14s loss =    2.6625
Epoch 24/50: 14s loss =    2.7351
Epoch 25/50: 14s loss =    2.5335
Epoch 26/50: 14s loss =    2.6600
Epoch 27/50: 14s loss =    2.6636
Epoch 28/50: 14s loss =    2.5972
Epoch 29/50: 14s loss =    2.5400
Epoch 30/50: 14s loss =    2.6047
Epoch 31/50: 14s loss =    2.5544
Epoch 32/50: 14s loss =    2.5932
Epoch 33/50: 14s loss =    2.5554
Epoch 34/50: 14s loss =    2.5256
Epoch 35/50: 14s loss =    2.5664
Epoch 36/50: 14s loss =    2.5977
Epoch 37/50: 14s loss =    2.5392
Epoch 38/50: 14s loss =    2.5666
Epoch 39/50: 14s loss =    2.5123
Epoch 40/50: 14s loss =    2.5169
Epoch 41/50: 14s loss =    2.4920
Epoch 42/50: 14s loss =    2.4872
Epoch 43/50: 14s loss =    2.5512
Epoch 44/50: 14s loss =    2.4895
Epoch 45/50: 14s loss =    2.5202
Epoch 46/50: 14s loss =    2.5011
Epoch 47/50: 14s loss =    2.2540
Epoch 48/50: 14s loss =    2.4145
Epoch 49/50: 14s loss =    2.4916
Epoch 50/50: 14s loss =    2.4924
</pre></div>


<div class="highlight"><pre><span></span><span class="n">valid_words_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">210</span><span class="p">,</span><span class="mi">239</span><span class="p">,</span><span class="mi">392</span><span class="p">,</span><span class="mi">396</span><span class="p">])</span>

<span class="n">valid_words</span><span class="p">,</span> <span class="n">nearests</span> <span class="o">=</span> <span class="n">model_CBOW</span><span class="o">.</span><span class="n">nearest_words</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">valid_words_index</span><span class="p">,</span><span class="n">top_nearest</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_words</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Nearest to &#39;{}&#39;: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_words</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="n">nearests</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span></span>Nearest to &#39;two&#39;:  [&#39;three&#39; &#39;four&#39; &#39;five&#39; &#39;six&#39; &#39;seven&#39; &#39;eight&#39; &#39;one&#39; &#39;xx&#39;]
Nearest to &#39;that&#39;:  [&#39;which&#39; &#39;however&#39; &#39;furthermore&#39; &#39;what&#39; &#39;nevertheless&#39; &#39;imaginable&#39;
 &#39;assemblage&#39; &#39;where&#39;]
Nearest to &#39;his&#39;:  [&#39;her&#39; &#39;their&#39; &#39;my&#39; &#39;your&#39; &#39;its&#39; &#39;whose&#39; &#39;our&#39; &#39;dufay&#39;]
Nearest to &#39;were&#39;:  [&#39;are&#39; &#39;remain&#39; &#39;include&#39; &#39;have&#39; &#39;was&#39; &#39;tend&#39; &#39;those&#39; &#39;appear&#39;]
Nearest to &#39;all&#39;:  [&#39;both&#39; &#39;various&#39; &#39;unacknowledged&#39; &#39;every&#39; &#39;faked&#39; &#39;aurangazeb&#39; &#39;some&#39;
 &#39;many&#39;]
Nearest to &#39;area&#39;:  [&#39;region&#39; &#39;areas&#39; &#39;regions&#39; &#39;land&#39; &#39;campus&#39; &#39;streets&#39; &#39;harbour&#39; &#39;tacos&#39;]
Nearest to &#39;east&#39;:  [&#39;west&#39; &#39;south&#39; &#39;southwest&#39; &#39;north&#39; &#39;northeast&#39; &#39;eastern&#39; &#39;southeast&#39;
 &#39;highlights&#39;]
Nearest to &#39;himself&#39;:  [&#39;him&#39; &#39;themselves&#39; &#39;them&#39; &#39;itself&#39; &#39;herself&#39; &#39;papp&#39; &#39;aafk&#39; &#39;heartbroken&#39;]
Nearest to &#39;white&#39;:  [&#39;red&#39; &#39;black&#39; &#39;blue&#39; &#39;dark&#39; &#39;yellow&#39; &#39;culturally&#39; &#39;dead&#39; &#39;angelman&#39;]
</pre></div>


<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pylab</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="s1">&#39;More labels than embeddings&#39;</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>  <span class="c1"># in inches</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span>
        <span class="n">pylab</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
        <span class="n">pylab</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">,</span>
                   <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">visualization_words</span> <span class="o">=</span> <span class="mi">800</span>
<span class="c1"># transform embeddings to 2D by t-SNE</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">model_CBOW</span><span class="o">.</span><span class="n">embedding_matrix</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="n">visualization_words</span><span class="o">+</span><span class="mi">1</span><span class="p">,:]</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">perplexity</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;exact&#39;</span><span class="p">)</span>
<span class="n">two_d_embed</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
<span class="c1"># list labels</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_CBOW</span><span class="o">.</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">visualization_words</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="c1"># plot</span>
<span class="n">plot</span><span class="p">(</span><span class="n">two_d_embed</span><span class="p">,</span><span class="n">words</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/05_output_20_0.png"></p>
<p><br/></p>
<h5><u>Reference</u></h5>
<ul>
<li>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb</li>
</ul></dd>
                <dt>2017 / 11月 18</dt>
                <dd><a href="./tensorflow-tutorial_4.html">實作Tensorflow (4)：Autoencoder</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p>Autoencoder是一個Neurel Network重要的工具，我個人認為它還漂亮的呈現Neurel Network的強大。</p>
<p>本單元程式碼Autoencoder部分可於<a href="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/04_1_Autoencoder_on_MNIST.py">Github</a>下載，De-noise Autoencoder部分可於<a href="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/code/04_2_DenoiseAutoencoder_on_MNIST.py">Github</a>下載。</p>
<p><br/></p>
<h5><u>Autoencoder觀念解析</u></h5>
<p>在「機器學習技法」的系列文章，我也<a href="http://www.ycc.idv.tw/YCNote/post/35">曾經介紹過Autoencoder</a>，可以搭配這篇服用。</p>
<p>Autoencoder概念很簡單，就是做資訊的壓縮，概念是這樣的，當我在一層當中使用神經元愈多，可以儲存的資訊量也就愈多，相反的神經元越少，可以儲存的資訊量越少，如果我要使用Neurel Network作資料壓縮的話，我希望的是可以使用比原本更少的資訊量來儲存，如果原本是一張MNIST的圖，有28x28=784個Pixels，所以可以想知，如果我要作壓縮就要使得壓縮後的神經元可以比784個更少。</p>
<p>但是什麼都不做我們就可以平白無故的做到壓縮？當然不行，我們還得從資料中找到一些規律，套用這些規律把多餘的東西去除，留下精髓，我們才可以把資料作壓縮，所以在實作上我們會建立一個神經元由大到小的Neurel Network，逐步的轉換，逐步的壓縮資訊。</p>
<p>那麼壓縮的目的是為了什麼？當然是有辦法還原回去原本狀態，這樣的壓縮才是有意義的，例如：將文檔打包成RAR，檔案大小會變小，但如果實際要再使用這個檔案，那就必須先做解壓縮，然後還原回去原本的檔案，這裡的還原率必須是百分之一百的，Autoencoder一樣的有一個機制可以還原，在實作上我們會建立一個神經元由小到大的Neurel Network，逐步的還原回去原本的狀態。</p>
<p>因此一個Autoencoder的圖像就出現了，我們需要有一組「Encoder」來逐步的壓縮，最後留下非常精簡的「Embedding Code」，而這組「Embedding Code」可以再經由「Decoder」還原回去原本的樣子，那我們怎麼讓他自己產生「Encoder」和「Decoder」呢？把原本的Input當作Output的目標答案去訓練Neurel Network就可以了，這就是Autoencoder巧妙的地方。</p>
<p>不管是「Encoder」還是「Decoder」他們的權重是可以調整的，所以如果你將Encoder+Decoder的結構建立好並搭配Input當作Output的目標答案，它在Training的過程，Autoencoder會試著找出最好的權重來使得資訊可以盡量完整還原回去，所以Autoencoder可以自行找出了Encoder和Decoder。</p>
<p>Encoder的效果等同於做Dimension Reduction，Encoder轉換原本數據到一個新的空間，這個空間可以比原本Features描述的空間更能精簡的描述這群數據，而中間這層Layer的數值Embedding Code就是新空間裡頭的座標，有些時候我們會用這個新空間來判斷每筆Data之間彼此的接近程度。</p>
<p><img alt="autoencoder" src="https://github.com/GitYCC/Tensorflow_Tutorial/blob/master/img/TensorflowTutorial.007.jpeg?raw=true"></p>
<p><br/></p>
<h5><u>Autoencoder程式碼</u></h5>
<p>實現Autoencoder和之前DNN並沒有太大的差異，只有兩點要特別提醒一下。</p>
<p>第一點，以下我會特別把<code>encoder</code>額外的在<code>structure</code>裡頭輸出出來，並且增加新的函數<code>encode</code>，讓使用者可以使用Train好的Encoder來做Encode。</p>
<p>第二點，以下的Regularizer不是採用單純的L2 Regularizer，我將會使用Weight-Elimination L2 Regularizer，這個Regularizer的好處是會使得權重接近Sparse，也就是說權重會留下比較多的0，這有一個好處，就是每個神經元彼此之間的依賴減少了，因為內積(評估相依性)時有0的那個維度將不會有所貢獻。</p>
<p>Weight-Elimination L2 Regularizer有這樣的效果原因是這樣的，L2 Regularizer在抑制W的方法是，如果W的分量大的話就抑制多一點，如果分量小就抑制少一點（因為W<sup>2</sup>微分為一次），所以最後會留下很多不為0的微小分量，不夠Sparse，這樣的Regularization顯然不夠好，L1 Regularizer可以解決這個問題（因為在大部分位置微分為常數），但不幸的是它無法微分，沒辦法作Backpropagation，所以就有了L2 Regularizer的衍生版本，</p>
<p>Weight-elimination L2 regularizer: 𝚺[(W<sub>jk</sub>(ℓ))<sup>2</sup>]/[1+(W<sub>jk</sub>(ℓ))<sup>2</sup>]</p>
<p>這麼一來不管W大或小，它受到抑制的值大小接近的 (Weight-elimination L2 regularizer微分為 -1次方)，因此就可以使得部分W可以為0，達成Sparse的目的。</p>
<p>那為什麼我要特別在Autoencoder講究Sparse特性呢？原因是我們現在正在做的事是Dimension Reduction，做這件事就好像是替原本空間找出新的軸，而這個軸的數量比原本空間軸的數量來得小，達到Dimension Reduction的效果，所以我們會希望這個新的軸彼此間可以不要太多的依賴，什麼是不依賴呢？直角座標就是最不依賴的座標系，X軸和Y軸內積為0，這樣的軸展開的效率是最好的，所以我們希望在做Regularization的同時可以減少新軸的彼此間的依賴性。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">time</span>

<span class="c1"># Config the matplotlib backend as plotting inline in IPython</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Autoencoder</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_features</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span> <span class="c1"># initialize new grap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">n_hidden</span><span class="p">,</span><span class="n">alpha</span><span class="p">)</span> <span class="c1"># building graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="c1"># create session by the graph </span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_features</span><span class="p">,</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">n_hidden</span><span class="p">,</span><span class="n">alpha</span><span class="p">):</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="c1">### Input</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">n_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_targets</span>  <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">n_features</span><span class="p">))</span>

            <span class="c1">### Optimalization</span>
            <span class="c1"># build neurel network structure and get their predictions and loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span>
                                               <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_features</span><span class="p">,</span>
                                               <span class="n">targets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_targets</span><span class="p">,</span>
                                               <span class="n">n_hidden</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>

            <span class="c1"># regularization loss</span>
            <span class="c1"># weight elimination L2 regularizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span> \
                    <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                     <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">out_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>

            <span class="c1"># total loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_loss</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span>

            <span class="c1"># define training operation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1">### Prediction</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">n_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_targets</span>  <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">n_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_y_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_original_loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure</span><span class="p">(</span>
                                                          <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">new_features</span><span class="p">,</span>
                                                          <span class="n">targets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">new_targets</span><span class="p">,</span>
                                                          <span class="n">n_hidden</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>  
            <span class="bp">self</span><span class="o">.</span><span class="n">new_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_original_loss</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularizer</span>

            <span class="c1">### Initialization</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">init_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>  

    <span class="k">def</span> <span class="nf">structure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">features</span><span class="p">,</span><span class="n">targets</span><span class="p">,</span><span class="n">n_hidden</span><span class="p">):</span>
        <span class="c1">### Variable</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="n">n_encoder</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">]</span><span class="o">+</span><span class="n">n_hidden</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_encoder</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span>
                        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n_encoder</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_encoder</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

            <span class="n">n_decoder</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))</span><span class="o">+</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_decoder</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span>
                        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n_decoder</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span><span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> \
                    <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_decoder</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>                    

        <span class="c1">### Structure</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span>

        <span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getDenseLayer</span><span class="p">(</span><span class="n">features</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encode1&#39;</span><span class="p">],</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encode1&#39;</span><span class="p">],</span>
                                     <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getDenseLayer</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span>
                        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>   

        <span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getDenseLayer</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;encode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;encode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))])</span> 

        <span class="n">decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getDenseLayer</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decode1&#39;</span><span class="p">],</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decode1&#39;</span><span class="p">],</span>
                                     <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getDenseLayer</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span>
                        <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span> 

        <span class="n">y_</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">getDenseLayer</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">&#39;decode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">[</span><span class="s1">&#39;decode{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">))],</span>
                        <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)</span>      

        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">targets</span> <span class="o">-</span> <span class="n">y_</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">y_</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">encoder</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getDenseLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">input_layer</span><span class="p">,</span><span class="n">weight</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span><span class="n">weight</span><span class="p">),</span><span class="n">bias</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">activation</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

        <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">9000</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">N</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_op</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%2d</span><span class="s2">/</span><span class="si">%2d</span><span class="s2">: &quot;</span><span class="o">%</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">epochs</span><span class="p">))</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="c1"># mini-batch gradient descent</span>
            <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                <span class="n">index_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
                <span class="n">batch_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">index_size</span><span class="p">))]</span>     

                <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_features</span><span class="p">:</span> <span class="n">X</span><span class="p">[</span><span class="n">batch_index</span><span class="p">,:],</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">train_targets</span><span class="p">:</span> <span class="n">Y</span><span class="p">[</span><span class="n">batch_index</span><span class="p">,:]}</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

                <span class="k">print</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">] loss = </span><span class="si">%9.4f</span><span class="s2">     &quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">N</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">),</span> <span class="n">N</span><span class="p">,</span> <span class="n">loss</span> <span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">)</span>


            <span class="c1"># evaluate at the end of this epoch</span>
            <span class="n">msg_valid</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">val_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">validation_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">validation_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">msg_valid</span> <span class="o">=</span> <span class="s2">&quot;, val_loss = </span><span class="si">%9.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">val_loss</span> <span class="p">)</span>

            <span class="n">train_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">] </span><span class="si">%d</span><span class="s2">s loss = </span><span class="si">%9.4f</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span>
                                                   <span class="n">train_loss</span><span class="p">,</span> <span class="n">msg_valid</span> <span class="p">))</span>

        <span class="k">if</span> <span class="n">test_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">test_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">test_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;test_loss = </span><span class="si">%9.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_encoder</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_features</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_y_</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_features</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">new_features</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
                                                       <span class="bp">self</span><span class="o">.</span><span class="n">new_targets</span><span class="p">:</span> <span class="n">Y</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">_check_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ndarray</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ndarray</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span> <span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ndarray</span><span class="p">,(</span><span class="mi">1</span><span class="p">,</span><span class="n">ndarray</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">ndarray</span>
</pre></div>


<p><br/></p>
<h5><u>測試Autoencoder</u></h5>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;MNIST_data/&quot;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">validation</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">model_1</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="o">=</span> <span class="mf">0.0005</span><span class="p">,</span>
                     <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                    <span class="p">)</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
           <span class="n">Y</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
           <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
           <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span><span class="n">valid_data</span><span class="o">.</span><span class="n">images</span><span class="p">),</span>
           <span class="n">test_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">),</span>
           <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
          <span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">img_original</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_original</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]),(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>Epoch  1/20: 
[55000/55000] 98s loss =    0.0335 , val_loss =    0.0330
Epoch  2/20: 
[55000/55000] 98s loss =    0.0307 , val_loss =    0.0305
Epoch  3/20: 
[55000/55000] 99s loss =    0.0293 , val_loss =    0.0291
Epoch  4/20: 
[55000/55000] 96s loss =    0.0283 , val_loss =    0.0282
Epoch  5/20: 
[55000/55000] 96s loss =    0.0277 , val_loss =    0.0278
Epoch  6/20: 
[55000/55000] 98s loss =    0.0271 , val_loss =    0.0273

...略...

Epoch 15/20: 
[55000/55000] 99s loss =    0.0250 , val_loss =    0.0258
Epoch 16/20: 
[55000/55000] 98s loss =    0.0246 , val_loss =    0.0255
Epoch 17/20: 
[55000/55000] 99s loss =    0.0246 , val_loss =    0.0256
Epoch 18/20: 
[55000/55000] 97s loss =    0.0247 , val_loss =    0.0256
Epoch 19/20: 
[55000/55000] 98s loss =    0.0246 , val_loss =    0.0256
Epoch 20/20: 
[55000/55000] 99s loss =    0.0244 , val_loss =    0.0255
test_loss =    0.0261
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/04_output_5_1.png"></p>
<p>上面圖中上排是進去Autoencoder之前的圖片，下排是經過Autoencoder後的圖片，效果是不是很驚人！大致都有辦法還原回去原圖。唯一可能有缺陷的地方是，這個Autoencoder似乎會把5看成是6，做個Regularization看看能不能解決這個問題。</p>
<div class="highlight"><pre><span></span><span class="n">model_2</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="o">=</span> <span class="mf">0.0005</span><span class="p">,</span>
                     <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                    <span class="p">)</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
           <span class="n">Y</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
           <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
           <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span><span class="n">valid_data</span><span class="o">.</span><span class="n">images</span><span class="p">),</span>
           <span class="n">test_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">),</span>
           <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
          <span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">img_original</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_original</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]),(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>Epoch  1/20: 
[55000/55000] 88s loss =    0.0332 , val_loss =    0.0328
Epoch  2/20: 
[55000/55000] 90s loss =    0.0301 , val_loss =    0.0299
Epoch  3/20: 
[55000/55000] 90s loss =    0.0288 , val_loss =    0.0287
Epoch  4/20: 
[55000/55000] 88s loss =    0.0279 , val_loss =    0.0278
Epoch  5/20: 
[55000/55000] 89s loss =    0.0274 , val_loss =    0.0275
Epoch  6/20: 
[55000/55000] 91s loss =    0.0270 , val_loss =    0.0272

...略...

Epoch 15/20: 
[55000/55000] 89s loss =    0.0247 , val_loss =    0.0255
Epoch 16/20: 
[55000/55000] 91s loss =    0.0245 , val_loss =    0.0253
Epoch 17/20: 
[55000/55000] 92s loss =    0.0244 , val_loss =    0.0253
Epoch 18/20: 
[55000/55000] 90s loss =    0.0244 , val_loss =    0.0253
Epoch 19/20: 
[55000/55000] 91s loss =    0.0244 , val_loss =    0.0254
Epoch 20/20: 
[55000/55000] 91s loss =    0.0242 , val_loss =    0.0252
test_loss =    0.0258
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/04_output_7_1.png"></p>
<p>似乎看起來是有效果的，現在5會被完整還原了。</p>
<p><br/></p>
<h5><u>壓縮碼Code與視覺化</u></h5>
<p>剛剛提到在Autoencoder前半段是一個Encoder，所以我們可以利用這個Encoder來做壓縮，會得到一個Code，在上面的這個例子，這個Code總共有4個值，因為中間層有4個神經元，可以把這個Code看成Dimension Reduction的結果，原本一張圖代表的是28x28=784個維度下的一個點，現在經過轉換後變成是4個維度下的一個點，而我們會直覺的認為同樣一群的數字圖形應該會有較高的相似度，所以在4個維度之下，同樣的數字圖片應該會彼此靠近的比較近，甚至聚成一團。</p>
<p>我想要驗證一下這件事，我們需要先圖像化，不過卻卡在維度太高的問題，人類無法想像高於3個維度以上的空間，也沒辦法將它視覺化，這個時候我們需要再做一次的Dimension Reduction，將維度降到低於3才可以視覺化，那一般手法是使用PCA來做這件事，有關於PCA我之前已經介紹過，請參考<a href="http://www.ycc.idv.tw/YCNote/post/35">這篇</a>，如此一來就可以在4個維度中切一個重要的截面來視覺化這些數據。不過記得喔！4個維度才是真正可以表示這群資料，做PCA只是為了畫圖而做的粗略轉換而已。</p>
<div class="highlight"><pre><span></span><span class="c1"># get code</span>
<span class="n">encode</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>

<span class="c1"># PCA 2D visualization</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">encode</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/04_output_9_0.png"></p>
<p>上面我以不同顏色當作不同的數字圖形，我們可以看到同樣的數字圖形會彼此聚成一團，所以的確同樣的數字的族群會被歸類到具有相似的特性，因此在code裏頭距離是彼此靠近的，還記得一開始我們沒加Regularization時。Model會把5看成是6，在這張圖你就會到原因，因為5號藍綠色和6號黃色靠的很近，很容易誤判。</p>
<p>這張圖同時揭露了Autoencoder的一個強大特性，注意喔!我們一開始Train這個Autoencoder的時候是沒有給它看任何Labels的，但他卻可以在壓縮資訊的同時找出規律，這個規律可以想成是我們人類在辨認每個不同數字的方法，所以Autoencoder可以在沒有Labels的情況下做歸納和學習，因此Autoencoder常常會被用在Unsupervised Learning (非監督式學習)。</p>
<p>另外介紹一種也是很流行的方法叫做t-SNE (讀作"tee-snee") ，這裡不多著墨這個方法的原理，但是它卻是目前2D Visualization最流行的作法，PCA只用線性的方式去做座標轉換，也就是從一個橫切面去看數據，這樣粗略的轉換並不能讓我們在視覺化時看出資料和資料間彼此的距離，尤其是從高維度轉換過來，經常會失真，而t-SNE是針對數據和數據間的距離去做轉換，最後被攤成2維時正是顯示數據點的距離關係，更能描述群聚的現象。</p>
<p>來看看t-SNE做起來效果如何。</p>
<div class="highlight"><pre><span></span><span class="c1"># get code</span>
<span class="n">encode</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>

<span class="c1"># TSNE 2D visualization</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_embedded</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">encode</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_embedded</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_embedded</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/04_output_11_0.png"></p>
<p><br/></p>
<h5><u>去雜訊(De-noise) Autoencoder</u></h5>
<p>我們巧妙的利用一下Autoencoder，我們將原本Autoencoder的前面加了一道人工雜訊的流程，但是最終又要讓Autoencoder試著去還原出原來沒有加入雜訊的資訊，這麼一來我們將可以找到一個Autoencoder是可以自行消除雜訊的，把這個Denoising Autoencoder加到正常Neural Network的前面，那這個Neural Network就擁有了抑制雜訊的功用，所以可以當作一種Regularization的方法。</p>
<p>先將圖片加上雜訊。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">ndarr</span><span class="p">):</span>
    <span class="n">noise_factor</span> <span class="o">=</span> <span class="mf">0.3</span>
    <span class="n">noisy_ndarr</span> <span class="o">=</span> <span class="n">ndarr</span> <span class="o">+</span> <span class="n">noise_factor</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                                          <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                                          <span class="n">size</span><span class="o">=</span><span class="n">ndarr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">noisy_ndarr</span>

<span class="n">noisy_train_img</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>
<span class="n">noisy_valid_img</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">valid_data</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>
<span class="n">noisy_test_img</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">noisy_train_img</span><span class="p">[</span><span class="n">i</span><span class="p">],(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/04_output_13_0.png"></p>
<p>圖片現在看起來非常的髒。</p>
<p>用這些髒圖片當作Input，正常圖當作Output的目標，我們就可以自然而然的Train出可以消除雜訊的Autoencoder。</p>
<div class="highlight"><pre><span></span><span class="n">denoise_model</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="o">=</span> <span class="mf">0.0003</span><span class="p">,</span>
                     <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                    <span class="p">)</span>
<span class="n">denoise_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">noisy_train_img</span><span class="p">,</span>
                  <span class="n">Y</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
                  <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                  <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">noisy_valid_img</span><span class="p">,</span><span class="n">valid_data</span><span class="o">.</span><span class="n">images</span><span class="p">),</span>
                  <span class="n">test_data</span><span class="o">=</span><span class="p">(</span><span class="n">noisy_test_img</span><span class="p">,</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">),</span>
                  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
                 <span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">img_original</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_original</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">img_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">noisy_test_img</span><span class="p">[</span><span class="n">i</span><span class="p">],(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img_noisy</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">denoise_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">noisy_test_img</span><span class="p">[</span><span class="n">i</span><span class="p">]),(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
    <span class="n">axis</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>Epoch  1/20: 
[55000/55000] 50s loss =    0.0402 , val_loss =    0.0398
Epoch  2/20: 
[55000/55000] 50s loss =    0.0361 , val_loss =    0.0360
Epoch  3/20: 
[55000/55000] 51s loss =    0.0341 , val_loss =    0.0341
Epoch  4/20: 
[55000/55000] 51s loss =    0.0328 , val_loss =    0.0330
Epoch  5/20: 
[55000/55000] 51s loss =    0.0319 , val_loss =    0.0322
Epoch  6/20: 
[55000/55000] 51s loss =    0.0313 , val_loss =    0.0319

...略...

Epoch 15/20: 
[55000/55000] 52s loss =    0.0288 , val_loss =    0.0305
Epoch 16/20: 
[55000/55000] 51s loss =    0.0287 , val_loss =    0.0303
Epoch 17/20: 
[55000/55000] 51s loss =    0.0285 , val_loss =    0.0303
Epoch 18/20: 
[55000/55000] 51s loss =    0.0285 , val_loss =    0.0304
Epoch 19/20: 
[55000/55000] 52s loss =    0.0286 , val_loss =    0.0306
Epoch 20/20: 
[55000/55000] 52s loss =    0.0283 , val_loss =    0.0303
test_loss =    0.0307
</pre></div>


<p><img alt="png" src="https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/04_output_15_1.png"></p>
<p>上面圖片第一排為原圖，第二排是加完雜訊後的結果，第三排是經過Autoencoder後的圖，傑克真的是太神奇啦！所有的雜訊都被消除掉了，特別注意，這裡我的Regularization下的特別重，原因是雜訊增多了，也更容易Overfitting，所以要下更多的Regularization才能抑制它。</p></dd>
            </dl>
        </div>
    </div>
<!-- /Navigation -->
<div class="container navigation">
    	<a class="navigate pull-right" href="./index2.html">Next <i class="fa fa-caret-right"></i></a>
</div>              
<!-- /Navigation --> 
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Sitemap</div>
                        <ul class="list-unstyled">
                            <li><a href="./archives.html">Archives</a></li>
                            <li><a href="./tags.html">Tags</a></li>
                            <li><a href="YCNote/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">Atom Feed</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Contact Me</div>
                        <ul class="list-unstyled">
                            <li><a href="./about-me.html" target="_blank">About Me</a></li>
                            <li><a href="https://github.com/GitYCC" target="_blank">Github</a></li>
                            <li><a href="mailto:ycc.tw.email@gmail.com" target="_blank">Email</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; YC Note 2018</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>