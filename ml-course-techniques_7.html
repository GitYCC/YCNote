
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="True" name="HandheldFriendly"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="index, follow" name="robots"/>
<link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&amp;family=Source+Sans+Pro:ital,wght@0,300;0,400;0,700;1,400&amp;display=swap" rel="stylesheet"/>
<link href="https://ycc.idv.tw/theme/stylesheet/style.less" rel="stylesheet/less" type="text/css"/>
<script src="//cdnjs.cloudflare.com/ajax/libs/less.js/2.5.1/less.min.js" type="text/javascript"></script>
<link href="https://ycc.idv.tw/theme/pygments/default.min.css" id="pygments-light-theme" rel="stylesheet" type="text/css"/>
<link href="https://ycc.idv.tw/theme/stork/stork.css" rel="stylesheet" type="text/css">
<link href="https://ycc.idv.tw/theme/font-awesome/css/fontawesome.css" rel="stylesheet" type="text/css"/>
<link href="https://ycc.idv.tw/theme/font-awesome/css/brands.css" rel="stylesheet" type="text/css"/>
<link href="https://ycc.idv.tw/theme/font-awesome/css/solid.css" rel="stylesheet" type="text/css"/>
<link href="/images/favicon.png" rel="shortcut icon" type="image/x-icon"/>
<link href="/images/favicon.png" rel="icon" type="image/x-icon"/>
<!-- Chrome, Firefox OS and Opera -->
<meta content="#FFFFFF" name="theme-color"/>
<!-- Windows Phone -->
<meta content="#FFFFFF" name="msapplication-navbutton-color"/>
<!-- iOS Safari -->
<meta content="yes" name="apple-mobile-web-app-capable"/>
<meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"/>
<!-- Microsoft EDGE -->
<meta content="#FFFFFF" name="msapplication-TileColor"/>
<link href="https://ycc.idv.tw/feeds/all.atom.xml" rel="alternate" title="YC Note Atom" type="application/atom+xml"/>
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68393177-2', 'auto');
  ga('send', 'pageview');
</script>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LXDD9FZFX2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LXDD9FZFX2');
</script>
<meta content="YC Chen" name="author">
<meta content="本篇內容涵蓋Radial Basis Function (RBF) Network、K-Means、One-Hot Encoding和Matrix Factorization" name="description">
<meta content="機器學習技法" name="keywords"/>
<meta content="YC Note" property="og:site_name">
<meta content="機器學習技法 學習筆記 (7)：Radial Basis Function Network與Matrix Factorization" property="og:title">
<meta content="本篇內容涵蓋Radial Basis Function (RBF) Network、K-Means、One-Hot Encoding和Matrix Factorization" property="og:description">
<meta content="en_US" property="og:locale">
<meta content="https://ycc.idv.tw/ml-course-techniques_7.html" property="og:url"/>
<meta content="article" property="og:type"/>
<meta content="2017-04-22 12:00:00+08:00" property="article:published_time"/>
<meta content="" property="article:modified_time"/>
<meta content="https://ycc.idv.tw/author/yc-chen.html" property="article:author"/>
<meta content="AI.ML" property="article:section">
<meta content="機器學習技法" property="article:tag"/>
<meta content="" property="og:image"/>
<title>YC Note – 機器學習技法 學習筆記 (7)：Radial Basis Function Network與Matrix Factorization</title>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-5639899546876072",
      enable_page_level_ads: true
    });
  </script>
</meta></meta></meta></meta></meta></meta></meta></link><link href="https://ycc.idv.tw/ml-course-techniques_7.html" rel="canonical"/><script type="application/ld+json">{"@context": "https://schema.org", "@type": "BreadcrumbList", "itemListElement": [{"@type": "ListItem", "position": 1, "name": "YC Note", "item": "https://ycc.idv.tw"}, {"@type": "ListItem", "position": 2, "name": "Ml course techniques_7", "item": "https://ycc.idv.tw/ml-course-techniques_7.html"}]}</script><script type="application/ld+json">{"@context": "https://schema.org", "@type": "Article", "author": {"@type": "Person", "name": "YC Chen"}, "publisher": {"@type": "Organization", "name": "YC Note"}, "headline": "機器學習技法 學習筆記 (7)：Radial Basis Function Network與Matrix Factorization", "about": "AI.ML", "datePublished": "2017-04-22 12:00"}</script></head>
<body class="light-theme">
<aside>
<div>
<a href="https://ycc.idv.tw/">
<img alt="YC Note" src="https://ycc.idv.tw/theme/img/profile.png" title="YC Note"/>
</a>
<h1>
<a href="https://ycc.idv.tw/">YC Note</a>
</h1>
<p style="text-align: center;">ML/DL Tech Blog (Total Views: 520,470) </p>
<div class="stork">
<input autocomplete="off" class="stork-input" data-stork="sitesearch" name="q" onclick="loadStorkIndex(this); this.onclick=null;" placeholder="Search (beta feature) ..." type="text"/>
<div class="stork-output" data-stork="sitesearch-output"></div>
</div>
<!-- <script>
      window.addEventListener('load', 
        function() { 
          loadStorkIndex();
        }, false);
    </script> -->
<p>This blog is a resource for anyone interested in data science and machine learning, featuring tutorials, research papers, and the latest industry technologies.</p>
<p>Hello, I am YC, an ML engineer/researcher with experience in CV, NLP/NLU, and Recommender. I also have experience in high-QPS ML systems. In my spare time, I'm a blogger and guitar singer. <a href="https://ycc.idv.tw/about-me.html#anchor" style="color:yellow">More about me.</a></p>
<ul class="social">
<li>
<a class="sc-facebook" href="https://www.facebook.com/yc.note" target="_blank">
<i class="fa-brands fa-facebook"></i>
</a>
</li>
<li>
<a class="sc-github" href="https://github.com/GitYCC" target="_blank">
<i class="fa-brands fa-github"></i>
</a>
</li>
<li>
<a class="sc-linkedin" href="https://www.linkedin.com/in/yi-chang-chen-aba1b6114/" target="_blank">
<i class="fa-brands fa-linkedin"></i>
</a>
</li>
</ul>
</div>
</aside>
<main>
<nav id="anchor">
<a href="https://ycc.idv.tw/">Home</a>
<a href="/about-me.html#anchor">About Me</a>
<a href="/categories.html#anchor">Categories</a>
<a href="/tags.html#anchor">Tags</a>
<a href="https://ycc.idv.tw/feeds/all.atom.xml">Atom</a>
</nav>
<article class="single">
<header>
<h1 id="ml-course-techniques_7">機器學習技法 學習筆記 (7)：Radial Basis Function Network與Matrix Factorization</h1>
<p>
      Posted on April 22, 2017 in <a href="https://ycc.idv.tw/category/aiml.html">AI.ML</a>. View: 14,204

    </p>
</header>
<div class="tag-cloud">
<p>
<a href="https://ycc.idv.tw/tag/ji-qi-xue-xi-ji-fa.html">機器學習技法</a>
</p>
</div>
<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle ads-responsive" data-ad-client="ca-pub-5639899546876072" data-ad-slot="5718861428"></ins>
<script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
<div class="main-contents">
<p><br/></p>
<h3 id="radial-basis-function-rbf-network">Radial Basis Function (RBF) Network</h3>
<p>回顧一下Gaussian Kernel SVM，</p>
<blockquote>
<p><span class="math">\(W = 𝚺_{n=sv}  α_n y_n Z_n\)</span></p>
<p><span class="math">\(G_{SVM}\)</span> <br/></p>
<p><span class="math">\(= sign[WZ+b]\)</span> <br/></p>
<p><span class="math">\(= sign{[𝚺_{n=sv} α_n y_n K(X_n,X)]+b}\)</span> <br/></p>
<p><span class="math">\(⇒ G_{SVM} = sign{[𝚺_{n=sv} α_n y_n exp(-γ |X-X_n|^2)]+b}\)</span> <br/></p>
</blockquote>
<p>看到這個式子你想到了什麼？有沒有融會貫通的感覺，你同樣的可以把上面的式子看成是Aggregation，又或者是Network。</p>
<p>先來定義一下RBF Function， 其實就是Gaussian Function，</p>
<p><strong>RBF Function: <span class="math">\(RBF(X,X_n)=exp(-γ|X-X_n|^2)\)</span></strong></p>
<p>所以我們可以仿造SVM的形式來造一個Network，</p>
<p><strong><span class="math">\(G=Output{[𝚺_m β_m RBF(X,μ_m)]+b}\)</span></strong></p>
<p>當<span class="math">\(Output\)</span>為<span class="math">\(sign\)</span> Function、<span class="math">\(β_m\)</span>為<span class="math">\(α_n y_n\)</span>就回到特例SVM了。</p>
<p>我們來細看這個式子傳遞的概念，RBF Network的第一層是先產生<span class="math">\(M\)</span>組<span class="math">\(RBF(X,μ_m)\)</span>，意味著以這<span class="math">\(M\)</span>個位置<span class="math">\(μ_m\)</span>當作中心點來評估各個<span class="math">\(X\)</span>與它的相似程度，RBF是有評估相似度的味道，越接近<span class="math">\(μ_m\)</span>的點，RBF越大，並隨著與<span class="math">\(μ_m\)</span>距離變大，RBF的值也快速遞減，所以這<span class="math">\(M\)</span>個<span class="math">\(μ_m\)</span>是有象徵性的，越接近它你越受它的影響。</p>
<p>決定了每一筆數據各是受哪些<span class="math">\(μ_m\)</span>影響，接下來第二層是由這M個代表性的位置來進行投票決定最後的結果，這意味的不同的地方對<span class="math">\(μ_m\)</span>最後結果也有不同的影響力，舉個例子，假設在SVM裡頭，某個<span class="math">\(μ_m\)</span>如果它的<span class="math">\(y_m =+1\)</span>，那它對最後的影響就會是正的；那如果某個<span class="math">\(μ_m\)</span>的<span class="math">\(y_m=-1\)</span>，那它對最後的影響就會是負的，所以一個點進來，先評估一下它和象徵性的幾個點<span class="math">\(μ_m\)</span>的距離，如果相鄰幾點都是正的，這個點最後的結果就會是正的。</p>
<p><img alt="RBF Network" src="/media/MachineLearningTechniques/MachineLearningTechniques.000_05.png"/></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf</a></p>
<p>RBF Network在歷史上是Neural Network的一個分支，不過從上面的介紹你就會發現，它們的結構是有差異的，演算法也就不一樣。</p>
<p>通常最佳化RBF Network做法是這樣的，我們會先用一些方法將<span class="math">\(μ_m\)</span>決定，如果<span class="math">\(μ_m\)</span>很懶惰的就直接使用所有的Training Data，總共有<span class="math">\(N\)</span>個，這<span class="math">\(μ_m\)</span>就叫做<strong>「Full RBF Network」</strong>。<strong>我們也可以使用一些歸納的演算法找出代表資料群體的幾個象徵性的中心點，例如待會會介紹的K-Means的方法</strong>，找出k個<span class="math">\(μ_m\)</span>再做計算，這樣的RBF Network稱為<strong>「k Nearest Neighbor RBF Network」</strong>。</p>
<p>找到了<span class="math">\(μ_m\)</span>就已經決定了所有的RBF Function，接下來就可以線性組合這些RBF Function，我們可以使用Regression的方法來求取<span class="math">\(β_m\)</span>。</p>
<p>而如果你使用「Full RBF Network」，你會發現做完Regression後<span class="math">\(E_{in}=0\)</span>，這是典型的Overfitting，那這時你可能就要採用有Regularization的Regression啦！譬如說Ridge Regression之類的。</p>
<p><br/></p>
<h3 id="k-means">K-Means</h3>
<p><img alt="K-Means" src="/media/MachineLearningTechniques/MachineLearningTechniques.000_06.png"/></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf</a></p>
<p>接下來來看怎麼用K-Means找到代表資料群體的幾個象徵性的中心點。</p>
<p>首先，先決定要有幾個「中心點」，這裡假設我要有<span class="math">\(k\)</span>個好了，接下來先隨機給這些「中心點」一個初始的位置，接下來根據數據的靠近程度開始歸類，如果一筆數據比較所有的「中心點」後發現離「中心點」A是最近的話，那這筆數據就歸「中心點」A了，就用這樣的規則把所有數據都做分類。</p>
<p>分完類後，接下來平均每一個資料群體裡的數據座標找出新的代表這個群體的「中心點」，然後又拿這個新的「中心點」根據數據的靠近程度再歸類一次，如此循環多次，直到收斂為止。這樣的話，這<span class="math">\(k\)</span>個「中心點」收斂後會各自佔據四方，並且代表某個群體的中心點。我們就可以找到代表性的<span class="math">\(k\)</span>個點，並拿這些點做「k Nearest Neighbor RBF Network」。</p>
<p><br/></p>
<h3 id="one-hot-encoding">One-Hot Encoding</h3>
<p>討論這麼久的ML，我們還沒有討論過假設遇到「類別」要怎麼處理！</p>
<p><strong>通常遇到類別的狀況，我們還是需要把它轉換成數值或向量來處理，常見的方法叫做One-Hot Encoding。</strong></p>
<p>舉個例子，如果要描述血型應該要怎麼做？我們可是無法拿字串下去Regression的啊～此時就需要One-Hot Encoding，假設血型有A, B, AB, O四種，我們可以這樣設定，</p>
<p><span class="math">\(A = [1, 0, 0, 0]^T\)</span></p>
<p><span class="math">\(B = [0, 1, 0, 0]^T\)</span></p>
<p><span class="math">\(AB = [0, 0, 1, 0]^T\)</span></p>
<p><span class="math">\(O = [0, 0, 0, 1]^T\)</span></p>
<p>就是這麼簡單，這個動作就叫做One-Hot Encoding。</p>
<p><br/></p>
<h3 id="matrix-factorization">Matrix Factorization</h3>
<p><strong>那如果今天我的Input和Output都是類別，而我們想要讓機器自己去找到匹配Input和Output的機制，解決這個問題的方法稱之為Matrix Factorization。</strong></p>
<p><strong>Matrix Factorization精神上有點像是Autoencoder，Autoencoder找出隱含在Data裡的特性，而Matrix Factorization則是找出隱含的匹配關係。</strong></p>
<p>舉個例子，如果Netflix有了一堆用戶和他們曾看過的電影的資料，我們想要從中抽取出用戶與他愛看的電影之間的關係，所以這不單單只是匹配而已，單純匹配就只需要硬碟就做的到了，我們要做的是找出匹配的規律，並且用更少、更精簡的方式表示這個匹配關係，舉個例子，有可能有部分用戶會被歸納到愛看恐怖片的，並且同時這些客戶會被連結到具有恐怖元素的電影，我們預期Matrix Factorization會有自行歸納整理的能力。</p>
<p>可以仿造Autoencoder來設計Matrix Factorization，而你會發現Activation Function只要使用線性就已經足夠了，因為對於One-Hot Encoding的類別來說，只有一條通道是有效的，這已經具有開關的味道了，所以我們不用在Activation Function上面再弄一道開關，所以採用Linear就足夠了。</p>
<p><img alt="Matrix Factorization" src="/media/MachineLearningTechniques/MachineLearningTechniques.000_07.png"/></p>
<p>from: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf</a></p>
<p>因為是線性模型的緣故，我們可以很簡單的使用矩陣來描述，</p>
<p>Hypothesis: <span class="math">\(h(X) = W^TVX\)</span></p>
<p>而如果是某一用戶，則</p>
<p><span class="math">\(h(X_n) = W^TV_n\)</span></p>
<p>對某個用戶而言與他匹配的電影是一個向量，上面紀錄了他看過的電影，假設我再指定一部電影<span class="math">\(m\)</span>，此時<span class="math">\(W_m^T V_n\)</span>就代表這個用戶有沒有看過這部電影。</p>
<p>用這個方法來想問題，假設今天你把用戶和電影填成一個大的表格，或是矩陣，有交集的部分就打個勾，這個矩陣的每個元素表示成<span class="math">\(r_{nm}\)</span>，有打勾的部分<span class="math">\(r_{nm}=1\)</span>，沒打勾的部分<span class="math">\(r_{nm}=0\)</span>，那我們做的轉換W和V最終就是為了讓</p>
<p><span class="math">\(W_m^T V_n ≈r_{nm}\)</span></p>
<p>為了評估匹配的好壞，我們定義Error Function為</p>
<p><span class="math">\(E_{in}(\{W_m\},\{V_n\}) = (1/𝚺_m |D_m|)×𝚺_{n,m} (r_{nm}-W_{m}^TV_n)^2\)</span></p>
<p>最佳化Matrix Factorization有兩個演算法，一個是Alternating Least Squares，另外一個是SGD。</p>
<p><br/></p>
<h3 id="alternating-least-squares-for-matrix-factorization">Alternating Least Squares for Matrix Factorization</h3>
<p><img alt="Alternating Least Squares for Matrix Factorization" src="/media/MachineLearningTechniques/MachineLearningTechniques.000_08.png"/></p>
<p>from: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf</a></p>
<p>第一個方法是利用Linear Regression交互的優化<span class="math">\(W_m\)</span>和<span class="math">\(V_n\)</span>，我們的目標是使得<span class="math">\(W_m^T V_n =r_{nm}\)</span>，這式子可以用兩個角度看，如果固定<span class="math">\(W_m\)</span>，優化<span class="math">\(V_n\)</span>，那就是線性擬合<span class="math">\(\{V_n, r_{nm}\}\)</span>的問題；那如果固定<span class="math">\(V_n\)</span>，優化<span class="math">\(W_m\)</span>，這就是線性擬合<span class="math">\(\{W_{m}, r_{nm}\}\)</span>的問題。<strong>因此，交替優化<span class="math">\(W_m\)</span>和<span class="math">\(V_n\)</span>就可以使得<span class="math">\(W_m^T V_n\)</span>越來越接近<span class="math">\(r_{nm}\)</span>了</strong>。</p>
<p><br/></p>
<h3 id="sgd-for-matrix-factorization">SGD for Matrix Factorization</h3>
<p><img alt="SGD for Matrix Factorization" src="/media/MachineLearningTechniques/MachineLearningTechniques.000_09.png"/></p>
<p>from: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf</a></p>
<p>第二個方法則是老招—Gradient Descent，這裡採用隨機的版本SGD，所以過程中我們會隨意的從<span class="math">\((n,m)\)</span>中挑點，然後根據Error Measure</p>
<div class="math">$$
E_{in}(\{W_m\},\{V_n\}) = (1/𝚺_m |D_m|) \times 𝚺_{n,m} (r_{nm}-W_{m}^T V_n )^2
$$</div>
<p>
我們就可以得到更新<span class="math">\(W_m\)</span>和<span class="math">\(V_n\)</span>的方法，詳細的方法見上圖所示。</p>
<p><strong>目前，SGD方法是處理大型Matrix Factorization最流行的作法。</strong></p>
<p><br/></p>
<h3 id="_1">結語</h3>
<p>本篇介紹類似Neural Network的兩種Network結構，分別為Radial Basis Function (RBF) Network和Matrix Factorization。</p>
<p>在做RBF Network時，我們先找出幾個代表的中心，並評估一筆資料與這些中心的距離，再來再考慮不同中心對於答案的貢獻，加總起來可以預測這筆資料的答案，我們可以使用K-Means的方法來找出k點代表性的中心點來做RBF Network。</p>
<p>Matrix Factorization和Autoencoder有點類似，Autoencoder目標在於找出隱含在Data裡的特性，而Matrix Factorization則是找出隱含的匹配關係，並且介紹了兩種Matrix Factorization的演算法：Alternating Least Squares和SGD方法。</p>
<p>這系列的介紹文章，到這裡算是走到尾聲了，最後跟大家推薦一下老師的最後一堂課的投影片：</p>
<p><a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/216_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/216_handout.pdf</a></p>
<p>這個投影片裡頭林軒田教授用心的彙整了一整個學期的內容，很值得一看。</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "left",
        indent = "1em",
        linebreak = "true";

    if (true) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</div>
<div class="center social-share">
<p>Like this article? Share it with your friends!</p>
<div class="addthis_native_toolbox"></div>
<div class="addthis_sharing_toolbox"></div>
<div class="addthis_inline_share_toolbox"></div>
</div>
<div class="neighbors">
<a class="btn float-left" href="https://ycc.idv.tw/ml-course-techniques_6.html#anchor" title="機器學習技法 學習筆記 (6)：神經網路(Neural Network)與深度學習(Deep Learning)">
<i class="fa fa-angle-left"></i> Previous Post
    </a>
<a class="btn float-right" href="https://ycc.idv.tw/python-play-with-data_3.html#anchor" title="Python玩數據 (3)：Numpy [2/2]">
      Next Post <i class="fa fa-angle-right"></i>
</a>
</div>
<div class="related-posts">
<h4>You might enjoy</h4>
<ul class="related-posts">
<li><a href="https://ycc.idv.tw/ml-course-techniques_3.html">機器學習技法 學習筆記 (3)：Kernel Regression</a></li>
<li><a href="https://ycc.idv.tw/ml-course-techniques_4.html">機器學習技法 學習筆記 (4)：Basic Aggregation Models</a></li>
<li><a href="https://ycc.idv.tw/ml-course-techniques_5.html">機器學習技法 學習筆記 (5)：Boost Aggregation Models</a></li>
<li><a href="https://ycc.idv.tw/ml-course-techniques_6.html">機器學習技法 學習筆記 (6)：神經網路(Neural Network)與深度學習(Deep Learning)</a></li>
</ul>
</div>
<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'ycnote-1';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>
    Please enable JavaScript to view comments.
</noscript>
<!-- End Disqus -->
</article>
<footer>
<p>
  © 2023  - This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/deed.en_US" rel="license" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p><p>
<a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license" target="_blank">
<img alt="Creative Commons License" height="15" src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" style="border-width:0" title="Creative Commons License" width="80"/>
</a>
</p></footer> </main>
<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " YC Note ",
  "url" : "https://ycc.idv.tw",
  "image": "",
  "description": "YC Note - ML/DL Tech Blog"
}
</script><script async="async" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-63b4eabb5e84e9fb" type="text/javascript"></script>
<script>
    window.loadStorkIndex = async (input_obj) => {
      input_obj.disabled = true;
      input_obj.placeholder = 'Downloading index file, please wait ...'
      await stork.register("sitesearch", "https://ycc.idv.tw/search-index.st", { showProgress: false });
      input_obj.placeholder = 'Search ...'
      input_obj.disabled = false;
    }
  </script>
<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
</body>
</html>