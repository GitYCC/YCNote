<!DOCTYPE html>
<html lang="zh">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="YC Note, 本網站內容包括機器學習(Machine Learning)、深度學習(Deep Learning)、類神經網路(Neural Network)、資料科學(Date Science)、Python、演算法(Algorithm)。">
        <meta name="keywords" content="">
        <link rel="icon" href="./static/img/favicon.png">

        <title>Homepage - page 3 - YC Note</title>

        <!-- Stylesheets -->
        <link href="./theme/css/all.min.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <link href="YCNote/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="YC Note Full Atom Feed" />
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->



    </head>

    <body>

        <!-- Header -->
    <div class="header-container" style="background: linear-gradient(rgba(0, 0, 0, 0.2), rgba(0, 0, 0, 0.2)), url('./images/welcome_front_board.jpg'); background-position: center; background-size: cover;">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                        <a class="pull-left" href="./"><img class="logo" src="./static/img/favicon.png" alt="logo">YC Note</a>
                    </div>
                    <div class="nav pull-right">
                                <a href="./category/coding.html">Coding</a>
                                <a href="./category/aiml.html">AI.ML</a>
                                <a href="./category/reading.html">Reading</a>
                                <a href="./category/recording.html">Recording</a>
                                <a href="./about-me.html">About Me</a>
                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title">YC NOTE</h1>
                      <div class="header-underline"></div>
                      <p class="header-subtitle header-subtitle-homepage">想像力比知識更重要</p>
                  </div>
              </div>
        </div>
    </div>
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    
    <div class="archive-container">
        <div class="container content archive">
            <h2><a href="./index3.html">Last Posts <small>- page 3</small></a></h2>
            <dl class="dl-horizontal">
                <dt>2017 / 5月 06</dt>
                <dd><a href="./python-play-with-data_3.html">Python玩數據 (3)：Numpy [2/2]</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p>在上一章節的討論，我們已經有了Numpy的基礎概念，在這一篇當中，我們會更深入的了解Numpy還有什麼進階的功能，包括：產生ndarray的多種方法、broadcast的概念以及ndarray的進階操作手法。</p>
<h5><u>產生ndarray的其他方法</u></h5>
<p>在上一章，ndarray的產生方法是由list產生的。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
</pre></div>


<p>Numpy還提供產生ndarray的其他方式，幫助我們更容易的產生ndarray，譬如，產生一個數列。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">E</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">E</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">step</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span> <span class="mf">3.</span> <span class="p">,</span>  <span class="mf">3.5</span><span class="p">,</span>  <span class="mf">4.</span> <span class="p">,</span>  <span class="mf">4.5</span><span class="p">,</span>  <span class="mf">5.</span> <span class="p">,</span>  <span class="mf">5.5</span><span class="p">])</span>
</pre></div>


<p>stop指的是停止的那點，那點是不包含在產生的數列的。</p>
<p>1D的數列也可轉換成多維度的數列。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">H</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span>
<span class="n">array</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">],</span>
       <span class="p">[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">K</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">K</span>
<span class="n">array</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
       <span class="p">[</span> <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">],</span>
       <span class="p">[</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
</pre></div>


<p>另外還有一種可以產生連續數列的方法。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span> <span class="mf">0.</span>  <span class="p">,</span>  <span class="mf">0.25</span><span class="p">,</span>  <span class="mf">0.5</span> <span class="p">,</span>  <span class="mf">0.75</span><span class="p">,</span>  <span class="mf">1.</span>  <span class="p">,</span>  <span class="mf">1.25</span><span class="p">,</span>  <span class="mf">1.5</span> <span class="p">,</span>  <span class="mf">1.75</span><span class="p">,</span>  <span class="mf">2.</span>  <span class="p">])</span>
</pre></div>


<p>這個函數是這樣的，0是起始值，2是最終值，這個最終值是包含在數列裡的，9是代表數列會有九個數字，所以它會自動從這區間找九個數字均勻分配。</p>
<p>另外，也可以產生一個全部都零或一的數列，或是矩陣中的「單位矩陣」。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>     <span class="c1"># &quot;eye&quot; means &quot;I&quot;</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]])</span>
</pre></div>


<p>或者，你想要亂數產生也可以。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">0.14405468</span><span class="p">,</span>  <span class="mf">0.2312139</span> <span class="p">,</span>  <span class="mf">0.79134702</span><span class="p">,</span>  <span class="mf">0.18676625</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.95305253</span><span class="p">,</span>  <span class="mf">0.44833768</span><span class="p">,</span>  <span class="mf">0.87919535</span><span class="p">,</span>  <span class="mf">0.69051727</span><span class="p">]])</span>
</pre></div>


<p>如果你想要數列依照你給定的規則產生，就先定義好函數，然後再利用<code>fromfunction</code>製造數列。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">func1</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">fromfunction</span><span class="p">(</span><span class="n">func1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</pre></div>


<p>這麼一來，每個位置的值都是由我們所定義的函數所決定。如果你覺得那個<code>func1</code>名稱很多餘，還有下面這個方法。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">fromfunction</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
</pre></div>


<p>上面我使用了<code>lambda</code>，這個東西稱之為『匿名函數』。</p>
<div class="highlight"><pre><span></span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span>
</pre></div>


<p>和</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">something</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span>
</pre></div>


<p>上面這兩個函式是等價的，差異只在於，第一個函式是沒有名稱的，稱為匿名函數，第二種就是一般的函式，具有名稱。</p>
<h5><u>Broadcasting</u></h5>
<p>在上一章，我有提到一般的矩陣運算，在Numpy中是採用element-wise operation，也就是每個相應元素做運算，然後產生新的ndarray，這個前題是兩組要運算的ndarray他們的shape是相同的，那如果遇到shape不一致，Numpy會怎麼處理呢？實際上，Numpy會幫你把陣列給延伸展開，就像廣播(broadcasting)一樣的傳遞出去，這遵照所謂的broadcasting rules。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">+</span> <span class="n">B</span>      <span class="c1"># element-wise plus</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>


<p>上面就是最普遍的兩個相同shape的矩陣作運算。</p>
<p>那如果是這個情況呢？</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]])</span>
</pre></div>


<p>你會發現如果矩陣對一個單一元素作運算，其實就等同於這個單一元素對矩陣內的元素分別作運算，這個方式相當好理解，那如果是這樣呢？</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">11</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">E</span> <span class="o">=</span> <span class="n">C</span> <span class="o">*</span> <span class="n">D</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">E</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">10.</span><span class="p">,</span>  <span class="mf">14.</span><span class="p">,</span> <span class="mf">22.</span> <span class="p">],</span>    <span class="c1"># [[ 2*5, 2*7, 2*11 ],</span>
       <span class="p">[</span> <span class="mf">15.</span><span class="p">,</span>  <span class="mf">21.</span><span class="p">,</span> <span class="mf">33.</span> <span class="p">]])</span>   <span class="c1">#  [ 3*5, 3*7, 3*11 ]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">E</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>


<p>讓我來分解解說一下broadcasting究竟做了什麼，broadcasting能自動填滿矩陣有一個大前提，</p>
<blockquote>
<p>參與運算的所有矩陣必須符合以下規則才能做broadcasting，所有矩陣的shape由axis＝-1開始對齊去比較彼此間的rank，所有矩陣的在每個axis下的rank必須符合以下兩種規則其中之一：</p>
<ol>
<li>所有rank為同一個值</li>
<li>只能有一個矩陣rank為非0或1，其餘矩陣的rank都要為0或1</li>
</ol>
</blockquote>
<p>上面這個例子，在axis= -2之下，只有C矩陣rank具有非0或1的2，而D的rank則為1；在axis= -1之下，只有D矩陣rank具有非0或1的3，而C的rank則為1，因此這兩個陣列可以使用broadcasting rule來延伸。</p>
<p>為什麼我們需要這樣的前提假設，原因是符合這樣的情況下，我們可以藉由重複的複製貼上來使得兩個或多個矩陣有一樣的shape，C矩陣shape為(2,1)，所以在axis= -2的方向上，重複貼3次就會產生出shape為(2,3)的矩陣；D矩陣的shape為(1,3)，所以在axis= -1的方向上，重複貼2次就會產生出(2,3)的矩陣，如此一來兩個矩陣都是(2,3)就可以作element-wise operation。</p>
<p>逐步示範一下，</p>
<div class="highlight"><pre><span></span>C  = [[2],[3]] # shape = (2,1)
C&#39; = [[2,2,2],[3,3,3]] # shape = (2,3)
D  = [[5,7,11]] # shape = (1,3)
D&#39; = [[5,7,11],[5,7,11]] # shape = (2,3)
E = C&#39; * D&#39;
</pre></div>


<p>以下這些都是同樣道理</p>
<div class="highlight"><pre><span></span>A      (2d array):  5 x 4
B      (1d array):      1
Result (2d array):  5 x 4

A      (2d array):  5 x 4
B      (1d array):      4
Result (2d array):  5 x 4

A      (3d array):  15 x 3 x 5
B      (3d array):  15 x 1 x 5
Result (3d array):  15 x 3 x 5

A      (3d array):  15 x 3 x 5
B      (2d array):       3 x 5
Result (3d array):  15 x 3 x 5

A      (3d array):  2 x 3 x 4
B      (2d array):      3 x 1
Result (3d array):  2 x 3 x 4
</pre></div>


<p>我們再來看一下，如果維度不一樣是怎麼運作，譬如說2D碰上3D的，</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">F</span>
<span class="n">array</span><span class="p">([[[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span>

       <span class="p">[[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">F</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">G</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span> <span class="o">=</span> <span class="n">F</span> <span class="o">+</span> <span class="n">G</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span>
<span class="n">array</span><span class="p">([[[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">]],</span>

       <span class="p">[[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">26</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>


<p>分解一下</p>
<div class="highlight"><pre><span></span>F  = [[[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]],
      [[12, 13, 14, 15],
       [16, 17, 18, 19],
       [20, 21, 22, 23]]]  # shape = (2,3,4)
G = [[1],
     [2],
     [3]] # shape = (3,1)
G&#39;= [[1,1,1,1],
     [2,2,2,2],
     [3,3,3,3]] # shape = (3,4)
G&quot;= [[[1,1,1,1],
      [2,2,2,2],
      [3,3,3,3]],
     [[1,1,1,1],
      [2,2,2,2],
      [3,3,3,3]]] # shape = (2,3,4)

H = F + G&quot;
   = [[[ 0+1,  1+1,  2+1,  3+1],
       [ 4+2,  5+2,  6+2,  7+2],
       [ 8+3,  9+3, 10+3, 11+3]],
      [[12+1, 13+1, 14+1, 15+1],
       [16+2, 17+2, 18+2, 19+2],
       [20+3, 21+3, 22+3, 23+3]]]
</pre></div>


<p>那這樣的性質可以怎麼運用呢？舉個例子。</p>
<div class="highlight"><pre><span></span>Example:
請問平面上這些點(102.0, 203.0),(132.0, 193.0),(45.0, 155.0),(57.0, 173.0)，哪一點最接近(111.0,188.0)?
</pre></div>


<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">observation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">111.0</span><span class="p">,</span><span class="mf">188.0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">codes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">102.0</span><span class="p">,</span> <span class="mf">203.0</span><span class="p">],[</span><span class="mf">132.0</span><span class="p">,</span> <span class="mf">193.0</span><span class="p">],[</span><span class="mf">45.0</span><span class="p">,</span> <span class="mf">155.0</span><span class="p">],[</span><span class="mf">57.0</span><span class="p">,</span> <span class="mf">173.0</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">codes</span> <span class="o">-</span> <span class="n">observation</span>  <span class="c1"># broadcasting</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">diff</span>
<span class="n">array</span><span class="p">([[</span> <span class="o">-</span><span class="mf">9.</span><span class="p">,</span>  <span class="mf">15.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">21.</span><span class="p">,</span>   <span class="mf">5.</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">66.</span><span class="p">,</span> <span class="o">-</span><span class="mf">33.</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">54.</span><span class="p">,</span> <span class="o">-</span><span class="mf">15.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># distance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dist</span>
<span class="n">array</span><span class="p">([</span> <span class="mf">17.49285568</span><span class="p">,</span>  <span class="mf">21.58703314</span><span class="p">,</span>  <span class="mf">73.79024326</span><span class="p">,</span>  <span class="mf">56.04462508</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nearest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nearest</span>
<span class="mi">0</span>   <span class="c1"># ANS is (102.0, 203.0)</span>
</pre></div>


<h5><u>Slice and Fancy Indexing</u></h5>
<p>最後，來看一下我們可以怎麼去切ndarray。在python內建語言中，常見的slice是這個樣子</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</pre></div>


<p>那如果是維度再加一級呢？則是這個樣子</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">4</span><span class="p">]</span>
<span class="mi">6</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</pre></div>


<p>如果是ndarray，我們常常處理維度大於1的陣列，如果用這個方法來slice，就顯得非常麻煩，Numpy提供了一種比較直覺的方式來做slice。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">M</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="mi">3</span>
</pre></div>


<p>在中括號裡頭用逗點隔開來表示在各個axis上要取的位置，還可以填入一個陣列來取出一個範圍。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span>   <span class="c1"># &quot;:&quot;代表全取，效果和 M[1,0:2]一樣</span>
<span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">,[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span> <span class="c1"># 寫成陣列也可以，效果和 M[1,0:2]一樣</span>
<span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># 還可以做到在axis=0的方向上取範圍，這是list做不到的</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">M</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
</pre></div>


<p>我們也可以引入一個ndarray來做篩選，常見使用的是布林陣列。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="p">(</span> <span class="n">N</span> <span class="o">!=</span> <span class="mi">1</span> <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">N</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span>
<span class="n">array</span><span class="p">([[</span><span class="bp">False</span><span class="p">,</span>  <span class="bp">True</span><span class="p">],</span>
       <span class="p">[</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">N</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</pre></div>


<p>b是由一個邏輯運算產生，這個邏輯運算會對矩陣作element-wise operation，所以會得出一個大小相同的布林陣列。而我們可以將b引入N當作篩選器，把符合的給取出來。事實上還可以更強大的去將取出來的值改值。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">N</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">N</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
</pre></div>


<p>上面我將取出來的值加倍，這樣的手法來取值改值會直接影響到原陣列，這是一個很重要的手法。</p>
<h5><u>子彈總結</u></h5>
<ul>
<li>產生ndarray的其他方法：np.arange, np.linspace, np.zeros, np.ones, np.eye, np.random.random 和 np.fromfunction</li>
<li>Broadcasting的前題：所有矩陣的shape由axis＝-1開始對齊去比較彼此間的rank，所有矩陣的在每個axis下的rank必須符合以下兩種規則其中之一：</li>
<li>所有rank為同一個值</li>
<li>只能有一個矩陣rank為非0或1，其餘矩陣的rank都要為0或1</li>
<li>Slicing Method ( Ex: M[1,0:2] )</li>
<li>布林陣列的取值賦值方法</li>
</ul></dd>
                <dt>2017 / 4月 22</dt>
                <dd><a href="./ml-course-techniques_7.html">機器學習技法 學習筆記 (7)：Radial Basis Function Network與Matrix Factorization</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><blockquote>
<p>本篇內容涵蓋Radial Basis Function (RBF) Network、K-Means、One-Hot Encoding和Matrix Factorization。</p>
</blockquote>
<p><br/></p>
<h5><u>Radial Basis Function (RBF) Network</u></h5>
<p>回顧一下Gaussian Kernel SVM，</p>
<blockquote>
<p>W = 𝚺<sub>n=sv</sub> α<sub>n</sub>y<sub>n</sub>Z<sub>n</sub>  <br/></p>
<p>G<sub>SVM</sub>   <br/></p>
<p>= sign[WZ+b] <br/></p>
<p>= sign{[𝚺<sub>n=sv</sub>α<sub>n</sub>y<sub>n</sub>K(X<sub>n</sub>,X)]+b} <br/></p>
<p>⇒ G<sub>SVM</sub> = sign{[𝚺<sub>n=sv</sub>α<sub>n</sub>y<sub>n</sub>exp(-γ|X-X<sub>n</sub>|<sup>2</sup>)]+b} <br/></p>
</blockquote>
<p>看到這個式子你想到了什麼？有沒有融會貫通的感覺，你同樣的可以把上面的式子看成是Aggregation，又或者是Network。</p>
<p>先來定義一下RBF Function， 其實就是Gaussian Function，</p>
<p><strong>RBF Function: RBF(X,X<sub>n</sub>)=exp(-γ|X-X<sub>n</sub>|<sup>2</sup>)</strong></p>
<p>所以我們可以仿造SVM的形式來造一個Network，</p>
<p><strong>G=Output{[𝚺<sub>m</sub> β<sub>m</sub>RBF(X,μ<sub>m</sub>)]+b}</strong></p>
<p>當Output為sign Function、β<sub>m</sub>為α<sub>n</sub>y<sub>n</sub>就回到特例SVM了。</p>
<p>我們來細看這個式子傳遞的概念，RBF Network的第一層是先產生M組RBF(X,μ<sub>m</sub>)，意味著以這M個位置μ<sub>m</sub>當作中心點來評估各個X與它的相似程度，RBF是有評估相似度的味道，越接近μ<sub>m</sub>的點，RBF越大，並隨著與μ<sub>m</sub>距離變大，RBF的值也快速遞減，所以這M個μ<sub>m</sub>是有象徵性的，越接近它你越受它的影響。</p>
<p>決定了每一筆數據各是受哪些μ<sub>m</sub>影響，接下來第二層是由這M個代表性的位置來進行投票決定最後的結果，這意味的不同的地方μ<sub>m</sub>對最後結果也有不同的影響力，舉個例子，假設在SVM裡頭，某個μ<sub>m</sub>如果它的y<sub>m</sub>=+1，那它對最後的影響就會是正的；那如果某個μ<sub>m</sub>的y<sub>m</sub>=-1，那它對最後的影響就會是負的，所以一個點進來，先評估一下它和象徵性的幾個點μ<sub>m</sub>的距離，如果相鄰幾點都是正的，這個點最後的結果就會是正的。</p>
<p><img alt="RBF Network" src="https://www.ycc.idv.tw/media/MachineLearningTechniques/MachineLearningTechniques.000_05.png"></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf</a></p>
<p>RBF Network在歷史上是Neural Network的一個分支，不過從上面的介紹你就會發現，它們的結構是有差異的，演算法也就不一樣。</p>
<p>通常最佳化RBF Network做法是這樣的，我們會先用一些方法將μ<sub>m</sub>決定，如果μ<sub>m</sub>很懶惰的就直接使用所有的Training Data，總共有N個μ<sub>m</sub>，這就叫做<strong>「Full RBF Network」</strong>。<strong>我們也可以使用一些歸納的演算法找出代表資料群體的幾個象徵性的中心點，例如待會會介紹的K-Means的方法</strong>，找出k個μ<sub>m</sub>再做計算，這樣的RBF Network稱為<strong>「k Nearest Neighbor RBF Network」</strong>。</p>
<p>找到了μ<sub>m</sub>就已經決定了所有的RBF Function，接下來就可以線性組合這些RBF Function，我們可以使用Regression的方法來求取β<sub>m</sub>。</p>
<p>而如果你使用「Full RBF Network」，你會發現做完Regression後E<sub>in</sub>=0，這是典型的Overfitting，那這時你可能就要採用有Regularization的Regression啦！譬如說Ridge Regression之類的。</p>
<p><br/></p>
<h5><u>K-Means</u></h5>
<p><img alt="K-Means" src="https://www.ycc.idv.tw/media/MachineLearningTechniques/MachineLearningTechniques.000_06.png"></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/214_handout.pdf</a></p>
<p>接下來來看怎麼用K-Means找到代表資料群體的幾個象徵性的中心點。</p>
<p>首先，先決定要有幾個「中心點」，這裡假設我要有k個好了，接下來先隨機給這些「中心點」一個初始的位置，接下來根據數據的靠近程度開始歸類，如果一筆數據比較所有的「中心點」後發現離「中心點」A是最近的話，那這筆數據就歸「中心點」A了，就用這樣的規則把所有數據都做分類。</p>
<p>分完類後，接下來平均每一個資料群體裡的數據座標找出新的代表這個群體的「中心點」，然後又拿這個新的「中心點」根據數據的靠近程度再歸類一次，如此循環多次，直到收斂為止。這樣的話，這k個「中心點」收斂後會各自佔據四方，並且代表某個群體的中心點。我們就可以找到代表性的k個點，並拿這些點做「k Nearest Neighbor RBF Network」。</p>
<p><br/></p>
<h5><u>One-Hot Encoding</u></h5>
<p>討論這麼久的ML，我們還沒有討論過假設遇到「類別」要怎麼處理！</p>
<p><strong>通常遇到類別的狀況，我們還是需要把它轉換成數值或向量來處理，常見的方法叫做One-Hot Encoding。</strong></p>
<p>舉個例子，如果要描述血型應該要怎麼做？我們可是無法拿字串下去Regression的啊～此時就需要One-Hot Encoding，假設血型有A, B, AB, O四種，我們可以這樣設定，</p>
<p>A = [1, 0, 0, 0]<sup>T</sup></p>
<p>B = [0, 1, 0, 0]<sup>T</sup></p>
<p>AB = [0, 0, 1, 0]<sup>T</sup></p>
<p>O = [0, 0, 0, 1]<sup>T</sup></p>
<p>就是這麼簡單，這個動作就叫做One-Hot Encoding。</p>
<p><br/></p>
<h5><u>Matrix Factorization</u></h5>
<p><strong>那如果今天我的Input和Output都是類別，而我們想要讓機器自己去找到匹配Input和Output的機制，解決這個問題的方法稱之為Matrix Factorization。</strong></p>
<p><strong>Matrix Factorization精神上有點像是Autoencoder，Autoencoder找出隱含在Data裡的特性，而Matrix Factorization則是找出隱含的匹配關係。</strong></p>
<p>舉個例子，如果Netflix有了一堆用戶和他們曾看過的電影的資料，我們想要從中抽取出用戶與他愛看的電影之間的關係，所以這不單單只是匹配而已，單純匹配就只需要硬碟就做的到了，我們要做的是找出匹配的規律，並且用更少、更精簡的方式表示這個匹配關係，舉個例子，有可能有部分用戶會被歸納到愛看恐怖片的，並且同時這些客戶會被連結到具有恐怖元素的電影，我們預期Matrix Factorization會有自行歸納整理的能力。</p>
<p>可以仿造Autoencoder來設計Matrix Factorization，而你會發現Activation Function只要使用線性就已經足夠了，因為對於One-Hot Encoding的類別來說，只有一條通道是有效的，這已經具有開關的味道了，所以我們不用在Activation Function上面再弄一道開關，所以採用Linear就足夠了。</p>
<p><img alt="Matrix Factorization" src="https://www.ycc.idv.tw/media/MachineLearningTechniques/MachineLearningTechniques.000_07.png"></p>
<p>from: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf</a></p>
<p>因為是線性模型的緣故，我們可以很簡單的使用矩陣來描述，</p>
<p>Hypothesis: h(X) = W<sup>T</sup>VX</p>
<p>而如果是某一用戶，則</p>
<p>h(X<sub>n</sub>) = W<sup>T</sup>V<sub>n</sub></p>
<p>對某個用戶而言與他匹配的電影是一個向量，上面紀錄了他看過的電影，假設我再指定一部電影m，此時W<sub>m</sub><sup>T</sup>V<sub>n</sub>就代表這個用戶有沒有看過這部電影。</p>
<p>用這個方法來想問題，假設今天你把用戶和電影填成一個大的表格，或是矩陣，有交集的部分就打個勾，這個矩陣的每個元素表示成r<sub>nm</sub>，有打勾的部分r<sub>nm</sub>=1，沒打勾的部分r<sub>nm</sub>=0，那我們做的轉換W和V最終就是為了讓</p>
<p>W<sub>m</sub><sup>T</sup>V<sub>n</sub>≈r<sub>nm</sub></p>
<p>為了評估匹配的好壞，我們定義Error Function為</p>
<p>E<sub>in</sub>({W<sub>m</sub>},{V<sub>n</sub>}) = (1/𝚺<sub>m</sub> |D<sub>m</sub>|)×𝚺<sub>n,m</sub> (r<sub>nm</sub>-W<sub>m</sub><sup>T</sup>V<sub>n</sub>)<sup>2</sup></p>
<p>最佳化Matrix Factorization有兩個演算法，一個是Alternating Least Squares，另外一個是SGD。</p>
<p><br/></p>
<h5><u>Alternating Least Squares for Matrix Factorization</u></h5>
<p><img alt="Alternating Least Squares for Matrix Factorization" src="https://www.ycc.idv.tw/media/MachineLearningTechniques/MachineLearningTechniques.000_08.png"></p>
<p>from: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf</a></p>
<p>第一個方法是利用Linear Regression交互的優化W<sub>m</sub>和V<sub>n</sub>，我們的目標是使得W<sub>m</sub><sup>T</sup>V<sub>n</sub>=r<sub>nm</sub>，這式子可以用兩個角度看，如果固定W<sub>m</sub>，優化V<sub>n</sub>，那就是線性擬合{V<sub>n</sub>, r<sub>nm</sub>}的問題；那如果固定V<sub>n</sub>，優化W<sub>m</sub>，這就是線性擬合{W<sub>m</sub>, r<sub>nm</sub>}的問題。<strong>因此，交替優化W<sub>m</sub>和V<sub>n</sub>就可以使得W<sub>m</sub><sup>T</sup>V<sub>n</sub>越來越接近r<sub>nm</sub>了</strong>。</p>
<p><br/></p>
<h5><u>SGD for Matrix Factorization</u></h5>
<p><img alt="SGD for Matrix Factorization" src="https://www.ycc.idv.tw/media/MachineLearningTechniques/MachineLearningTechniques.000_09.png"></p>
<p>from: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/215_handout.pdf</a></p>
<p>第二個方法則是老招—Gradient Descent，這裡採用隨機的版本SGD，所以過程中我們會隨意的從(n,m)中挑點，然後根據Error Measure</p>
<p>E<sub>in</sub>({W<sub>m</sub>},{V<sub>n</sub>}) = (1/𝚺<sub>m</sub> |D<sub>m</sub>|)×𝚺<sub>n,m</sub> (r<sub>nm</sub>-W<sub>m</sub><sup>T</sup>V<sub>n</sub>)<sup>2</sup></p>
<p>我們就可以得到更新W<sub>m</sub>和V<sub>n</sub>的方法，詳細的方法見上圖所示。</p>
<p><strong>目前，SGD方法是處理大型Matrix Factorization最流行的作法。</strong></p>
<p><br/></p>
<h5><u>結語</u></h5>
<p>本篇介紹類似Neural Network的兩種Network結構，分別為Radial Basis Function (RBF) Network和Matrix Factorization。</p>
<p>在做RBF Network時，我們先找出幾個代表的中心，並評估一筆資料與這些中心的距離，再來再考慮不同中心對於答案的貢獻，加總起來可以預測這筆資料的答案，我們可以使用K-Means的方法來找出k點代表性的中心點來做RBF Network。</p>
<p>Matrix Factorization和Autoencoder有點類似，Autoencoder目標在於找出隱含在Data裡的特性，而Matrix Factorization則是找出隱含的匹配關係，並且介紹了兩種Matrix Factorization的演算法：Alternating Least Squares和SGD方法。</p>
<p>這系列的介紹文章，到這裡算是走到尾聲了，最後跟大家推薦一下老師的最後一堂課的投影片：</p>
<p><a href="https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/216_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mltech17spring/doc/216_handout.pdf</a></p>
<p>這個投影片裡頭林軒田教授用心的彙整了一整個學期的內容，很值得一看。</p></dd>
                <dt>2017 / 4月 17</dt>
                <dd><a href="./ml-course-techniques_6.html">機器學習技法 學習筆記 (6)：神經網路(Neural Network)與深度學習(Deep Learning)</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><blockquote>
<p>本篇內容涵蓋神經網路(Neural Network, NN)、深度學習(Deep Learning, DL)、反向傳播算法(Backpropagation, BP)、Weight-elimination Regularizer、Early Stop、Autoencoder、Principal Component Analysis (PCA)。</p>
</blockquote>
<p><br/></p>
<h5><u>神經網路(Neural Network)</u></h5>
<p>最後一個主題，我們要來講第三種「特徵轉換」— Extraction Models，其實就是現今很流行的「類神經網路」(Neural Network) 和「深度學習」(Deep Learning)，包括下圍棋的AlphaGo、Tesla的自動駕駛都是採用這一類的Machine Learning。</p>
<p>Extraction Models的基本款就是廣為人知的「神經網路」(Neural Network)，它的特色是使用神經元來做非線性的特徵轉換，那如果具有多層神經元，就是做了多次的非線性特徵轉換，這就是所謂的「深度學習」(Deep Learning)。</p>
<p><img alt="Neural Network" src="https://dl.dropbox.com/s/a7divvzh6mzfwvb/MachineLearningTechniques.016.jpeg"></p>
<p>上圖左側就是具有一層神經元的Neural Network，首先我們有一組特徵X，通常我們會加入一個維度X<sub>0</sub>=1，這是為了可以讓結構變得更好看，未來可以與W<sub>0</sub>相乘產生常數項。使用W來給予特徵X權重，最後總和的結果稱之為Score，s = W<sub>0</sub>X<sub>0</sub>+𝚺<sub>i=1</sub>W<sub>i</sub>X<sub>i</sub> = 𝚺<sub>i=0</sub>W<sub>i</sub>X<sub>i</sub>。</p>
<p>這個Score會被輸入到一個Activation Function裡頭，<strong>Activation Function的用意就是開關</strong>，當Score大於某個閥值，就打通線路讓這條路的貢獻可以繼續向後傳遞；當Score小於某個閥值，就關閉線路，所以Activation Function可以是Binary Function，但在實際操作之下不會使用像Binary Function這類不可以微分的Activation Function，所以我們會找具有相似特性但又可以微分的函數，例如tanh或者是ReLU這類比較接近開關效果的函數，經過Activation Function轉換後的輸出表示成g<sub>t</sub> = σ(𝚺<sub>i</sub>W<sub>i</sub>X<sub>i</sub>)，這個g<sub>t</sub>就稱為神經元、σ為Activation Function、𝚺<sub>i</sub> W<sub>i</sub>X<sub>i</sub>是Score。</p>
<p>如果我們有多組權重W就能產生多組神經元g<sub>t</sub>，然後最後把g<sub>t</sub>做線性組合並使用Output Function h(x)來衡量出最後的答案，Output Function可以是Linear Classification的Binary Function h(x)=sign(x)，不過一樣的問題，它不可以微分，通常不會被使用，常見的是使用Linear Regression h(x)=x，或者Logistic Regression h(x)=Θ(x)來當作Output Function，最後的結果可以表示成 y=h(𝚺<sub>t</sub>α<sub>t</sub>g<sub>t</sub>)，看到這個式子有沒有覺得很熟悉，它就像我們上一回講的Aggregation，將特徵X使用特徵轉換轉成使用g<sub>t</sub>表示，再來組合這些g<sub>t</sub>成為最後的Model，所以單層的Neural Network就使用到了Aggregation，它繼承了Aggregation的優點。</p>
<p>有了這個Model的形式了，我們可以使用Gradient Descent的手法來做最佳化，這也就是為什麼要讓操作過程當中所使用的函數都可以微分的原因。Gradient Descent在Neural Network的領域裡面發展出一套方法稱為Backpropagation，我們待會會介紹。<strong>因此實現Backpropagation，我只要餵Data進去，Model就會去尋找可以描述這組Data的特徵轉換g<sub>t</sub>，這就好像是可以從Data中萃取出隱含的Feature一樣，所以這類的Models才會被統稱為Extraction Models</strong>。</p>
<p><br/></p>
<h5><u>深度學習(Deep Learning)</u></h5>
<p>剛剛我們介紹了最基本款的Neural Network，那如果這個Neural Network有好幾層，我還會稱它為Deep Learning，所以基本上Deep Neural Network和Deep Learning是指同一件事，那為什麼會有兩個名字呢？其實是有歷史典故的。</p>
<p>Neural Network的歷史相當悠久，早在1958年就有人提出以Perceptron當作Activation Function的單層Neural Network，大家也知道一層的Neural Network是不Powerful的，所以在1969年，就有人寫了論文叫做「perceptron has limitation」，從那時Neural Network的方法就很少人研究了。</p>
<p>直到1980年代，有人開始使用多層的Neural Network，並在1989年，Yann LeCun博士等人就已經將反向傳播演算法(Backpropagation, BP)應用於Neural Network，當時Neural Network的架構已經和現在的Deep Learning很接近了，不過礙於當時的硬體設備計算力不足，Neural Network無法發揮功效，並且緊接的<strong>有人在1989年證明了只要使用一層Neural Network就可以代表任意函數，那為何還要Deep呢？</strong>所以Deep Neural Network這方法就徹底黑掉了。</p>
<p>一直到了最近，<strong>G. E. Hinton博士為了讓Deep Neural Network起死回生，重新給了它一個新名字「Deep Learning」</strong>，再加上他在2006年提出的RBM初始化方法，這是一個非常複雜的方法，所以在學術界就造成了一股流行，雖然後來被證明RBM是沒有用的，不過卻因為很多人參與研究Deep Learning的關係，也找出了解決Deep Learning痛處的方法，<strong>2009年開始有人發現使用GPU可以大大的加速Deep Learning</strong>，從這一刻起，Deep Learning就開始流行起來，直到去年的2016年3月，圍棋程式Alpha GO運用Deep Learning技術以4:1擊敗世界頂尖棋手李世乭，Deep Learning正式掀起了AI的狂潮。</p>
<p>聽完這個故事我們知道改名字的重要性XDD，不過大家是否還有看到什麼關鍵，「使用一層Neural Network就可以代表任意函數，那為何還要Deep呢？」這句話，這不就否定了我們今天做的事情了嗎？的確，使用一層的Neural Network就可以形成任意函數，但這一層的神經元也同樣需要無窮多個才做的到。<strong>Deep Learning的學習方法和人有點類似，我們在學習一個艱深的理論時，會先單元式的針對幾個簡單的概念學習，然後在整合這些概念去理解更高層次的問題</strong>，Deep Learning透過多層結構學習，雖然第一層的神經元沒有很多，能學到的也只是簡單的概念而已，不過第二層再重組這些簡單概念，第三層再用更高層次的方法看問題，所以同樣的問題使用一層Neural Network可能需要很多神經元才有辦法描述，但是Deep Learning卻可以使用更少的神經元做到一樣的效果。</p>
<p>另外，Deep Learning還有一個很大好處，就是比較不容易Overfitting，你可以想像一下如果我們使用100個神經元來造一個單層Neural Network，跟使用100個神經元來造一個五層的Neural Network，哪一個比容易Overfitting，當然是單層的Neural Network，多層Neural Network是使用一個從簡單到複雜的抽取特徵方法，所以它比較不易受到雜訊的影響，<strong>Deep Learning在建立多層「模組化」的過程可以抑制對於雜訊的過度反應，這等於是一種Regularization</strong>。</p>
<p><strong>因此，Deep Learning中每一層當中做了Aggregation，在增加模型複雜度的同時，也因為平均的效果而做到截長補短，這具有Regularization的效果，並且在採用多層且瘦的結構也同時因為「模組化」而做到Regularization，這就不難想像Deep Learning為何如此強大。</strong></p>
<p><br/></p>
<h5><u>反向傳播算法(Backpropagation, BP)</u></h5>
<p><img alt="Neural Network" src="https://dl.dropbox.com/s/khbpmalswll787f/MachineLearningTechniques.017.jpeg"></p>
<p>我們接下來就來看一下Deep Learning的演算法—反向傳播法，我們來看要怎麼從Gradient Descent來推出這個算法。</p>
<p>看一下上面的圖，我畫出了具有L層深的Deep Learning，每一層都有一個權重W<sub>ij</sub><sup>(ℓ)</sup>，因此我們可以估計出每一層的Score s<sub>j</sub><sup>(ℓ)</sup>= 𝚺<sub>i</sub> W<sub>ij</sub><sup>(ℓ)</sup>X<sub>i</sub><sup>(ℓ-1)</sup>，把Score s<sub>j</sub><sup>(ℓ)</sup>通過Activation Function，就可以得到下一層的Input，如此不斷的疊上去，直到最後一層L為Output Layer，Output最後的結果y，這裡我使用Linear Function來當作Output Function，這就是Deep Learning最簡單的架構。</p>
<p>而我們需要Training的就是這些權重W<sub>ij</sub><sup>(ℓ)</sup>，我們如何一步一步的更新W<sub>ij</sub><sup>(ℓ)</sup>，使得它可以Fit數據呢？回想一下Gradient Descent的流程：</p>
<ol>
<li>定義出Error函數</li>
<li>Error函數讓我們可以去評估E<sub>in</sub></li>
<li>算出它的梯度∇E<sub>in</sub></li>
<li>朝著∇E<sub>in</sub>的反方向更新參數W，而每次只跨出η大小的一步</li>
<li>反覆的計算新參數W的梯度，並一再的更新參數W</li>
</ol>
<p>假設使用平方誤差的話，Error函數在這邊就是</p>
<p>L = (1/2) (y-ŷ)<sup>2</sup>，</p>
<p>因此我們的更新公式可以表示成</p>
<p>W<sub>ij</sub><sup>(ℓ)</sup> ←  W<sub>ij</sub><sup>(ℓ)</sup>-η×∂L/∂W<sub>ij</sub><sup>(ℓ)</sup> </p>
<p>那我們要怎麼解這個式子呢？關鍵就在∂L/∂W<sub>ij</sub><sup>(ℓ)</sup>這項要怎麼計算，這一項在Output Layer (ℓ=L)是很好計算的，</p>
<p>∂L/∂W<sub>ij</sub><sup>(L)</sup></p>
<p>= {∂L/∂s<sub>j</sub><sup>(L)</sup>}×{∂s<sub>j</sub><sup>(L)</sup>/∂W<sub>ij</sub><sup>(L)</sup>}  (連鎖率)</p>
<p>= {δ<sub>j</sub><sup>(L)</sup>}×{X<sub>i</sub><sup>(L-1)</sup>}</p>
<p>上式當中我們使用了微分的連鎖率，並且令</p>
<p><strong>δ<sub>j</sub><sup>(L)</sup> = ∂L/∂s<sub>j</sub><sup>(L)</sup></strong></p>
<p>δ<sub>j</sub><sup>(L)</sup>這一項被稱為Backward Pass Term，而X<sub>i</sub><sup>(L-1)</sup>這項被稱為Forward Pass Term，所以L層權重的更新取決於Forward Pass Term和Backward Pass Term相乘δ<sub>j</sub><sup>(L)</sup>×X<sub>i</sub><sup>(L-1)</sup>。</p>
<p>我們先來看一下L層的Forward Pass Term要怎麼計算，X<sub>i</sub><sup>(L-1)</sup>這項是很容易求的，我們只要讓數據一路從0層傳遞上來就可以自然而然的得到X<sub>i</sub><sup>(L-1)</sup>的值，所以我們會稱X<sub>i</sub><sup>(L-1)</sup>這一項為Forward Pass Term，因為我們必須要往前傳遞才可以得到這個值。</p>
<p>再來看一下L層的Backward Pass Term要怎麼計算，δ<sub>j</sub><sup>(L)</sup>一樣是很容易求得的，</p>
<p>δ<sub>j</sub><sup>(L)</sup> = ∂L/∂s<sub>j</sub><sup>(L)</sup> = ∂[(1/2) (y-ŷ)<sup>2</sup>]/∂y = (y-ŷ)</p>
<p>你會發現這一項的計算需要得到誤差的資訊，而誤差資訊要等到Forward的動作做完才有辦法得到，所以資訊的傳遞方向是從尾巴一路回到頭，是一個Backword的動作。</p>
<p>因此，最後一層也是Output Layer的更新公式如下：</p>
<p>W<sub>ij</sub><sup>(L)</sup> ←  W<sub>ij</sub><sup>(L)</sup>-η×δ<sub>j</sub><sup>(L)</sup>×X<sub>i</sub><sup>(L-1)</sup></p>
<p>權重的更新取決於Input和Error的影響，需要考慮Forward Pass Term和Backward Pass Term。</p>
<p>那除了Output這一層以外的權重應該怎麼更新？來看一下(ℓ)層，</p>
<p>∂L/∂W<sub>ij</sub><sup>(ℓ)</sup></p>
<p>= {∂L/∂s<sub>j</sub><sup>(ℓ)</sup>}×{∂s<sub>j</sub><sup>(ℓ)</sup>/∂W<sub>ij</sub><sup>(ℓ)</sup>} (連鎖率)</p>
<p>= δ<sub>j</sub><sup>(ℓ)</sup>×X<sub>i</sub><sup>(ℓ-1)</sup></p>
<p>一樣是Forward Pass Term和Backword Pass Term相乘，不過δ<sub>j</sub><sup>(ℓ)</sup>這一項的計算有點技巧性，來看一下，</p>
<p>δ<sub>j</sub><sup>(ℓ)</sup></p>
<p>= ∂L/∂s<sub>j</sub><sup>(ℓ)</sup></p>
<p>= 𝚺<sub>k</sub> {∂L/∂s<sub>k</sub><sup>(ℓ+1)</sup>}×{∂s<sub>k</sub><sup>(ℓ+1)</sup>/∂X<sub>jk</sub><sup>(ℓ)</sup>}×{∂X<sub>jk</sub><sup>(ℓ)</sup>/∂s<sub>j</sub><sup>(ℓ)</sup>} (連鎖率)</p>
<p>= 𝚺<sub>k</sub> {δ<sub>k</sub><sup>(ℓ+1)</sup>}×{W<sub>jk</sub><sup>(ℓ)</sup>}×{σ'(s<sub>j</sub><sup>(ℓ)</sup>)}</p>
<p>W<sub>jk</sub><sup>(ℓ)</sup>和σ'(s<sub>j</sub><sup>(ℓ)</sup>)都是Forward之後就會得到的資訊，而δ<sub>k</sub><sup>(ℓ+1)</sup> 而是需要Backward才可以得到，我們已經知道δ<sub>j</sub><sup>(ℓ=L)</sup>的值，就可以從δ<sub>j</sub><sup>(ℓ=L)</sup>開始利用上面的公式，一路Backward把所有的δ<sub>j</sub>都找齊。好！那現在我們已經找到了更新所有Weights的方法了。</p>
<p>看一下上圖中的最下面的Flow，一開始我們Forward，把所有X和s都得到，到了Output Layer，我們得到了δ<sub>j</sub><sup>(ℓ=L)</sup>，再Backward回去找出所有的δ，接下來就可以用Forward Pass Term和Backword Pass Term來Update所有的W了。</p>
<p>總結一下，反向傳播算法(Backpropagation, BP)更新權重的方法為</p>
<blockquote>
<p><strong>W<sub>ij</sub><sup>(ℓ)</sup> ←  W<sub>ij</sub><sup>(ℓ)</sup>-η×δ<sub>j</sub><sup>(ℓ)</sup>×X<sub>i</sub><sup>(ℓ-1)</sup>  <br/></strong></p>
<p><strong>If output layer (ℓ=L), δ<sub>j</sub><sup>(ℓ=L)</sup>=(y-ŷ)  <br/></strong></p>
<p><strong>If other layer, δ<sub>j</sub><sup>(ℓ)</sup>= σ'(s<sub>j</sub><sup>(ℓ)</sup>) × 𝚺<sub>k</sub> δ<sub>k</sub><sup>(ℓ+1)</sup>×W<sub>jk</sub><sup>(ℓ)</sup>  <br/></strong></p>
<p><strong>δ<sub>j</sub><sup>(ℓ)</sup>為Backword Pass Term；X<sub>i</sub><sup>(ℓ-1)</sup>為Forward Pass Term。</strong></p>
</blockquote>
<p><br/></p>
<h5><u>Regularization in Deep Learning</u></h5>
<p>那麼像是Deep Learning這麼複雜的Model，我們要怎麼避免Overfitting呢？有五個方法。</p>
<p>第一個方法，就是我們剛剛提過的<strong>「設計Deep Neural Network的結構」</strong>，藉由限縮一層當中的神經元來達到一種限制，做到Regularization。</p>
<p>第二個方法是<strong>「限制W的大小」</strong>，和標準Regularization作一樣的事情，我們將W的大小加進去Cost裡頭做Fitting，例如使用L2 Regularizer Ω(W)=𝚺(W<sub>jk</sub><sup>(ℓ)</sup>)<sup>2</sup>，但這樣使用有一個問題就是W並不是Sparse的，L2 Regularizer在抑制W的方法是，如果W的分量大的話就抑制多一點，如果分量小就抑制少一點（因為W<sup>2</sup>微分為一次），所以最後會留下很多很小的分量，造成計算量大大增加，尤其像是Deep Learing這麼龐大的Model，這樣的Regularization顯然不夠好，L1 Regularizer顯然可以解決這個問題（因為在大部分位置微分為常數），但不幸的是它無法微分，所以就有了L2 Regularizer的衍生版本，</p>
<p>Weight-elimination L2 regularizer: 𝚺[(W<sub>jk</sub><sup>(ℓ)</sup>)<sup>2</sup>]/[1+(W<sub>jk</sub><sup>(ℓ)</sup>)<sup>2</sup>]</p>
<p>這麼一來不管W大或小，它受到抑制的值大小接近的 (Weight-elimination L2 regularizer微分為 -1次方)，因此就可以使得部分W可以為0，大大便利於我們做計算。</p>
<p>第三種方法是最常使用的<strong>「Early Stopping」</strong>，所謂的Early Stopping就是，在做Backpropagation的過程去觀察Validation Data的Error有沒有脫離Training Data的Error太多，如果開始出現差異，我們就立刻停止計算，這樣就可以確保Model裡的參數沒有使得Model產生Overfitting，是一個很直接的作法。</p>
<p>第四種方法是<strong>「Drop-out」</strong>，在Deep Learing Fitting的過程中，隨機的關閉部分神經元，藉由這樣的作法使得Fitting的過程使用較少的神經元，並且使得結構是瘦長狀的，來達到Regularization。</p>
<p>第五種方法是接下來會用更大篇幅介紹的<strong>「Denoising Autoencoder」</strong>，在Deep Neural Network前面加入這樣的結構有助於抑制雜訊。</p>
<p><br/></p>
<h5><u>Autoencoder</u></h5>
<p><img alt="Regularization in Deep Learning" src="https://dl.dropbox.com/s/qnyy3uyyszq45yx/MachineLearningTechniques.018.jpeg"></p>
<p>Neural Network針對不同需要發展出很多不同的型態，包括CNN, RNN，還有接下來要介紹的Autoencoder，<strong>Autoencoder是一種可以將資料重要資訊保留下來的Neural Network</strong>，效果有點像是資料壓縮，在做資料壓縮時，會有一個稱為Encoder的方法可以將資料壓縮，那當然還要有另外一個方法將它還原回去，這方法稱為Decoder，壓縮的過程就是用更精簡的方式保存了資料。<strong>Autoencoder同樣的有Encoder和Decoder，不過它不像資料壓縮一樣可以百分之一百還原，不過特別之處是Autoencoder會試著從Data中自己學習出Encoder和Decoder，並盡量讓資料在壓縮完了可以還原回去原始數據</strong>。</p>
<p>見上圖中Basic Autoencoder的部分，透過兩層的轉換，我們試著讓Input X可以完整還原回去，通常中間這一層會使用比較少的神經元，因為我們想要將資訊做壓縮，所以第一層的部分就是一個Encoder，而第二層則是Decoder，他們由權重W<sub>jk</sub><sup>(ℓ)</sup>決定，而在Training的過程，Autoencoder會試著找出最好的W<sub>jk</sub><sup>(ℓ)</sup>來使得資訊可以盡量完整還原回去，這也代表Autoencoder可以自行找出了Encoder和Decoder。</p>
<p><strong>Encoder這一段就是在做一個Demension Reduction</strong>，Encoder轉換原本數據到一個新的空間，這個空間可以比原本Features描述的空間更能精準的描述這群數據，而中間這層Layer的數值就是新空間裡頭的座標，有些時候我們會用這個新空間來判斷每筆Data之間彼此的接近程度。</p>
<p>我們也可以讓Encoder和Decoder可以設計的更複雜一點，所以你同樣的可以使用多層結構，稱之為Deep Autoencoder。另外，也有人使用Autoencoder的方法來Pre-train Deep Neural Network的各個權重。</p>
<p>緊接著介紹兩種特殊的例子，第一個是Linear Autoencoder，我們把所有的Activation Function改成線性的，這個方法可以等效於待會要講的Principal Component Analysis (PCA)的方法，PCA是一個全然線性的方法，所以它的效力會比Autoencoder差一點。</p>
<p>第二個是剛剛提到的Denoising Autoencoder，我們在原本Autoencoder的前面加了一道增加人工雜訊的流程，但是又要讓Autoencoder試著去還原出原來沒有加入雜訊的資訊，這麼一來<strong>我們將可以找到一個Autoencoder是可以消除雜訊的</strong>，把這個Denoising Autoencoder加到正常Neural Network的前面，那這個Neural Network就擁有了抑制雜訊的功用，所以可以當作一種Regularization的方法。</p>
<p><br/></p>
<h5><u>Principal Component Analysis (PCA)</u></h5>
<p>最後來講一下Principal Component Analysis (PCA)，它不太算是Deep Learning的範疇，不過它是一個傳統且重要的Dimension Reduction的方法，我們就來看一下。</p>
<p><img alt="PCA" src="https://dl.dropbox.com/s/4ek9k9g8vrwnwia/MachineLearningTechniques.019.jpeg"></p>
<p>PCA的演算法是這樣的，第一步先求出資料Features的平均值，並且將各個Features減掉平均值，令為ζ，第二步求出由ζ<sup>T</sup>ζ產生的矩陣的Eigenvalue和Eigenvector，第三步，從這些Eigenvalue和Eigenvector中挑選前面k個，並組成轉換矩陣W，而最終PCA的轉換就是Φ(x)=W<sup>T</sup>(X-mean(X))，這個轉換做的就是Dimension Reduction，將數據降維到k維。</p>
<p>PCA做的事是這樣的，每一個Eigenvector代表新空間裡頭的一個軸，而Eigenvalue代表站在這個軸上看資料的離散程度，當然我們如果可以描述每筆資料越分離，就代表這樣的描述方法越好，所以Eigenvalue越大的Eigenvector越是重要，<strong>所以取前面k個Eigenvector的用意是在降低維度的過程，還可以盡量的保持對數據的描述力，而且Eigenvector彼此是正交的，也就是說在新空間裡頭的每個軸是彼此垂直，彼此沒有Dependent的軸是最精簡的，所以PCA所做的Dimension Reduction一定是線性模型中最好、最有效率的</strong>。</p>
<p>另外，剛剛有提到的Linear Autoencode幾乎是等效於PCA，大家可以看上圖中的描述，這裡不多贅述，不過不同的是，Linear Autoencoder並沒有限制新空間軸必須是正交的特性，所以它的效率一定會比PCA來的差。</p>
<p><br/></p>
<h5><u>結語</u></h5>
<p>這一篇當中，我們介紹了Neural Network，並且探討多層Neural Network—Deep Neural Network，也等同於Deep Learning，並且說明為什麼需要「Deep」，然後介紹Deep Learning最重要的演算法—反向傳播算法，接著介紹五種常用的Regularization的方法：設計Deep Neural Network的結構、限制W的大小、Early Stopping、Drop-out和Denoising Autoencoder。</p>
<p>介紹完以上內容，我們就已經對於Deep Learning的全貌有了一些認識了，緊接著來看Deep Learning的特殊例子—Autoencoder，Autoencoder可以用來做Dimension Reduction，那既然提到了Dimension Reduction，那就不得不在講一下重要的線性方法PCA。</p>
<p>那在下一回，我們會繼續探討Neural Network還有哪些特殊的分支。</p></dd>
                <dt>2017 / 4月 17</dt>
                <dd><a href="./python-play-with-data_2.html">Python玩數據 (2)：Numpy [1/2]</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p>在上一次我們已經成功了安裝了IPython，這將會是我們這系列教學的主要舞台，而今天我要教大家在這個舞台上利用Numpy來做一些簡單的科學計算。</p>
<h5><u>IPython</u></h5>
<p>像上次一樣，打開IPython，緊接著把numpy和pandas載入，載入numpy之後我們習慣用<code>as</code>將它縮寫為<code>np</code>，pandas則縮寫為<code>pd</code>。</p>
<p><img alt="ipython" src="http://www.ycc.idv.tw/media/PlayDataWithPython/ipython.jpeg"></p>
<p>IPython是一個具有互動式介面的python執行介面，你可以一邊寫一邊理解目前的狀況，舉個例子</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># integer(整數)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>     <span class="c1"># check variable a</span>
<span class="mi">12</span>
</pre></div>


<p>在第一行中，我令變數a為12，而第二行只要把變數a直接key出來，我們就可以立刻查看變數裡頭有什麼內容，注意喔！在一般的python語言中，直接把變數key出來這件事是沒有意義的，這只有在IPython上才有的方便功能，<strong>有了這樣一個互動式的介面，讓我們在處理數據的時候可以隨時查看，目前數據的狀況</strong>。</p>
<h5><u>Python常見的資料型別</u></h5>
<p>Python常見的資料型別有整數(integer)、浮點數(floating-point number)、字串(string)、串列(list)、序對(tuple)、字典(dictionary)，可以使用<code>type()</code>來查詢資料型別。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># integer</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="mf">40.0</span> <span class="c1"># float, 必須有&#39;.&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;word&#39;</span> <span class="c1"># string</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">]</span> <span class="c1"># list</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="s1">&#39;6&#39;</span><span class="p">)</span> <span class="c1"># tuple</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">f</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span><span class="mi">2</span> <span class="p">}</span> <span class="c1"># dictionary</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="nb">str</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="nb">list</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">dict</span>
</pre></div>


<p>list和tuple裡面可以塞入任意的資料型別，甚至可以塞入另外一個list，或是自己定義的物件，list和tuple其實非常的相似，差異只在於tuple一旦決定了就不能在變更，但是list卻可以。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">d</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;new&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;new&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># 取出第一項(index=0)加一再設定回去第一項</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span>
<span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;new&#39;</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 刪除index=1的那項</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span>
<span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;new&#39;</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">e</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;new&#39;</span><span class="p">)</span>   <span class="c1"># fail</span>
<span class="ne">AttributeError</span><span class="p">:</span> <span class="s1">&#39;tuple&#39;</span> <span class="nb">object</span> <span class="n">has</span> <span class="n">no</span> <span class="n">attribute</span> <span class="s1">&#39;append&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="mi">4</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">e</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>   <span class="c1"># fail</span>
<span class="ne">TypeError</span><span class="p">:</span> <span class="s1">&#39;tuple&#39;</span> <span class="nb">object</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">support</span> <span class="n">item</span> <span class="n">assignment</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">del</span> <span class="n">e</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># fail</span>
<span class="ne">TypeError</span><span class="p">:</span> <span class="s1">&#39;tuple&#39;</span> <span class="nb">object</span> <span class="n">doesn</span><span class="s1">&#39;t support item deletion</span>
</pre></div>


<p>在python中，整數和浮點數可以作簡單的四則運算</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">6</span> <span class="o">/</span> <span class="mi">2</span>
<span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="mf">2.0</span> <span class="o">-</span> <span class="mf">6.0</span> <span class="o">/</span> <span class="mf">2.0</span>
<span class="mf">2.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">3</span> <span class="o">**</span> <span class="mi">2</span>  <span class="c1"># 指數</span>
<span class="mi">9</span>
</pre></div>


<p>一群整數做完運算輸出是整數，一群浮點數做完運算輸出是浮點數，那假如整數和浮點數混雜的情形呢？</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span>
<span class="mi">0</span>  <span class="c1"># 整數除整數，結果必定是整是，是整數0，而不是想像中的0.5，這種運算效果有點像求商</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">2.</span>
<span class="mf">0.5</span> <span class="c1"># 只要有任意浮點數出現，整數強迫轉為浮點數，然後再做運算，這才是我們要的結果</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">3</span> <span class="o">**</span> <span class="mf">2.</span>
<span class="mf">9.0</span>
</pre></div>


<p>所以在運算之前，你要想清楚你想要的目標是什麼？如果你有一個整數變數<code>someInt</code>接下來要作浮點數運算，可以使用<code>float(someInt)</code>強制先轉成浮點數再做接下來的運算，這樣比較不會犯錯。</p>
<p>事實上，轉成浮點數這樣的自動轉換在python中是很少見的，python是屬於<strong>強型別語言，所以型別和型別之間有很強的區份性，常常不會自動轉換</strong>，如果需要轉換必須要作額外的操作。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span> <span class="o">+</span> <span class="s1">&#39;2&#39;</span> <span class="c1"># fail</span>
<span class="ne">TypeError</span><span class="p">:</span> <span class="n">unsupported</span> <span class="n">operand</span> <span class="nb">type</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="o">+</span><span class="p">:</span> <span class="s1">&#39;int&#39;</span> <span class="ow">and</span> <span class="s1">&#39;str&#39;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="s1">&#39;2&#39;</span><span class="p">)</span> <span class="c1"># 使用int()將字串轉成整數</span>
<span class="mi">3</span>
</pre></div>


<p>常見的型別轉換函數有<code>int()</code>, <code>float()</code>, <code>str()</code>, <code>list()</code>, <code>tuple()</code>。所以如果要對一個tuple做更改，可以先轉成list再做運算。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># 在index為0的地方插入整數4</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">h</span>
<span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</pre></div>


<h5><u>Numpy的數學運算</u></h5>
<p>在上一段我簡單介紹了python內建的運算，在大多數情況，內建的運算就已經足夠應付了，不過如果遇到複雜的運算，例如：三角函數、取最大最小值、exp、log、開根號、矩陣運算，我們就需要用到 Numpy    。</p>
<p>首先先介紹Numpy的一些數學運算，Numpy的數學運算詳細<a href="https://docs.scipy.org/doc/numpy/reference/routines.math.html">參考這</a>。</p>
<p>我這邊舉幾個比較常見的例子。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># 加總</span>
<span class="mi">6</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># 最大值</span>
<span class="mi">3</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># 最小值</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 求餘數</span>
<span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mf">2.</span><span class="p">)</span> <span class="c1"># 求sin</span>
<span class="mf">1.0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># ln 和 e</span>
<span class="mf">1.0</span>
</pre></div>


<h5><u>Numpy基礎元素：ndarray</u></h5>
<p>Numpy最重要的元素就是ndarray，它是N-Dimensional Array的縮寫，在Numpy裡，dimesions被稱為axes，而axes的數量被稱為rank，axes是一個重要的概念，了解這個概念基本上就把Numpy搞懂一半以上了。</p>
<p>先來建立一個簡單1D的ndarray</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</pre></div>


<p>從外到內第一個遇到的中括號就是axis=0，往內就遞增上去，所以從1到2再到3，這個方向就叫做axis=0，Numpy大部分的運算都支援陣列的運算，經常你需要限制要在哪個axis方向上作運算，舉個例子</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>  <span class="c1"># axis為None的時候則加總所有元素</span>
<span class="mi">6</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="mi">6</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># fail 因為A只有一維</span>
<span class="ne">ValueError</span><span class="p">:</span> <span class="s1">&#39;axis&#39;</span> <span class="n">entry</span> <span class="ow">is</span> <span class="n">out</span> <span class="n">of</span> <span class="n">bounds</span>
</pre></div>


<p>另外，也可以由內往外數，最內部的第一個中括後就是axis=-1，越外面就越負。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="mi">6</span>
</pre></div>


<p>剛來上面的例子可能看不出效果，再來就稍微有趣一點，我們來看看2D的ndarray</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>   <span class="c1"># [1+4, 2+5, 3+6]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>    <span class="c1"># [1+2+3, 4+5+6]</span>
</pre></div>


<p>有看懂axis怎麼運作嗎？最外面的中括號是axis=0，它包含[1,2,3]和[4,5,6]兩個元素，方向就是從[1,2,3]到[4,5,6]的方向，在這個方向上做sum，所以結果就會得到[1+4, 2+5, 3+6]。若是axis=1則是第二層中括號，也就是1到3和4到5的方向，所以結果會是[1+2+3, 4+5+6]。</p>
<p>一樣從內而外也可以，如果axis=None或defalut情形下，則是對矩陣內所有元素作運算。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="mi">21</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="c1"># same as above</span>
<span class="mi">21</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 和axis=1等價</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
</pre></div>


<p>相信大家已經有感覺了，那3D也是一樣道理的。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">C</span>
<span class="n">array</span><span class="p">([[[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">]],</span>

       <span class="p">[[</span> <span class="mi">7</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span>    <span class="c1"># [1+7,  2+8,  3+9 ]</span>
       <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">]])</span>   <span class="c1"># [4+10, 5+11, 6+12]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span> <span class="mi">5</span><span class="p">,</span>  <span class="mi">7</span><span class="p">,</span>  <span class="mi">9</span><span class="p">],</span>    <span class="c1"># [1+4, 2+5, 3+6]</span>
       <span class="p">[</span><span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">21</span><span class="p">]])</span>   <span class="c1"># [7+10, 8+11, 9+12]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>        <span class="c1"># [1+2+3, 4+5+6]</span>
       <span class="p">[</span><span class="mi">24</span><span class="p">,</span> <span class="mi">33</span><span class="p">]])</span>       <span class="c1"># [7+8+9, 10+11+12]</span>
</pre></div>


<p>畫張圖可能比較好理解一點，在各個方向上加總的結果都不一樣。</p>
<p><img alt="ndarray axis" src="http://www.ycc.idv.tw/media/PlayDataWithPython/ndarray_axis.png"></p>
<p>同樣，axis的概念也可以用在矩陣的shape</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>


<p><code>(3, 2)</code>這樣的shape我們就一點都不意外了，axis=0有三個元素，而axis=1有兩個元素。shape可以直接改，如果數量恰當的話就會自動重組。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span>
<span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

       <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]])</span>
</pre></div>


<p>axis=0有兩個元素，axis=1有一個元素，axis=2有三個元素。</p>
<p>同樣的概念也可以用在取出單一元素上。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">D</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="mi">3</span>
</pre></div>


<p>在axis=0上選第二個元素(1)，在axis=1上選第一個元素(0)，在axis=2上選第二個元素(1)，所以選出來的元素就是5啦！</p>
<p>有了axis的概念，我們來看另外一個重要的概念—dtype。</p>
<p>ndarray有其資料型別，這個資料型別就稱為dtype，有哪些內建的資料型別呢？我們可以透過numpy的內建資料來查看。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sctypes</span>
<span class="p">{</span><span class="s1">&#39;complex&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">complex128</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">complex256</span><span class="p">],</span>
 <span class="s1">&#39;float&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float128</span><span class="p">],</span>
 <span class="s1">&#39;int&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int16</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">],</span>
 <span class="s1">&#39;others&#39;</span><span class="p">:</span> <span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">object</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">unicode</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">void</span><span class="p">],</span>
 <span class="s1">&#39;uint&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint32</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">uint64</span><span class="p">]}</span>
</pre></div>


<p>有複數、浮點數、整數，另外每個資料型別還可以由資料的儲存容量大小來區分，例如：numpy.int32就代表是容量為32bits的整數。我們可以在設置ndarray的時候事先強迫設成某資料型別。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t1</span>
<span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t1</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t2</span>
<span class="n">array</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t2</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">dtype</span><span class="p">(</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
</pre></div>


<h5><u>Numpy的矩陣運算</u></h5>
<p>有了ndarray就可以作矩陣的運算了，矩陣運算有兩種系統，一種是element-wise(元素方面) operation，一種是matrix operation。</p>
<p>這樣講好像很抽象，我來解釋一下，element-wise operation就是每個元素獨立運算，例如，以下例子就是element-wise的相加。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">+</span><span class="n">B</span>      <span class="c1"># element-wise plus</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
</pre></div>


<p>A和B矩陣中同樣位置的元素相加，再放到新的矩陣中，這一種操作就叫做element-wise operation。</p>
<p>在numpy中如果沒有特別指定，所有的運算都是這類的運算，我們來看一下減、乘和除。</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">-</span><span class="n">B</span>      <span class="c1"># element-wise minus</span>
<span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">*</span><span class="n">B</span>      <span class="c1"># element-wise multiply</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span><span class="o">/</span><span class="n">A</span>      <span class="c1"># element-wise divide</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
</pre></div>


<p>那我如果想要作矩陣操作(matrix operation)呢？譬如說矩陣內積，</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span> <span class="c1"># 矩陣內積</span>
<span class="n">array</span><span class="p">([[</span>  <span class="mf">5.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">15.</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">]])</span>
</pre></div>


<p>還有更多的矩陣操作，</p>
<p>矩陣轉置</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span> <span class="c1"># 矩陣轉置</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
</pre></div>


<p>反矩陣</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A_rev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="c1"># 反矩陣</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">A_rev</span>
<span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">2.</span> <span class="p">,</span>  <span class="mf">1.</span> <span class="p">],</span>
       <span class="p">[</span> <span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">A_rev</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span>  <span class="mf">1.00000000e+00</span><span class="p">,</span>   <span class="mf">0.00000000e+00</span><span class="p">],</span>
       <span class="p">[</span>  <span class="mf">8.88178420e-16</span><span class="p">,</span>   <span class="mf">1.00000000e+00</span><span class="p">]])</span>
</pre></div>


<p>A和A的反矩陣內積為單位矩陣，你有注意到<code>8.88178420e-16</code>這個奇怪的數字嗎？這是因為python在計算的過程有一些誤差的緣故，所以才會產生一個這麼小的數字，但基本上可以看作是0。</p>
<p>另外矩陣跟矩陣間也可以合併。</p>
<p>垂直方向合併</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float64&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">V</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
</pre></div>


<p>水平方向合併</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">H</span>
<span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
</pre></div>


<p>當然也可以分割矩陣，</p>
<p>垂直方向分割</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">vsplit</span><span class="p">(</span><span class="n">V</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 2代表切兩份</span>
<span class="p">[</span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]]),</span> <span class="n">array</span><span class="p">([[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])]</span>
</pre></div>


<p>水平方向分割</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">H</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># 4代表切四份</span>
<span class="p">[</span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.</span><span class="p">]]),</span> <span class="n">array</span><span class="p">([[</span> <span class="mf">2.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.</span><span class="p">]]),</span> <span class="n">array</span><span class="p">([[</span> <span class="mf">5.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">]]),</span> <span class="n">array</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">]])]</span>
</pre></div>


<h5><u>子彈總結</u></h5>
<ul>
<li>Python常見的資料型別：整數(integer)、浮點數(floating-point number)、字串(string)、串列(list)、序對(tuple)、字典(dictionary)</li>
<li>ndarray的axes概念很重要，這會決定函數操作的方式，例如：np.sum</li>
<li>ndarray的資料型別(dtype)，例如：'float64', 'int64', 'string', ...</li>
<li>numpy的矩陣運算有element-wise operation和matrix operation兩種</li>
</ul>
<p>Numpy的基礎概念我們已經有了，在下一篇當中會再更深入的了解Numpy還有什麼進階的功能，包括：產生ndarray的多種方法、broadcast的概念以及ndarray的進階操作手法。</p></dd>
                <dt>2017 / 4月 07</dt>
                <dd><a href="./big-data-a-revolution.html">大數據 Big Data:A Revolution That Will Transform How We Live, Work, and Think</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p><img alt="cover" src="http://www.ycc.idv.tw/media/Reading/BigData_pic.jpg"></p>
<p>最近，Big Data這個詞相當的紅，但是對於這個詞我們還是有很多的誤會，一個常見的疑問是，究竟多大才可以稱得上是大數據呢？事實上，我接下來要介紹的這本書告訴你，大數據多「大」不是重點，重點是你怎麼看待和處理數據。</p>
<p>「<a href="http://www.books.com.tw/products/0010587258">大數據</a>」這本書分為三個部分，在第一個部分，作者為讀者介紹大數據的三大思維變革，包括：採用全體數據取代抽樣數據、容忍資料的混雜特性、「是什麼」比「為什麼」還重要，第二部分則在講述大數據如何改變了商業、市場和社會的本質。第三部分在探討大數據會對人類產生什麼不好的影響，而我們如何去避免。本篇我主要著墨於第一部分和第二部分。</p>
<h5><u>樣本=總體</u></h5>
<blockquote>
<p>大數據是指不採用統計「隨機採樣」這樣的捷徑，而直接處理所有的數據。</p>
</blockquote>
<p>在資料分析中，如果要研究的對象（母群體）非常的龐大、資料量非常大，我們通常會採取「隨機採樣」來處理，這條捷徑在處理特定問題非常成功，也因此它成為現代社會、現代測量領域的主要路數，但這方式存在著一些缺陷。</p>
<p>「隨機採樣」的缺陷之一是無法瞭解更深層次的細節。在宏觀領域起作用的方法在微觀領域失去了作用。隨機採樣就像印象派的畫作一樣，遠看很不錯，可以看見整個整體趨勢，但是一旦聚焦於某一點，就會變得模糊不清。</p>
<p>另外，「隨機採樣」還有一個缺陷是缺乏延展性，人們只能從採樣數據中得出事先設計好的問題的結果——千萬不要奢求採樣的數據還能回答你突然意識到的其他問題，也就是調查得出的數據不能夠重新分析以實現計劃之外的目的。</p>
<p>不過，在目前這個技術和資訊爆炸的時代，我們訊息量的增長速度比世界經濟的增長速度快4倍，而電腦數據處理能力的增長速度則比世界經濟的增長速度快9倍，也因此我們有更充沛的資料和處理資料的能力，所以是時候應該丟棄以往的「隨機採樣」，而直接採用「樣本=總體」的方式。</p>
<p>Xoom是一個專門從事跨境匯款業務的公司。2011年，它注意到用「發現卡」從新紐澤西州匯款的交易量比正常情況多一些，系統於是啟動警報。Xoom公司的CEO John Kunze(約翰·孔澤) 解釋說：「這個系統關注的是不應該出現的情況。」單獨來看，每筆交易都是合法的，但是事實證明這是一個犯罪集團在試圖詐騙。而要能發現異常的唯一方法是，需要檢查所有的數據，找出「隨機採樣」分析法所獲取不到的訊息。</p>
<p>另外一個例子，Lytro相機，它把大數據運用到了基本的攝影中。與傳統相機只可以記錄一束光不同，Lytro相機可以記錄整個光場裡所有的光，可以達到1100萬束之多。具體生成什麼樣的照片則可以在拍攝之後再依照需要決定。用戶沒必要在一開始就聚焦，因為該相機可以捕捉到所有的數據，所以之後可以選擇聚焦圖像中的任一一點。</p>
<p><strong>大數據所謂的「大」，並不是指數據量有多大，而是指如何處理數據的方法，直接處理「樣本=總體」，而非傳統的「隨機採樣」，我們將得到更多的細節，做更多的事。</strong></p>
<h5><u>允許不精確</u></h5>
<p>對於採取隨機取樣的小數據而言，保證每筆資料的質量是相當重要的，為了使結果更加準確，很多科學家都致力於優化測量工具。不過，面對大數據的時候，我們可能增加不少不正確的資料，正因為我們無法逐一的檢查，甚至在資料的格式上也難以統一，因此大數據本身就具有混雜的特性。</p>
<p>不過這混雜所造成的不準確也可以因為數據量大而彌補，事實上，<strong>大數據的簡單演算法比小數據的複雜演算法更為有效</strong>，舉個例子，在冷戰時期，美國掌握了大量關於蘇聯的各種資料，但缺少翻譯這些資料的人手。所以，計算機翻譯也成了急需解決的問題。那個時候的科學家想藉由結合文法規則和字典來創造一個翻譯機器， 最後卻失敗了，他們發現機器翻譯不能只是讓電腦熟悉常用規則，還必須教會電腦處理「特殊的」語言情況。畢竟，翻譯不僅僅只是記憶和複述，也涉及選詞，而明確地教會電腦這些是非常困難的。</p>
<p>時間拉回到現代，Google翻譯則採取另外一種方式，Google翻譯系統不由程式設計師直接告訴計算機要怎麼做，而是靠著資料來訓練計算機學習怎麼做，計算機會盡量吸收它能找到的所有翻譯文本，從各式各樣語言的公司網站上尋找對譯的文檔，還會去尋找聯合國和歐盟這些國際組織發佈的官方文件和報告的譯本，藉由這大量的數據去預測對譯詞語應該是什麼，<strong>然而儘管其輸入來源很混亂，但相較於其他翻譯系統而言，Google的翻譯質量相對而言還是最好的</strong>。</p>
<p><strong>要想獲得大規模數據帶來的好處，混亂應該是一種標準途徑，而不應該去竭力避免，不過數據量一旦大，這些混亂所帶來的不精確將被彌補。</strong></p>
<h5><u>「是什麼」比「為什麼」還重要</u></h5>
<p>大數據利用數值方法，他可以看到人類不容易看出來的相關性，兩件事雖然擁有相關性，但並不代表他們擁有因果關係，但是在大部分時間裡，相關性比因果關係更為重要。</p>
<p>美國折扣零售商塔吉特（Target）使用大數據的相關性分析已經有很多年了。《紐約時報》的記者杜西格（Charles Duhigg）就在一份報道中闡述了塔吉特公司怎樣在完全不和准媽媽對話的前提下預測一個女性會在什麼時候懷孕。塔吉特公司注意到，資料上的婦女會在懷孕大概第三個月的時候買很多無香乳液。幾個月之後，她們會買一些營養品，比如鎂、鈣、鋅。公司最終找出了大概20多種關聯項目，這些關聯項目可以給顧客進行「懷孕趨勢」評分。杜西格在《習慣的力量》（The Power of Habit）一書中講到了接下來發生的事情。一天，一個男人衝進了一家位於明尼阿波利斯市郊的塔吉特商店，要求經理出來見他。他氣憤地說：「我女兒還是高中生，你們卻給她郵寄嬰兒服和嬰兒床的優惠券，你們是在鼓勵她懷孕嗎？」而當幾天後，經理打電話向這個男人致歉時，這個男人的語氣變得平和起來。他說：「我跟我的女兒談過了，她的預產期是8月份，是我完全沒有意識到這個事情的發生，應該說抱歉的人是我。」 </p>
<p>在上述的例子，我們雖然不見得可以找出這20項關聯項和懷孕之間的因果關係，不過他們確實相關，所以我們可以用來預測。<strong>有些時候我們只需要知道「是什麼」就夠了，沒必要知道「為什麼」。</strong></p>
<h5><u>大數據時代的商業變革</u></h5>
<p>Matthew Fontaine Maury是一位前途看好的美國海軍軍官，1839年，卻意外的出了車禍，使得他無法繼續在海上工作，不過危機就是轉機，在近三年的休養，美國海軍將他安排進辦公室，讓他負責修復陳舊的圖表和儀器，他在其中挖到了寶，那是一批航海日記，日記裡頭詳細的記載了特定時間在特定地點的風、水和天氣狀況，Maury意識到如果把這些資料整理起來，將會呈現一張全新的航海圖，這些數據將會比大家口耳相傳的經驗還有用，後來也證明Maury是對的，這資料幫助船長們省去了三分之一左右的航程，後來全世界第一條跨越大西洋的電報電纜也是建基在這個基礎之上。</p>
<p>數據就像是一座鑽石礦，透過分析我們可以將其中的鑽石給掏出，事實上這金礦無所不在，數據可能藏於書籍或網路文本、數據可能藏於方位、數據可能藏於溝通網絡、數據可能藏於微型運動感測器，仔細留意，數據幾乎無所不在，什麼都可以量化，有了大數據的思維，我們不會再把世界看成只有單純是自然現象或是社會現象，我們會意識到世界的本質就是由眾多信息所構成的，而這會帶來的是一場商業上的變革。</p>
<p>作者認為大數據時代，依照提供價值不同，分別會出現三類的大數據公司，第一種是擁有大量數據的公司，第二種是擁有技能挖掘數據的公司，最後一種是提供嶄新大數據思維的公司，能從數據中創造出意想不到的價值，第三種是作者最為推崇的，作者列了幾種數據創新的方法。</p>
<p>作者提了五種數據創新方法，第一種是<strong>數據再利用</strong>，有許多數據因為儲存成本低而被保存下來，不過沒有被充分的利用，數據科學家稱之為「數據墳場」，從這墳場中我們可以盜到很多的寶，就像Maury從航海日記撈出了許多有用的資訊一樣。</p>
<p>第二種是<strong>數據間的整合</strong>，丹麥同時擁有從1985年起的手機用戶數據庫和該國所有癌症患者的資訊，有人想到如果整合這兩者資訊，研究人員可以研究手機用戶是不是比非手機用戶顯示出更容易得癌症，最後，研究結果沒有發現這兩者存在著相關性。</p>
<blockquote>
<p>隨著大數據的出現，數據的總和比部分更有價值。當我們將多個數據集的總和重組在一起時，重組總和本身的價值也比單個總和更大</p>
</blockquote>
<p>第三種是<strong>具可擴張性的數據</strong>，要使得數據可以一再的利用，我們必須在一開始就設計好他的可擴張性，也就是要盡可能的一次蒐集所有資料齊全，舉個知名的例子，Google街景拍攝，其備受爭議的街景汽車不僅僅拍攝房屋和道路的照片，他還同時採集了每個位置的GPS數據，甚至還加入了無線網路名稱的蒐集，一輛Google街景車每時每刻都在累積大量的各方面的數據，而這些資訊可能在目前用不到，不過未來的某天可能會用到，花一次的錢可以得到更多的好處。</p>
<p>第四種是<strong>必須考慮數據的折舊</strong>，譬如你在亞馬遜十年前買一本書的資訊，一定不會比昨天剛購買的資訊重要，所以資料還必須考慮它隨時間下降的重要程度。</p>
<p>第五種是<strong>數據廢氣能回收再利用</strong>，什麼是數據廢氣呢？</p>
<blockquote>
<p>一個用來描述人們在網上留下的數字軌跡的藝術詞彙出現了，這就是「數據廢氣」。它是用戶在線交互的副產品，包括瀏覽了哪些頁面、停留了多久、滑鼠光標停留的位置、輸入了什麼信息等。許多公司因此對系統進行了設計，使自己能夠得到數據廢氣並循環利用，以改善現有的服務或開發新服務。 </p>
</blockquote>
<p>Google就是這方面的高手，例如錯誤拼寫校正，Google擁有世界上最完整的拼寫檢查器，基本上涵蓋了各種語言，而且Google幾乎免費的獲得這種能力，它依據每天處理的30億個錯誤拼寫的查詢，一個巧妙的反饋系統可以讓用戶告訴Google他其實是想輸入什麼字，當搜尋頁面頂部顯示「你要找的是不是：流行病學」時，如果是的話，你將會點選並讓Google了解你真正想查的字詞，原本輸入錯誤這樣的數據廢氣卻被巧妙的回收再利用來優化它的系統。</p>
<h5><u>全息社會</u></h5>
<p>大數據正在慢慢影響這個社會，包括我們的知識取得方式，包括我們的社交活動，甚至在未來會決定人類很多的決策，大至公司策略發展，小至個人理財規劃，確實，大數據和機器學習的引入可能會取代掉許多目前的工作，不過也同時會創造更多新的工作內容，讓人類可以盡情發揮潛能，把更多的精力放在創造之上，如果亨利·福特問大數據他的顧客想要的是什麼，大數據將會回答，「一匹更快的馬。」在全息社會中，包括創意、直覺、冒險精神和知識野心在內的人類特性的培養顯得尤為重要，人類的進步正是源自我們的獨創性。</p></dd>
                <dt>2017 / 4月 02</dt>
                <dd><a href="./ml-course-techniques_5.html">機器學習技法 學習筆記 (5)：Boost Aggregation Models</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><blockquote>
<p>本篇內容涵蓋AdaBoost (Adaptive Boost)、Gradient Boost、AdaBoosted Decision Tree和Gradient Boosted Decision Tree (GBDT)。</p>
</blockquote>
<h5><u>Boost的精髓</u></h5>
<p>在上一回當中，我們介紹的Aggregation Models都屬於沒有Boost的，不管是Bagging或Decision Tree都沒有要試著在Training的過程中改善Model，<strong>而這篇將要提到的Boost方法，則是在產生每個g<sub>t</sub>時試圖讓Model整體更完善，更能發揮Aggregation Models中截長補短中的「補短」的效果，也就是說g<sub>t</sub>可以彼此互補不足之處</strong>。</p>
<p>那實際上我們應該怎麼做才能實踐Boost呢？其實方法的道理早就透漏在上一回中的Bagging和Decision Tree裡頭了，不管是Bagging和Decision Tree都是使用變換Data來做到變異度，在這個方法下Model的架構可以本身是不變的，這帶來相當的便利性，而今天我們要講的Boost也同樣的利用「變換Data」來做到變異度，但不同的是Boost的過程中「變換Data」這件事是有目標性的。</p>
<p><strong>Boost方法在「變換Data」時會試著去凸顯原先做錯的Data，而降低原本已經做對的Data，藉由這樣的方法訓練出來的g<sub>t</sub>可以補齊前面的不足，所以Boost的過程將會使得Model漸漸的完善，這就是Boost的主要精髓。</strong></p>
<p><br/></p>
<h5><u>AdaBoost (Adaptive Boost) for Classification</u></h5>
<p>剛剛上一段的最後我已經揭露了Boost的真正精髓，拿這樣的概念來做分類問題，就是我們接下來要談的AdaBoost，全名稱為Adaptive Boost。</p>
<p>在分類問題中我們怎麼做到「凸顯原先做錯的Data」？簡單的想法是這樣的，我們可以減少原本已經是正確分類的Data的數量，然後增加原本錯誤分類的Data的數量，<strong>增減Data的數量其實是等效於改變每筆Data的權重</strong>，假如我們給每筆資料權重，要做的事是拉低正確分類Data的權重，而且拉高錯誤分類Data的權重。</p>
<p>那我們應該要提升權重或降低權重到什麼程度才是OK的呢？換個方式思考，我們為什麼要去調整權重？目的其實是要去凸顯原先做錯的部分，降低原本做對的部分，也就是想<strong>藉由調整每筆Data的多寡或權重來做到「弭平原先的預測性」，最好可以讓原本的預測方法看起來是隨機分布</strong>，也就是「錯誤率＝正確率」，讓它像是擲銅板一樣，沒有什麼預測能力。</p>
<p><img alt="AdaBoost" src="https://dl.dropbox.com/s/n61vejw6rs6f9nm/MachineLearningTechniques.012.jpeg"></p>
<p>有了概念之後，我們來看實際應該要怎麼做？見上圖說明，首先我們需要先將Data權重u<sup>(1)</sup>先初始化，接下來就可以開始找g<sub>t</sub>了，我們使用任意一個分類問題的Model搭配上Data的權重，求得一組g<sub>t</sub>，接下來計算這組g<sub>t</sub>的<strong>「錯誤率」ε<sub>t</sub></strong>，</p>
<p><strong>ε<sub>t</sub>= 𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup> ⟦y<sub>n</sub>≠g<sub>t</sub>(x<sub>n</sub>)⟧ / 𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup></strong></p>
<p>有注意到考慮「錯誤率」ε<sub>t</sub>的時候必須要評估u<sub>n</sub><sup>(t)</sup>，要記得會有Data權重是為了表示增加或減少原本的Data的數量，所以依照每筆Data的出現機會不同，會有不同的權重，也就會有對「錯誤率」不同的貢獻程度。</p>
<p>那為了待會要對權重重新分配，我們先定義了β<sub>t</sub>，在未來我會將錯誤的Data的權重乘上β<sub>t</sub>，即u<sub>n</sub><sup>(t+1)</sup>=u<sub>n</sub><sup>(t)</sup>×β<sub>t</sub>，並且把正確的Data權重除以β<sub>t</sub>，即u<sub>n</sub><sup>(t+1)</sup>=u<sub>n</sub><sup>(t)</sup>/β<sub>t</sub>，<strong>而期望的結果是重新分配的Dataset在g<sub>t</sub>的預測下可以表現的像隨機的一樣，於是乎下一次使用這組Dataset訓練出來的g<sub>t+1</sub>將會彌補g<sub>t</sub>的不足</strong>，根據這樣的原則我們來推一下β<sub>t</sub>，</p>
<p>𝚺<sub>n</sub> u<sub>n</sub><sup>(t+1)</sup> ⟦y<sub>n</sub>≠g<sub>t</sub>(x<sub>n</sub>)⟧ / 𝚺<sub>n</sub> u<sub>n</sub><sup>(t+1)</sup>=1/2 (預測能力像隨機分布)</p>
<p>⇒  𝚺<sub>n</sub> u<sub>n</sub><sup>(t+1)</sup> ⟦y<sub>n</sub>≠g<sub>t</sub>(x<sub>n</sub>)⟧ = 𝚺<sub>n</sub> u<sub>n</sub><sup>(t+1)</sup> ⟦y<sub>n</sub>=g<sub>t</sub>(x<sub>n</sub>)⟧ </p>
<p>⇒  𝚺<sub>n</sub> (u<sub>n</sub><sup>(t)</sup>×β<sub>t</sub>)  ⟦y<sub>n</sub>≠g<sub>t</sub>(x<sub>n</sub>)⟧ = 𝚺<sub>n</sub> (u<sub>n</sub><sup>(t)</sup>/β<sub>t</sub>) ⟦y<sub>n</sub>=g<sub>t</sub>(x<sub>n</sub>)⟧ </p>
<p>⇒  β<sub>t</sub><sup>2</sup> = 𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup> ⟦y<sub>n</sub>=g<sub>t</sub>(x<sub>n</sub>)⟧ / 𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup>  ⟦y<sub>n</sub>≠g<sub>t</sub>(x<sub>n</sub>)⟧</p>
<p>⇒  β<sub>t</sub><sup>2</sup> = [𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup> ⟦y<sub>n</sub>=g<sub>t</sub>(x<sub>n</sub>)⟧ /  𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup>]/ [𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup>  ⟦y<sub>n</sub>≠g<sub>t</sub>(x<sub>n</sub>)⟧ / 𝚺<sub>n</sub> u<sub>n</sub><sup>(t)</sup> ]</p>
<p>⇒  <strong>β<sub>t</sub><sup>2</sup> = 1-ε<sub>t</sub> / ε<sub>t</sub></strong></p>
<p>所以我們就可以利用這個β<sub>t</sub>來更新我的Data權重，並且在多次迭代後，得到很多個g<sub>t</sub>。而將來我們會把所有的g<sub>t</sub>做線性組合，而我們希望<strong>「錯誤率」越低的g<sub>t</sub>可以有更高的貢獻度α<sub>t</sub></strong>，所以使用β<sub>t</sub>緊接著計算「g<sub>t</sub>的權重」α<sub>t</sub>，定義為</p>
<p><strong>α<sub>t</sub> = ln(βt)</strong></p>
<p>所以當一個百分之一百可以完全預測的g<sub>t</sub>出現時，它的ε<sub>t</sub>=0，此時它的β<sub>t</sub> →∞，同時α<sub>t</sub> →∞，所以這樣的g<sub>t</sub>會有完全的貢獻。</p>
<p>如果一個預測效果很差的g<sub>t</sub>出現，它的ε<sub>t</sub>=1/2，此時它的β<sub>t</sub>=1，同時α<sub>t</sub>=0，所以這樣的g<sub>t</sub>並沒有任何參考價值。</p>
<p>那如果出現一個g<sub>t</sub>它的ε<sub>t</sub> &gt; 1/2，那這樣的g<sub>t</sub>並不能說它沒有用處，反而是一個很好的反指標，我們只需要反著看就好了，當ε<sub>t</sub> &gt; 1/2時，β<sub>t</sub> &lt; 1，所以α<sub>t</sub> &lt; 0，這樣的g<sub>t</sub>具有逆向的貢獻。</p>
<p>最後只要把這些訓練好的g<sub>t</sub>乘上各自的α<sub>t</sub>再加總起來，我們就完成了AdaBoost啦！</p>
<p><br/></p>
<h5><u>Gradient Boost for Regression</u></h5>
<p>剛剛我們講了AdaBoost，是個很神奇的方法，當我們做錯了，沒關係！從哪裡跌倒就從哪裡站起來，利用這種精神我們就可以做到Boost的效果，但美中不足的是上面的方法只能用在「分類問題」上，那如果我也想在「Regression問題」也做到Boost呢？這就是接下來要講的GradientBoost的方法。</p>
<p>在課程中林軒田教授是從AdaBoost出發經過推導後，得到一個很像是Gradient Decent的式子，接下來將式子一般化成為可以使用任意Error Measure的形式，我稍微列一下：</p>
<blockquote>
<p>GradientBoost: min<sub>η</sub> min<sub>h</sub> (1/N) 𝚺<sub>n</sub> err[𝚺<sub>τ=1~t-1</sub> α<sub>τ</sub> g<sub>τ</sub>(x<sub>n</sub>) + η h(x<sub>n</sub>), y<sub>n</sub>]</p>
</blockquote>
<p>我們這邊會考慮err為平方誤差(s-y)<sup>2</sup>的結果，詳細的推導這邊就不多加討論，可以到影片中學習，這裡我想要從我觀察出來的觀點，概念性的來看這個GradientBoost的方法。</p>
<p>「從哪裡跌倒就從哪裡站起來」就是Boost的精神，所以今天你有一個Regression問題沒做好，<strong>留下了餘數Residual，怎麼辦？那我就把這個餘數當作另外一個Regression問題來做它</strong>，再把這個結果附到先前的那個就好啦！如果第一次Regression後的Model是g<sub>1</sub>(x)，那剩下的沒做好的餘數就應該是y(x)-g<sub>1</sub>(x)，我們拿這個餘數下去在做一次Regression得到另外一個Model g<sub>2</sub>(x)，此時合併這兩個結果的餘數就變成了y(x)-g<sub>1</sub>(x)-g<sub>2</sub>(x)，就可以使用這個餘數繼續做下去，最後組合所有的g<sub>t</sub>(x)就會得到一個更好的Model。</p>
<p><img alt="Gradient Boost" src="https://dl.dropbox.com/s/dy5xu7ifew5dfn4/MachineLearningTechniques.013.jpeg"></p>
<p>依循這樣的概念我們來看GradientBoost作法，如上圖，一開始我們先初始化每一筆Data的預測值s<sub>n</sub>為0，再接下來開始產生g<sub>t</sub>，我們先把Data的 y<sub>n</sub> 減去每一筆Data當前的預測值s<sub>n</sub>，就會產生餘數(y<sub>n</sub>-s<sub>n</sub>)，當然，在一開始s<sub>n</sub>=0，所以y<sub>n</sub>-s<sub>n</sub>=y<sub>n</sub>，等於是對原問題求解。</p>
<p>接下來因為最後我們要線性組合g<sub>t</sub>(x)，所以需要決定g<sub>t</sub>(x)前面的係數α<sub>t</sub>，也就是貢獻度，這個α<sub>t</sub>的決定方式是去求解一個One-Variable-Linear-Regression (單變數線性迴歸)，目的是<strong>去縮放g<sub>t</sub>(x)使得它更接近剛剛的餘數(y<sub>n</sub>-s<sub>n</sub>)，而找到這個縮放值就是α<sub>t</sub></strong>。所以每一次g<sub>t</sub>(x)的產生都是為了可以把G(x)描述的更好，最後G(x)=𝚺<sub>t</sub> α<sub>t</sub>g<sub>t</sub>(x)。</p>
<p>看到這裡有人一定會認為One-Variable-Linear-Regression求α<sub>t</sub>這一步是多餘的，因為在一開始做{x<sub>n</sub>,y<sub>n</sub>-s<sub>n</sub>}的Regression中我們已經最佳化過g<sub>t</sub>(x)，那為什麼還要把g<sub>t</sub>(x)乘上α<sub>t</sub>再做同樣的事呢？α<sub>t</sub>一定是1的啊！就像我一開始舉的例子一樣啊！其實問題就出在於你把g<sub>t</sub>(x)理所當然的看成是線性模型，你才會覺得這一步是多餘的，如果g<sub>t</sub>(x)不是線性的，求α<sub>t</sub>就很重要的，因為你要使用線性組合來組出G(x)，但是你的g<sub>t</sub>(x)不是線性的，所以你只好在外面再用線性模型來包裝一遍。</p>
<p><br/></p>
<h5><u>AdaBoosted Decision Tree和Gradient Boosted Decision Tree (GBDT)</u></h5>
<p><img alt="AdaBoosted and GrandientBoosted DTree" src="https://dl.dropbox.com/s/zm43nardbpkyr4n/MachineLearningTechniques.014.jpeg"></p>
<p>和Random Forest一樣，我們也可以將AdaBoost和GradientBoost套用到Decision Tree上面，<strong>如果是處理分類問題就使用AdaBoosted Decision Tree；那如果是處理Regression問題可以使用Gradient Boosted Decision Tree</strong>。</p>
<p>但要特別注意的是，這邊的Decision Tree都必須是弱的，也就是Pruning過後的樹，如果直接使用完全長成的樹，你會發現在AdaBoosted Decision Tree中，因為ε<sub>t</sub>=0所以α<sub>t</sub>→∞；在Gradient Boosted Decision Tree中，y<sub>n</sub>-s<sub>n</sub>→0，因為錯誤出現的太少了，所以造成我們不能真正使用到Boost的效果，也就失去做Boost的意義了，<strong>因此在做AdaBoosted Decision Tree或Gradient Boosted Decision Tree時要使用「弱」一點的Decision Tree</strong>。</p>
<p><br/></p>
<h5><u>結語</u></h5>
<p>這一篇當中，我們完整提了Boost的方法，Boost的精神就是從哪裡跌倒就從哪裡站起來，使用變換Data權重的手法去凸顯原先做錯的Data，而降低原本已經做對的Data，藉由這樣的方法訓練出來的g<sub>t</sub>可以補齊前面的不足，所以Boost的過程將會使得Model漸漸的完善。</p>
<p>我們提了兩種Boost的方法，如果是處理分類問題就使用AdaBoost；如果是處理Regression問題可以使用GradientBoost，而且這兩種方法都可以和Decision Tree做結合。</p>
<p>以上兩回，我們已經完成了Aggregation Models了，接下來的下一回將要探討的就是現今很流行的類神經網路和深度學習等等。</p></dd>
                <dt>2017 / 3月 30</dt>
                <dd><a href="./algorithm-complexity-theory.html">輕鬆談演算法的複雜度分界：什麼是P, NP, NP-Complete, NP-Hard問題</a></dd>
                <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><p>在寫程式的時候，會聽到有人說這些問題是NP-Complete問題，或說這些是P問題，那這到底是什麼東西？其實這就是一套定義演算法複雜度的方法，今天我就想帶大家來聊聊這個艱澀但有趣的話題。</p>
<h5><u>Turing Machine</u></h5>
<p>我們先從 <a href="https://en.wikipedia.org/wiki/Turing_machine">Turing machine</a>（圖靈機）開始講起，Turing machine是現代電腦的基本雛型，是英國數學家圖靈（Alan Turing）於1936年提出的一種抽象計算模型，這個計算模型在猜想上可以「計算所有在演算法中可計算的問題」，也就是可以解決人類所有可解的問題，這個猜想稱之為 <a href="https://en.wikipedia.org/wiki/Church–Turing_thesis">Church–Turing thesis</a>（thesis代表假設或猜想），僅管目前還無法證明這個猜想，但是目前為止它幾乎完全被接受。</p>
<p>簡單的談一下 Turing machine的基本架構，首先我們需要一個磁帶，這一條磁帶上面可以一格一格的填入一些 symbols，這可以是單純的 0/1 symbols 或者更多種類的 symbols，但這些 symbols 的數量必須是有限的，而這個symbols就可以當作我的輸入，接下來我需要一個讀寫頭，這個讀寫頭會在磁帶上讀取或寫入 symbol，或左右移動，另外這個讀寫頭存有一個 state，這個 state 會隨著狀況改變，然後我就利用 symbol 和 state 來建立一個規則表，舉個例子，譬如說：初始的 state 是 q0，如果讀寫頭在 q0 的情況下讀到 symbol 0，就寫入 symbol 1，並且向右移動3格，並且改變 state q0 為 q1，... 等等，藉由規則來完成我們想做的運算，最後最重要的是它必須有一個 halt state 讓機器知道已經計算完畢了。Turing machine 不僅僅在理論上可以做任何的計算，而更有價值的是 Turing machine 的架構是有辦法用物理的方式來製造的，所以才會有現代電腦這玩意兒。</p>
<p>說到電腦，更嚴謹地說，我們當今的電腦架構是比較接近 <a href="https://en.wikipedia.org/wiki/Turing_machine">deterministic Turing machine</a> (DTM)，和它對比的是 <a href="https://en.wikipedia.org/wiki/Non-deterministic_Turing_machine">non-deterministic Turing machine</a> (NTM)，我來好好的解釋一下，deterministic 的中文稱為決定性，所以 non-deterministic 就是非決定性，如果給予 Turing machine 某個 state 和某個 symbol 下它的下一步如果只有一種可能，那我們就稱它為 deterministic Turing machine (DTM)，所以上述的讀取頭每次就依照當下特定的 symbol 和 state 然後「決定」下一步應該要怎麼動作。</p>
<p>但是 non-deterministic Turing machine (NTM) 就不拘於此，針對某個 state 和某個 symbol 它的下一步可能會有很多種，它會是一個分支，它可能同時要向右移3格，又同時要向左移動2格，所以你可以想像一下你的讀寫頭一分為二，然後再各自進行自己的任務，這個分支可以有無限多個，只要最後有某個分支到達 halt state，我們就解完問題了，這就是 non-deterministic Turing machine (NTM)。</p>
<p>顯而易見的，DTM 只是 NTM 的特例，所以 NTM 比 DTM 擁有更快的計算速度，但這裡不要誤會喔！不管是 DTM 和 NTM 能解的問題是一樣多的，而且在數學上可以將 NTM 轉換成 DTM，只是它們解決相同問題所用到的時間複雜度不一樣，不過這就很關鍵。</p>
<h5><u>時間複雜度</u></h5>
<p>接下來，我要開始切入正題，我們來聊聊時間複雜度吧！什麼是時間複雜度呢？時間複雜度用來評估演算法需要花多少時間做計算，我們常用<a href="https://zh.wikipedia.org/wiki/大O符号">大O符號</a>來描述，代表的是一個漸進的函數數量級上界，舉個例子，假設我想要在一個有序的數列2,3,5,7,13,27中找到7的位置，最簡單的做法就是從第一個元素開始檢查起，如果不是元素7就再找下一個，直到找到為止，所以最差的情形就是我一路找直到了最後一個元素，如果數列有Ｎ個元素，我們最差的情形就是做了Ｎ次的比較，而每次做比較所花的時間是一個常數時間，因此這個演算法的上界將被 a×N 所界定，a為常數，所以這個演算法的時間複雜度為O(N)，再舉個稍微難一點的例子：<a href="https://en.wikipedia.org/wiki/Subset_sum_problem">子集合加總問題</a>，假設給予一組集合{−7, −3, −2, 5, 8}，然後問是否有一組子集合相加為0，怎麼做呢？最簡單的做法就是，窮舉出所有可能的子集合然後相加驗證是否剛好為0，假設集合中有Ｎ個元素，我會有2^N種的子集合，而且要加總最多Ｎ個元素，所以這個過程的時間複雜度為 O(N×(2^N))。特別提醒，以上的分析方式大致上是符合DTM和現代電腦的運作方式，一步接著一步做（step-by-step），NTM就不這麼分析問題，當然兩者看待同一個問題的時間複雜度就會不一樣。</p>
<p>剛剛有提到 Turing machine 可以解所有演算法問題，那如果我製造一台機器符合 Turing machine或者是我購買一台電腦，是不是就可以躺著解所有的問題了，很可惜的，並不是的！我們剛剛有簡單的帶大家了解時間複雜度，我們知道每種演算法有其計算時間，子集合加總問題的時間複雜度為O(N×(2^N))，如果今天很單純的，我的元素只有1000個，這個數量不過分吧！但大家試著計算一下1000 ×(2^1000)就會發現這是一個天文數字，它大到縱使每個相加只需要0.00001秒，也需要遠遠超過地球年齡的時間才有辦法算完，因此這類問題就算是可解的，也並不實際，所以只有在一個數量級時間以下的問題我們才好應付，這個數量級被稱為 polynomial time（多項式時間），用大Ｏ表示為Ｏ(N^k)，剛剛上面提到的數列找元素問題，它得時間複雜度為O(N)，為 <a href="https://zh.wikipedia.org/wiki/多項式時間">polynomial time</a>，這是屬於好對付的問題，如果超過 polynomial time 的問題我們稱為 <a href="https://en.wikipedia.org/wiki/Intractability_(complexity)">intractable</a> problem (難解的問題)。</p>
<h5><u>P＝NP？</u></h5>
<p>如果有一群演算法用DTM來做計算所需時間是 polynomial time，那這類演算法或問題被稱為Ｐ問題，Ｐ就是 polynomial-time 的縮寫，另外如果有一群演算法用NTM來做計算所需時間是 polynomial time，那這類問題被稱為NP問題，NP是 non-deterministic polynomial-time 的縮寫，NP問題還有另一個數學上等價的判斷方法，從驗證解的難度來界定，如果用DTM來驗證一組解是否正確只需要 polynomial time，那這個問題就是一個NP問題，剛剛子集合加總問題，我們要驗證解是否正確很簡單也很快速，我們只要把解的數字加總起來看是不是為0就可以了，所以子集合加總問題是一個NP問題，但因為這個問題的時間複雜度為 O(N×(2^N))，所以它不是一個Ｐ問題，當然也許有一天可以找到一種演算法來解這個問題，並且只需要 polynomial time，那這個問題就是既是NP問題也是P問題，那麼這種演算法找得到嗎？這就牽扯出一樁數學懸案。</p>
<p>在討論這個問題之前，我先補充一件事，剛剛我提到NP問題有兩種定義是等價的，一種是NTM可在 polynomial time 內解決的問題，另一種是問題的解有辦法在DTM polynomial time下被驗證，這兩種定義如何連結起來呢？我來粗略地說明一下，因為NTM有無窮多個分支讓我利用，那我就讓每個分支去窮舉每種可能的解，然後再驗證每個分支的解是否正確，而驗證的過程只需要 polynomial time，所以自然在NTM下我只需要 polynomial time 就可以將這個問題給解完，也因此它們是等價的。那也許大家還有一個疑問，有什麼問題是無法在 polynomial time 內驗證解的？我們稍稍的改一下子集合加總問題，改問「這集合之中最多有多少種子集合符合加總為0 ?」這時候如果我告訴你解是3個，你要怎麼驗證這個答案是對的，你會發現你幾乎還是需要再重新解同樣的問題才有辦法驗證，這種問題被稱為Co-NP問題（<a href="https://zh.wikipedia.org/wiki/反NP">反NP問題</a>）。</p>
<p>毋庸置疑的，NP問題必定包含P問題，在DTM之下為 polynomial time 可解決的，在NTM之下也必定是 polynomial time 可解決的，但是P問題會等價於NP問題嗎？（<a href="https://en.wikipedia.org/wiki/P_versus_NP_problem">P=NP?</a>）這個問題到目前為止還是數學界無法證明的問題，目前既不能證明P=NP也不能證明P≠NP，克雷數學研究所曾在2000年公布千禧年大獎七大難題，每解破一題的解答者，會頒發獎金100萬美元，裡面的其中一題就是P=NP?問題，那為什麼這個問題很重要呢？ 舉個例子，有一種我們現今常用的加密方法叫做RSA加密，它的概念非常的簡單，我們知道由兩個質數相乘的合數，只有用這兩個質數的其中一個才有辦法整除它，今天我拿一個由兩個大質數相乘的合數當作鑰匙孔，所以手上有鑰匙（其中一個質數）的人就可以開啟這個鎖（整除它），如果你想要暴力破解這個鎖是很困難的，你需要超過 polynomial time 的時間，但是你要驗證解是否正確是很容易的，根據上面的定義<a href="https://zh.wikipedia.org/wiki/RSA加密演算法">RSA加密</a>是一個NP問題，如果今天有人找到方式可以把NP問題當作P問題處理，也就是說他可以輕易地用現代的電腦去解開RSA加密，還有破解其他的加密方法，目前的加密方法幾乎都是NP問題，這一定會造成世界不少的動盪，不過也不僅僅只有壞處啦，只要確立了NP=P，我們可以拿來解很多我們現今無法解的難題，含括各領域：人工智慧、物理、醫學 ...，人類知識科技將大步的躍進。</p>
<h5><u>NP-Complete 問題</u></h5>
<p>當數學家試圖解決 NP=P? 問題時，導出了一個重要的概念— NP-Complete問題。1971年美國 Stephen A. Cook提出了<a href="https://zh.wikipedia.org/wiki/Cook-Levin理論">Cook-Levin理論</a>，這個數學理論指出任何一個NP裡面的問題都可以在 polynomial time 內，使用DTM，將之化約成「一個布林方程式是否存在解」的問題，這個被化約的問題又稱為布爾可滿足性問題（SAT），我們稱SAT問題為NP-Complete問題。</p>
<p>只要滿足以下兩個條件的，我們都稱之為<a href="https://en.wikipedia.org/wiki/NP-completeness">NP-Complete</a>：1. 它本身是一個NP問題  2. 所有的NP問題都可以用DTM在 polynomial time 內化約成為它。</p>
<p>這個概念非常強大，假設我證明了SAT是P問題，就等於今天我隨便拿到一個NP問題就可以在 polynomial time 內把問題轉換成SAT，然後再用 polynomial time 把SAT解掉，所以所有的NP問題都只是P問題了，也就是P=NP，因此NP-Complete問題就是解決 P=NP 的關鍵，如果可以證明NP-Complete問題為P問題，就可以間接證明P=NP。</p>
<p>NP-Complete 問題不只有SAT一種，在Cook提出Cook-Levin理論的隔一年，1972年，Richard Karp將這個想法往前推進了一步，他證明了<a href="https://zh.wikipedia.org/wiki/卡普的二十一個NP-完全問題">21個不同但都難解的組合數學與圖論問題為NP-Complete問題</a>，一樣的其中的任何一種只要被證明為P問題，都可以間接證明P=NP，目前已經有更多問題被證明為NP-Complete 問題。</p>
<p>大家可能還會看到一個名詞叫做<a href="https://en.wikipedia.org/wiki/NP-hardness">NP-Hard</a>，它的定義很好了解，只需要符合NP-Complete的第二個條件：所有的NP問題都可以用DTM在 polynomial time 內化約成為它，就被稱為NP-Hard 問題。所以NP-Complete問題是NP-Hard 問題的一種特例，NP-Hard 問題可以不必是NP問題，譬如停機問題就是一個NP-Hard 問題但不是一個NP問題。</p>
<h5><u>後話</u></h5>
<p>最後，以下面這張圖作個結尾，左圖是假設P≠NP被證明的情形，NP-Hard有兩個部分，一個部分它同時是個NP問題，另外一部分則不是，所謂的NP問題就是可以用NTM在 polynomial time內給解掉的問題，另外其解的驗證必定能用DTM在 polynomial time內完成，兩種定義是等價的，有一部分的NP問題是屬於P問題，這些問題大部分都是易解的，有另外一部分的NP問題為NP-Complete問題，這些問題被視為難解的問題，我們只能用逼進的方法盡量接近答案。</p>
<p>右圖是假設P＝NP被證明的情形，此時NP-Complete問題已經被證明為P問題，利用NP-Complete問題的特性，我們可以化約所有NP問題為NP-Complete問題，在把這個NP-Complete問題用 polynomial time 解掉，所以P=NP=NP-Complete。</p>
<p>事實上，目前科學界普遍相信P≠NP，所以遇到NP-Complete的問題，就直接標註這是一道難題，使用近似解吧！這是一個不怎麼樂觀的看法，難道說我們真的無法把這樣的難題給解決掉了嗎？也未必啦！仔細想想我們也許還有另外一個方法，只要我們創建一個NTM就可以把這些難題給解決掉啦！<a href="https://en.m.wikipedia.org/wiki/BQP">不過連量子電腦都普遍不被認為是一個NTM</a>（最後又回補了一槍）。</p>
<p><img alt="P_np_np-complete_np-hard" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/P_np_np-complete_np-hard.svg/800px-P_np_np-complete_np-hard.svg.png"></p></dd>
            </dl>
        </div>
    </div>
<!-- /Navigation -->
<div class="container navigation">
    	<a class="navigate pull-left" href="./index2.html"><i class="fa fa-caret-left"></i> Previous</a>
    	<a class="navigate pull-right" href="./index4.html">Next <i class="fa fa-caret-right"></i></a>
</div>              
<!-- /Navigation --> 
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Sitemap</div>
                        <ul class="list-unstyled">
                            <li><a href="./archives.html">Archives</a></li>
                            <li><a href="./tags.html">Tags</a></li>
                            <li><a href="YCNote/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">Atom Feed</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Contact Me</div>
                        <ul class="list-unstyled">
                            <li><a href="./about-me.html" target="_blank">About Me</a></li>
                            <li><a href="https://github.com/GitYCC" target="_blank">Github</a></li>
                            <li><a href="mailto:ycc.tw.email@gmail.com" target="_blank">Email</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; YC Note 2018</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>