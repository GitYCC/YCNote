<!DOCTYPE html>
<html lang="zh">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="Ai.ml">
        <meta name="keywords" content="">
        <link rel="icon" href="../static/img/favicon.png">

        <title>AI.ML - YC Note</title>

        <!-- Stylesheets -->
        <link href="../theme/css/all.min.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <link href="YCNote/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="YC Note Full Atom Feed" />
        <link href="YCNote/feeds/aiml.atom.xml" type="application/atom+xml" rel="alternate" title="YC Note Categories Atom Feed" />
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->



    </head>

    <body>

        <!-- Header -->
    <div class="header-container" style="background: linear-gradient(rgba(0, 0, 0, 0.2), rgba(0, 0, 0, 0.2)), url('../images/welcome_front_board.jpg'); background-position: center; background-size: cover;">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                        <a class="pull-left" href="../"><img class="logo" src="../static/img/favicon.png" alt="logo">YC Note</a>
                    </div>
                    <div class="nav pull-right">
                                <a href="../category/coding.html">Coding</a>
                                <a href="../category/aiml.html">AI.ML</a>
                                <a href="../category/reading.html">Reading</a>
                                <a href="../category/recording.html">Recording</a>
                                <a href="../about-me.html">About Me</a>
                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title text-uppercase">Ai.ml</h1>
                      <div class="header-underline"></div>
                      <p class="header-subtitle header-subtitle-homepage">www.ycc.idv.tw</p>
                  </div>
              </div>
        </div>
    </div>
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    <div class="archive-container">
        <div class="container content archive">
            <h2><a href="../category/aiml.html">AI.ML : All Articles</u> </a></h2>
            <dl class="dl-horizontal">
            	<dt>2016 / 9月 18</dt>
            	<dd><a href="../ml-course-foundations_4.html">機器學習基石 學習筆記 (4)：機器可以怎麼學得更好?</a></dd>
              <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>前言</u></h5>
<p>在上一回中，我們已經了解了機器學習基本的操作該怎麼做。而這一篇中，我們來看<strong>機器可以怎麼學得更好?</strong> 基本上有三招：Feature Transformation（特徵轉換）、Regularization（正規化）和Validation（驗證），我們來看看。</p>
<p><br/></p>
<h5><u>Feature Transformation（特徵轉換）</u></h5>
<p><img alt="ML" src="https://dl.dropbox.com/s/vutayryjaw27ckp/MachineLearningFoundations.013.jpeg"></p>
<p>在上一回當中我們講了很多的線性模型，大家有沒有懷疑說，數據呈現的方式一定可以用線性描述嗎？我的答案是通常線性描述會表現不錯，但不是絕對，<strong>那我們怎麼用非線性的方法來描述我們的數據，這邊提供一個方法叫做「非線性轉換」，或者又稱為「特徵轉換」（還記得變數x又可以稱為特徵Features）</strong>，聽起來有點困難齁～其實不會啦！</p>
<p>假設今天你的Data分布是圓圈狀的分布，顯而易見的你很難用一條線去區分他們，那我們應該怎麼做呢？假設今天有一個轉換可以把這個圓圈狀分布的空間轉換到另外一個空間，在這個新的空間可以做到線性可分，這樣的問題不就解決了嗎，我們會做線性可分的問題啊！</p>
<p>這個轉換就叫做「非線性轉換」，那這個轉換要怎麼得到呢？可以用人為定義，譬如你知道這個空間的分布狀況是圓圈分布，記作 </p>
<p>H(x<sub>1</sub>, x<sub>2</sub>) = sign(-A*x<sub>1</sub><sup>2</sup>-B*x<sub>2</sub><sup>2</sup>+C)</p>
<p>，那只要做一件事我就可以把它轉換成線性可描述的，令 z<sub>1</sub>=-x<sub>1</sub><sup>2</sup>; z<sub>2</sub>=-x<sub>2</sub><sup>2</sup>，所以問題就變成</p>
<p>H(z<sub>1</sub>, z<sub>2</sub>) = sign(A*z<sub>1</sub>+B*z<sub>2</sub>+C)</p>
<p>此時這個問題就變成一個線性問題啦！</p>
<p><strong>藉由人為觀察數據並給予適當的特徵轉換是特徵工程（Feature Engineering）中一件重要的事。</strong></p>
<p>但如果我們需要去人為定義這個「非線性轉換」，這就很弱啦！我們當然希望機器可以自行從Data中學習到這個轉換，作法是這樣的，我們先把變數x做個變化和擴充，讓它們互相的相乘創造出高次項，再把這些項等價的放到Linear Model裡，所以我們就用了線性的作法來做到Non-linear Model，而因為有權重W在非線性項前面的關係，所以機器會針對Data自行去調配非線性項，這效果就等同於機器自行學習到「非線性轉換」。</p>
<p><strong>機器自己學習特徵轉換的這個概念應該是現今ML最重要的概念之一，最近很夯的深度學習甚至不只做一次性的特徵轉換，而是做了多層的特徵轉換，而這些轉換都是機器自動從Data中學來的。</strong></p>
<p><strong>特徵轉換讓ML變得很強大，但要特別注意，因為我們增加了非線性項，所以等於是增加了模型的複雜度，這麼做的確可以壓低E<sub>in</sub>沒有錯，但也可能使得E<sub>in</sub> ≈ E<sub>out</sub>不再成立，也就是Overfitting，所以建議要逐步的增加非線性項，從低次方的項開始加起，避免Overfitting。</strong></p>
<p><br /></p>
<h5><u>Overfitting</u></h5>
<p>Overfitting是一個大怪獸，在學習怎麼對付牠之前，我們先來好好的了解牠！</p>
<p><img alt="Overfitting" src="https://dl.dropbox.com/s/jet3ocknucywtlz/MachineLearningFoundations.000.03.png"></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/13_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/13_handout.pdf</a></p>
<p>上面這張圖用很簡單的方法說明了Overfitting是怎麼一回事，假設藍色的線是Target，也就是我們抽樣的母群體，因為雜訊的關係，抽樣出來的點可能會稍微偏離Target，而如果這個時候我們用二次式來描述這些抽樣出來的Data（上圖中的左側）會發現E<sub>in</sub>不能壓到0，所以這個時候可能有人想說加進去更高次項來試試看（上圖中的右側），此時會發現E<sub>in</sub>=0，所有數據都可以被完整描述了，但是你會發現Fit的曲線已經完全偏離了Target，反而是使用低次項還描述的比較好，所以結論是<strong>如果我們把「隨機雜訊」（Stochastic Noise）Fit進去Model裡面就會因此產生Overfitting</strong>。</p>
<p><img alt="Overfitting2" src="https://dl.dropbox.com/s/wzv2dxk0m310wuy/MachineLearningFoundations.000.04.png"></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/13_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/13_handout.pdf</a></p>
<p>但可別以為沒有「隨機雜訊」鬧場就不會出現Overfitting，上圖假設一個沒有「隨機雜訊」的情形，但是Target Function的複雜度很高（上圖右側），當我們從中採樣一些Data來進行Fitting，如上圖左側，我們分別使用2次和10次來做Fitting，這個時候你會發現雖然2次和10次都和Target曲線差很遠，但是小次方的還是Fit的比較好一點，造成Overfitting的原因是因為當Target很複雜的情況下，如果採樣的數據不大，根本無法反應Target本身，所以就算使用了和Target一樣複雜的Model，也只是在瞎猜而已。<strong>這種因為Target本身的複雜度所帶來的雜訊，我們稱為「決定性雜訊」(Deterministic Noise)</strong>。</p>
<p><img alt="Noise" src="https://dl.dropbox.com/s/vgur2f9qjmonlm0/MachineLearningFoundations.000.05.png"></p>
<p>From: <a href="https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/13_handout.pdf">https://www.csie.ntu.edu.tw/~htlin/course/mlfound17fall/doc/13_handout.pdf</a></p>
<p>我們來看一下「隨機雜訊」（Stochastic Noise）和「決定性雜訊」（Deterministic Noise）怎麼造成Overfitting的，上圖中的兩張漸層圖表示的是Overfitting的程度，越接近紅色代表Overfitting越嚴重；反之，越接近藍色則Overfitting越輕微。左邊的漸層圖是考慮「隨機誤差」的影響，右邊的漸層圖則是考慮「決定性雜訊」的影響。從這兩張圖我們可以觀察出下面四點，</p>
<ol>
<li>Data數量N越少，越容易Overfitting</li>
<li>「隨機雜訊」越多，越容易Overfitting</li>
<li>「決定性雜訊」越多，越容易Overfitting</li>
<li>Model本身越複雜，越容易Overfitting</li>
</ol>
<p>那有什麼方法可以防止Overfitting嗎？有的，有一些之前提過，而有一些我接下來會講，我們來看一下：</p>
<ol>
<li><strong>從簡單的模型開始做起，從低次模型開始做起，在慢慢加入高次項</strong></li>
<li><strong>提升資料的正確性：Data Cleaning/Pruning（資料清洗）將錯誤的Data修正或刪除</strong></li>
<li><strong>Data Hinting（製造資料），使用合理的方法擴增原有的資料，例如：在圖形辨識問題中，可以用平移和旋轉來擴增出更多Data</strong></li>
<li><strong>Regularization（正規化）：限制權重W的大小以控制高次的影響。</strong>（接下來會詳述...）</li>
<li><strong>Validation（驗證）：將部分Data保留不進去Fitting，然後用這個Validation Data來檢驗Overfitting的程度。</strong>（接下來會詳述...）</li>
</ol>
<p><br /></p>
<h5><u>Regularization（正規化）</u></h5>
<p><img alt="regularation" src="https://dl.dropbox.com/s/3aulwfr8gj2pr14/MachineLearningFoundations.014.jpeg"></p>
<p>剛剛我們提到了Overfitting所造成的影響很大一部分是因為Model複雜度所造成的，但是為了可以把E<sub>in</sub>給壓下去，我們又的確需要去增加高次項，所以依照建議需要從低次項開始慢慢的加，這樣感覺很麻煩啊！<strong>有沒有辦法讓機器自己去限制高次項的出現呢？有的，這就是Regularization（正規化）</strong>。</p>
<p>還記得剛剛在講「特徵轉換」時，有提到一點，ML有辦法自行學習「特徵轉換」的關鍵是因為高次項前面有一個可調控的權重，而機器會針對Data來調整權重大小，那其實就是等價於機器自己學習到了「特徵轉換」，同理可知，<strong>我們只要限制權重W的大小就等同於限制了機器無所忌憚的使用高次項</strong>。</p>
<p>經數學證明，<strong>限制權重W的大小可以等價於在E<sub>in</sub>上面加上「W大小的平方」乘上定值λ，λ越大代表W大小限制越緊；λ越小代表W大小限制越鬆</strong>，這也非常容易想像，訓練Model的方法是去降低E<sub>in</sub>，但是如果使用了大的W，就會使得E<sub>in</sub>增大，自然而然在訓練的過程中，機器會去尋找小一點的W，也就等同於限制了W的大小。</p>
<p>見上圖左側，我們修改了Gradient Descent讓它受到Regularization的限制。</p>
<p>而上圖左側下方，顯示了在λ增大的同時，限制W的大小會越來越緊，所以Fitting的結果從原本的Overfitting變成Underfitting。</p>
<p><strong>Underfitting所代表的是Model本身的複雜度不足以使得E<sub>in</sub>減小，如果你經過Validation（待會會講）後發現沒有Overfitting的現象，但是你的E<sub>in</sub>始終壓不下來，那就有可能是Underfitting，那你可以考慮增加Model複雜度或者放寬Regularization。</strong></p>
<p><strong>Regularizer的選擇常見的有兩種L2和L1，L2使用「W大小的平方」，L1則使用「W大小的絕對值」。</strong></p>
<p>當Linear Regression使用Regularization限制，統計上有一個名稱稱為Ridge Regression，你可以使用Gradient Descent來做，又或者使用解析解的方法。</p>
<p>最後提一個Regularization的細節，你會發現因為高次項是彼此兩兩相乘的結果，所以項目的個數會隨著次方增加而增加，這麼一來在做Regularization時可能會過度懲罰高次項，因此，我們可以將Feature轉換成Legendre Polynomials來避免這個問題。</p>
<p><br /></p>
<h5><u>Validation（驗證）</u></h5>
<p><img alt="validation" src="https://dl.dropbox.com/s/ytuv7ns8s39ocvd/MachineLearningFoundations.015.jpeg"></p>
<p>講了這麼多Overfitting，但到底要怎麼去量化Overfitting呢？Overfitting就是E<sub>in</sub> ≈ E<sub>out</sub>不成立，但是E<sub>out</sub>我們不會知道啊！因為我們不會知道Target Function是什麼，那該怎麼得到量化Overfitting的值呢？</p>
<p><strong>有一個方法叫做Validation可以拿來量化Overfitting的值，這個方法是先將採樣的數據做分離，一部分將會拿來做Model Fitting（Model Training），另外一部分保留起來評估訓練完畢的Model，因為保留的這一部分源自於母群體，而且又沒有被Model給看過，所以它可以很客觀的反應出E<sub>out</sub>的大小。</strong></p>
<p>我們的Model和Algorithm從以前講到現在已經是越來越複雜了，來複習一下Model和Algorithm受哪些參數影響，Algorithm的選擇就有很多了，包括：PLA、Linear Regression、Logistic Regression；Learning Rate η也需要去選擇大小決定學習速率；Feature Transformation中Feature的決定和次方大小的決定；Regularization也有L2、L1 Regularizer的選擇；還有Regularization的λ值也必須被決定。</p>
<p>這些條件彼此交互搭配會產生很多組的Model，那該如何挑選Model呢？我們就可以使用Validation來當作一個依據來選擇Model，選擇出E<sub>val</sub>最小的Model，如上圖所示。</p>
<p>另外實作上有一些方法：Leave-One-Out Cross Validation和V-Fold Cross Validation，他們的精髓就是保留k筆Data當作未來Validation用，另外一些拿下去Train Model，然後再用這k筆去評估並得到E<sub>val</sub>1，還沒結束，為了讓E<sub>val</sub>盡可能的正確，所以我們會在把Data作一個迴轉，這次使用另外一組k組Data來Validation，其餘的再拿去Train Model，然後在評估出E<sub>val</sub>2， … 以此類推，當轉完一輪之後，在把這些E<sub>val</sub>1, E<sub>val</sub>2, ...做平均得到一個較為精確E<sub>val</sub>。那Leave-One-Out Cross Validation顧名思義就是k=1，但這樣做要付出的代價就是計算量太大了，所以V-Fold Cross Validation則使用k=V來做。實務上，我常常做Validation時根本不會去Cross它們，我大都只是保留一部分的Data來驗證而已，給大家參考。</p>
<p><br /></p>
<h5><u>總結</u></h5>
<p>來到了這四篇有關於林軒田教授機器學習基石學習筆記的尾聲了，讓我們重溫看看我們學會了什麼？</p>
<p>一開始我帶大家初探ML的基本架構，建立Model、使用Data訓練、最後達到描述Target Function的目的，也帶大家認識各種機器學習的類型。</p>
<p>接下來，我們用理論告訴大家，ML是不是真的可以做到，那在什麼時候可以做到？要符合哪些條件？我們知道要有好的Model，VC Dimension越小越好，也就是可調控的參數越少越好，才會使得E<sub>in</sub> ≈ E<sub>out</sub>成立；要有足夠的Data；要有好的Learning Algorithm能把E<sub>in</sub>壓低，這三種條件成立後，如此一來Model在描述訓練數據很好的同時也可以很好的去預測母群體，但我們發現E<sub>in</sub>壓低和可調控的參數越少越好兩者是Trade-off，所以我們必須取適當的VC Dimension。</p>
<p>再接下來我們開始看實際上ML該怎麼做，引入相當重要的Learning Algorithm，也就是Gradient Descent，並且說明了Linear Regression和Logistic Regression，而且還可以使用這兩種Regression來做分類問題。</p>
<p>那最後就真正亮出ML的三大絕招啦：Feature Transformation（特徵轉換）、Regularization（正規化）和Validation（驗證），Feature Transformation使得Model更為強大，所以E<sub>in</sub>更能夠壓低，但是為了避免Overfitting我們必須去限制它，Regularization可以限制高次項的貢獻，另外，Validation可以量化Overfitting的程度，有了這個我們就可以去選出體質健康而且E<sub>in</sub>又小的Model。</p>
<p>機器學習基石的這些概念都很重要，往後如果你開始學習其他的ML技巧，例如：深度學習，這些知識都是你強大的基礎，所以多看幾次吧！</p></dd>
              
            	<dt>2016 / 8月 07</dt>
            	<dd><a href="../ml-course-foundations_3.html">機器學習基石 學習筆記 (3)：機器可以怎麼樣學習?</a></dd>
              <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>前言</u></h5>
<p>在上一回中，我們已經了解了機器學習在理論上有怎樣的條件才可以達成，所以接下來我們就可以正式的來看有哪一些機器學習的方法。</p>
<p>在這一篇中，我會帶大家初探：<strong>機器可以怎麼樣學習?</strong> 內容包括：Gradient Descent、Linear Regression、Logistic Regression、使用迴歸法做二元分類問題等等。</p>
<p><br/></p>
<h5><u>Gradient Descent（梯度下降）</u></h5>
<p><img alt="ML" src="https://dl.dropbox.com/s/9wwibe1ix3cs1od/MachineLearningFoundations.009.jpeg"></p>
<p>還記得上一回我們歸納出了一套ML的流程，複習一下</p>
<ol>
<li>準備好足夠的數據</li>
<li>把Model建立好，d<sub>VC</sub>必須要是有限的，而且大小要適中</li>
<li>定義好評估E<sub>in</sub>的Error Measurement</li>
<li>使用演算法找出最佳參數把E<sub>in</sub>降低</li>
<li>最後評估一下是否有Overfitting的狀況，確保E<sub>in</sub> ≈ E<sub>out</sub></li>
</ol>
<p>請容許我先不管Model這部份該怎麼建立，我們先來看如何找到最佳參數這部份，<strong>假設今天我知道E<sub>in</sub>的評估方法，我該如何找到最佳的參數來使得E<sub>in</sub>更小？有一套普遍的方法叫做Gradient Descent</strong>，很強大，甚至連現今流行的「深度學習」找最佳解的機制也是從Gradient Descent衍生出來的。</p>
<p>想像一下你是一位登山客，你在爬一座由E<sub>in</sub>所決定的高山，你的目標是去這座山最低的山谷，也就是E<sub>in</sub>最小的地方，因為村莊正在那裡，但是很不幸的你沒有地圖，這個時候有什麼方法可以知道低谷在哪裡呢？答案是就一直下坡吧！反正我知道村莊在山谷裡，那我就一路下山應該就可以找到村莊了，這就是Gradient Descent的精髓。</p>
<p>在數學上有一個衡量函數變化的東西，這就是Gradient（梯度），Gradient是一個向量，它的「方向」指向函數值增加量最大的方向，而它的「大小」反應這個變化有多大，其實就是一次微分啦！只不過Gradient推廣到高維度而已。所以我們和這個登山客做一樣的事情，我們朝著下降最多的方向前進，這就是Gradient Descent（梯度下降法），我剛剛說了，梯度是指向函數值增加量最大的方向，那顯然我們往反方向走就可以達到最大下降，所以如果我們有一個Error函數E<sub>in</sub>，它的Gradient就是∇E<sub>in</sub>，那我們的下降方向就是-∇E<sub>in</sub>。</p>
<p>來看一下上圖中Gradient Descent的流程，</p>
<ol>
<li>定義出Error函數</li>
<li>Error函數讓我們可以去評估E<sub>in</sub></li>
<li>算出它的梯度∇E<sub>in</sub></li>
<li>朝著∇E<sub>in</sub>的反方向更新參數W，而每次只跨出η大小的一步</li>
<li>反覆的計算新參數W的梯度，並一再的更新參數W</li>
</ol>
<p>這邊要特別注意，流程中的第四項中，有提到η，<strong>η稱為Learning Rate，它影響的是更新步伐的大小</strong>，η的選擇要適當，如果η太小的時候，我們可能要花很多時間才可以走到低點，但如果η太大的話，又可能導致我們在兩個山腰間跳來跳去，甚至越更新越往高處跑，<strong>所以選擇適當的η相當的重要，所以下次如果你發現E<sub>in</sub>一直降不下來甚至在增大，試著將η減小看看</strong>。另外η也可以是變動的值，我們可以直接設η＝|∇E<sub>in</sub>|，這麼一來遇到陡坡的時候它就會跨大一點的步伐，遇到緩坡的時候就會跨小步一點，隨狀況調整η的值。</p>
<p>Gradient Descent (GD, 梯度下降) 有兩個變形，分別為Stochastic Gradient Descent (SGD, 隨機梯度下降) 和 Batch Gradient Descent (BGD, 批次梯度下降)，這差別只在於評估∇E<sub>in</sub>的時候所考慮的Data數量，正常來說必須要考慮所有的Data，我們才會得到真正的E<sub>in</sub>，才有辦法算出正確的∇E<sub>in</sub>，但這樣所要付出的代價就是較大的計算量。</p>
<p>所以<strong>Stochastic Gradient Descent的作法是一次只拿一筆Data來求E<sub>in</sub>'，並且更新參數W</strong>，這樣的更新方法顯然會比較不穩定，但我們假設，經過好幾輪的更新後，已經完整看過整個數據了，所以平均來說效果和一般的Gradient Descent一樣。</p>
<p>另外還有一種介於Gradient Descent和Stochastic Gradient Descent之間的作法，稱之為Batch Gradient Descent，它不像Stochastic Gradient Descent那麼極端，一次只評估一組Data，<strong>Batch Gradient Descent一次評估k組數據，並更新參數W</strong>，這是相當好的折衷方案，平衡計算時間和更新穩定度，而且在某些情形下，計算時間還比Stochastic Gradient Descent還快，為什麼呢？GPU的計算方法你可以想像成在做矩陣計算，矩陣元素在計算的時候往往是可以拆開計算的，此時GPU利用它強大的平行化運算將這些元素平行計算，可以大大增進效率，所以如果一次只算一筆資料，反而是沒有利用到GPU的效率，<strong>所以如果你用GPU計算的話，依照你的GPU去設計適當的k值做Batch Gradient Descent，是既有效率又穩定的作法</strong>。</p>
<p>Gradient Descent求最佳解其實是會產生問題的，還記得我們的目標嗎？我們希望可以走到最低點的山谷裡，所以我們採取的策略是不斷的下降，這個時候如果遇到兩種情形就會動彈不得，</p>
<ol>
<li>小山谷，數學上稱為<strong>Local Minimum</strong>，雖然在那點看起來，那邊的確是低點，但卻不是整個E<sub>in</sub>的最低點</li>
<li>平原，數學上稱為<strong>Saddle Point（鞍點）</strong>，在一片很平的區域，∇E<sub>in</sub>=0，所以就停止不動了</li>
</ol>
<p>針對這些問題有一些改良後的演算法，在這裡不詳述，請參考<a href="http://ruder.io/optimizing-gradient-descent/">S. Ruder的整理</a>。</p>
<p>好！我們已經了解了怎麼使用Gradient Descent去找到E<sub>in</sub>最小的最佳參數，那我們可以回頭看Model有哪一些？Error Measure該怎麼定？</p>
<p><br/></p>
<h5><u>Linear Regression</u></h5>
<p><img alt="ML" src="https://dl.dropbox.com/s/prx1u719y743s56/MachineLearningFoundations.010.jpeg"></p>
<p>先從最簡單的看起，那就是線性迴歸（Linear Regression），假設今天我要用三種變數(x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>)來建立一個簡單的線性模型，那就是</p>
<p>w<sub>0</sub>+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+w<sub>3</sub>x<sub>3</sub>，</p>
<p>這個又稱為Score，標為s，為了方便起見，我們會額外增加x<sub>0</sub>=1的參數，這麼一來Score就可以寫成矩陣形式</p>
<p>s = w<sub>0</sub>x<sub>0</sub>+w<sub>1</sub>x<sub>1</sub>+w<sub>2</sub>x<sub>2</sub>+w<sub>3</sub>x<sub>3</sub>=W<sup>T</sup>x</p>
<p>W = [w<sub>0</sub>, w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>]</p>
<p>x = [x<sub>0</sub>=1, x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>]</p>
<p>在線性模型中，這個 s 就正好是我們Model預測的 y，通常我們會把預測得來的 y 記作 ŷ (y hat)，如果今天這個 y 和 ŷ 是實數的話，那這就是一個標準的Linear Regression問題，那如何去衡量預測的好或不好呢？<strong>我們可以使用Squared Error來衡量，err(ŷ,y)=(ŷ-y)<sup>2</sup></strong>，所以 ŷ 和 y 越靠近Error就越小。</p>
<p>Squared Error的E<sub>in</sub>平面比較簡單，就是一個單純的開口向上的拋物線，所以它的最低點其實是有解析解的，我們可以靠著數學上的<strong>Pseudo-Inverse方法</strong>在評估完全部的Data之後把最佳參數給算出來，這麼簡單的E<sub>in</sub>平面是很難見到的，我們之前介紹的Gradient Descent則是靠著逐步更新的方式去尋找近似解，這個方法是不管E<sub>in</sub>平面有多麼複雜都可以處理，但是需要特別注意別卡在Local Minimum和Saddle Point。</p>
<p><br/></p>
<h5><u>Logistic Regression</u></h5>
<p><img alt="ML" src="https://dl.dropbox.com/s/ugchv7yzd1bcm1a/MachineLearningFoundations.011.jpeg"></p>
<p>在上一回討論二元分類問題時，我們考慮的狀況是「沒有雜訊」的情形，不過在實際情況下，「雜訊」是一定需要考慮的。在「沒有雜訊」的情形下，一筆Data只會有一個確定的答案，<strong>如果考慮「雜訊」，一筆Data有可能有多個答案，呈現機率分布</strong>，對於正確答案的機率也許會高一點，但因為雜訊的干擾的原因並非能百分之一百的出現正確答案。</p>
<p>在二元分類的答案因為雜訊出現了機率分布，可能會產生像下面一樣的情況，</p>
<p>ℙ(◯|X<sup>1</sup>) = 0.9 ;   ℙ(✕|X<sup>1</sup>) = 0.1</p>
<p>而之前PLA的分類方法是屬於非黑及白的，這種分類法我們稱為Hard Classification，並不能描述這種機率分布，所以我們來考慮另外一種分類法，稱之為Soft Classification。</p>
<p><strong>Soft Classification看待每個答案不是非黑及白的，而是去評估每個答案出現的機會有多大，以此作為分類</strong>，我們打算使用Regression的連續特性來產生Soft Classification，我們需要引入一個重要的函數—Logistic Function，這個函數可以將所有實數映射到0到1之間，如上圖下方中間的圖示所示，<strong>Logistic Function會將極大的值映射成1，而將極小值映射成0，這個0到1的值剛剛好可以拿來當作機率的大小</strong>。</p>
<p>所以我們就可以來建立一個有機率概念的模型，這個Model的預測值是一個機率，一樣的先給予輸入變數x權重W求出Score s，再把 s 放到Logistic Function當中，我們就可以映射出在一個機率空間，我們藉由調整W來改變Model以描述我們的Data，有了這個新的Model，我們就可以用機率的方式來描述二元分類，</p>
<p>ℙ(◯|X<sup>1</sup>) = Θ(s) ;   ℙ(✕|X<sup>1</sup>) = 1 - Θ(s) = Θ(-s)</p>
<p>OK! 決定好Model，我們就可以來定義它的Error Measurement的方式了，這個時候如果使用Squared Error來作為Error Measurement你會發現這種評估方式有一點失焦了，我們並不是要將雜訊給放進去Model之中，而是要在考慮雜訊之下盡可能的去描述數據背後真正的機制。</p>
<p>所以我們來探討一下「可能性」，在考慮採樣數據過程因為雜訊造成的機率分布的前提下，我們去看會採樣到這組Data的可能性，我們應該合理的認為採樣出來的這組Data應該具有最大的「可能性」，這個「可能性」可以表示成</p>
<p>Assume ◯ ≡ (y=+1) and ✕ ≡ (y=-1)</p>
<p>ℙ(likelihood of ◯) = ℙ(x<sup>1</sup>)Θ(y<sup>1</sup>×s<sup>1</sup>) × ℙ(x<sup>2</sup>)Θ(y<sup>2</sup>×s<sup>2</sup>) × … × ℙ(x<sup>N</sup>)Θ(y<sup>N</sup>×s<sup>N</sup>)</p>
<p><strong>所以我們需要設計一組Error Measurement，使得Error降低的同時可以使得ℙ of likelihood可以增大，這個Error Measurement就是Cross-Entropy，Error<sub>ce</sub>=ln[1+exp(-ys)]。</strong></p>
<p>來推導一下Cross-Entropy怎麼來的，</p>
<p>Max. ℙ(likelihood of ◯) </p>
<p>= Max. Θ(y<sup>1</sup>×s<sup>1</sup>) × Θ(y<sup>2</sup>×s<sup>2</sup>) × … × Θ(y<sup>N</sup>×s<sup>N</sup>)</p>
<p>= Min. 𝚺 -ln[Θ(y<sup>n</sup>×s<sup>n</sup>)]</p>
<p>= Min. 𝚺 ln[1+exp(-y<sup>n</sup>×s<sup>n</sup>)]</p>
<p>= Min. 𝚺 Error<sub>ce, n</sub></p>
<p><strong>我們可以使用Gradient Descent來降低Cross-Entropy，這又稱為Logistic Regression，在這個問題中就沒有簡單的解析解可以直接算，只能使用近似解來處理。</strong></p>
<p><br/></p>
<h5><u>使用迴歸法做二元分類問題</u></h5>
<p><img alt="ML" src="https://dl.dropbox.com/s/01zyuaqal2achqu/MachineLearningFoundations.012.jpeg"></p>
<p>剛剛介紹了Logistic Regression，我們可以使用Regression方式來做二元分類問題，我們來看一下實際上該怎麼做？</p>
<p>線性模型的標準方法，我們會將變數x做線性組合得到Linear Scoring Function — s，線性組合的係數和Threshold稱為權重W，我們可以調整權重W來改變Model，那針對看待s的不同方式就衍生出不同的方法。那為了可以將Regression問題轉換成二元分類問題，所以通常我們會假設(y=+1)為◯，(y=-1)為✕。</p>
<p>先回顧一下之前<a href="http://www.ycc.idv.tw/YCNote/post/25">PLA的作法</a>，我們把 <code>s&gt;0</code> 的狀況視為◯，也就是(y=+1)；然後把 <code>s&lt;0</code> 的狀況視為✕，也就是(y=-1)，把這個概念畫成上圖右側的圖，圖中藍色的階梯函數就是PLA的Error Measurement，正是因為它是一個階梯函數，所以我們不能使用Gradient Descent等Regression方法來處理，<strong>因為在階梯的每一點∇E<sub>in</sub>都是0（除了原點外），也就是如此PLA在更新的過程才無法確保趨近於最佳解，而需要使用Pocket PLA來解決這個問題</strong>。</p>
<p>那如果我們用Linear Regression來做這件事呢？我們把Squared Error畫在上圖右側小圖的紅線，你會發現它的低點會落在ys=1的地方，這應該不是我們要的結果，雖然它一樣可以把錯誤的判斷修正回正確，但是面對過度確定的正確答案，它反而會去修正它往錯誤的方向，很顯然這不是我們想要的。</p>
<p>最好的方式就是Logistic Regression了，我們將s做Logistic Function的轉換，轉換成機率，並在評估最大化Likelihood的條件下定義出Cross-Entropy來當作Error Measurement，在上圖右側的小圖，我們稍微調整Cross-Entropy，使得它的Error Function可以在ys=0的地方和Squared Error相切，<strong>這張圖告訴我們的是隨著Grandient Descent每次的更新，Logistic Regression會把分類做的越來越好，把◯和✕拉的更遠</strong>。</p>
<p><br /></p>
<h5><u>後話</u></h5>
<p>在這一篇當中，我們介紹了Grandient Descent這一個相當重要的演算法，並且運用在兩種Regression上：Linear Regression和Logistic Regression，Linear Regression是最簡單的Regression方法，甚至它還可以使用Pseudo-Inverse的方法直接算出最佳解，Logistic Regression考慮了有雜訊的Data產生的機率分布，我們可以用Logistic Regression做Soft Binary Classification，而且我們也說明了Logistic Regression為何適合拿來用在二元分類上。本篇我們對於ML的實際作法有了基本認識，在下一篇，我們繼續討論還有沒有什麼方式可以讓ML做的更好。</p></dd>
              
            	<dt>2016 / 6月 26</dt>
            	<dd><a href="../ml-course-foundations_2.html">機器學習基石 學習筆記 (2)：為什麼機器可以學習?</a></dd>
              <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>前言</u></h5>
<p>在上一回當中，我們初探了機器學習，了解了什麼時候適合使用機器學習，而不是一般的Hard Coding，那今天這篇文章要繼續問下去。</p>
<p><strong>為什麼機器可以學習(Why Can Machines Learn?)</strong>，本篇會介紹學理上機器學習（ML）必須要有哪些條件才可行，這些理論有非常多的數學，但卻是了解機器學習非常重要的內功，我會盡量避開繁複的數學運算，而帶大家直接的了解式子所要告訴我們的觀念。</p>
<h5><u>機器可以學習嗎?</u></h5>
<p><img alt="MachineLearningFoundations.001" src="https://dl.dropbox.com/s/rjxzcwyfabb02ae/MachineLearningFoundations.001.jpeg"></p>
<p>還記得上面這張圖嗎? 上次帶大家初探了Machine Learning(ML)的基本架構，可以把整個概念總結成上面這張圖。</p>
<p>我們來複習一下，先從最上面的盆子開始看起，我們用Target Function代表你想要學習的技能，在非常理想的情況下，也就是沒有noise的情況，每組輸入變數 Xn都會找到一組精確的輸出 yn，而這個Target Function能產生多個Data，圖中那些小球就是代表各個單筆的Data，今天我從中隨機抽取出N組Data來做機器學習，接下來Learning Algorithm會利用這些取出的Data去從Hypothesis Set中找出最像Target Function的Hypothesis，那這組Hypothesis就成了我們學習出來的結果，我們可以利用這個結果來預測新的問題。</p>
<p>那麼上面這張圖真的合理嗎? 我們真的有辦法用上面的方法讓機器學習嗎? </p>
<p>先介紹幾個名詞，我們會稱<strong>抽樣的Data為In-sample Data</strong>，並且稱<strong>Hypothesis預測In-sample Data的誤差為In-sample Error，表示為E<sub>in</sub></strong>，因此Learning Algorithm的目的就是找出那組Hypothesis使得E<sub>in</sub>最小。</p>
<p>回想一下二元分類問題，在上一篇當中我們使用PLA來挑選Hypothesis Set，還記得我們做了什麼事來確保我們可以得到最佳解嗎? 那就是Pocket的方法，Pocket的目的就是去留住一組能預測最好的Hypothesis，也就是能保留一組參數使得E<sub>in</sub>最小。</p>
<p>但如果E<sub>in</sub>真的已經可以壓到0了，我們就可以說機器學習已經完成了嗎？</p>
<p>並不是這樣的，回到目的，我們真正希望的是機器有辦法預測新的問題，所以真正的目標是將取樣前的母群體給預測好。</p>
<p>我們會稱<strong>抽樣前的母群體為Out-sample Data</strong>，並且稱<strong>Hypothesis預測Out-sample Data的誤差為Out-sample Error，表示為E<sub>out</sub>，我們最終目的就是把E<sub>out</sub>壓下來</strong>。</p>
<p>但遺憾的是我們不會真正知道E<sub>out</sub>的大小，所以我們只能評估E<sub>in</sub>來選取Model參數，因此重要的是需要E<sub>in</sub> ≈ E<sub>out</sub>這個條件成立，否則一切的學習都是無效的。</p>
<p><strong>總結一下機器學習的條件，我們必須建立一個 Learning Model在N筆資料輸入的情況下可以確保E<sub>in </sub>≈ E<sub>out</sub>，所以在Learning Algorithm選出最小E<sub>in</sub>的Hypothesis，同時這組Hypothesis也可以很好的預測Out-sample，我們就可以說機器已經會學習了。</strong></p>
<h5><u>E<sub>in</sub>和E<sub>out</sub>的差異</u></h5>
<p><img alt="image" src="https://dl.dropbox.com/s/z6s7d0wsq00c5nn/MachineLearningFoundations.005.jpeg"></p>
<p>剛剛我們已經提到了如果機器能學習，那就必須先確保E<sub>in</sub> ≈ E<sub>out</sub>，下面我會引入Hoeffding不等式來說明這個條件怎麼成立。</p>
<p>我們先想像一下我有一個桶子，這個桶子裝了兩種顏色的很多顆小球，分別為橘色和綠色，今天如果桶子內橘色球佔的比例為μ，而今天我們從中隨機抽樣出N顆小球，並且計算出這N顆小球中橘色佔的比例為ν，此時我們可以想像的到，μ=ν不一定會成立，但μ也不至於離ν太遠，所以Hoeffding不等式就告訴我們|μ-ν|會被限制在一個範圍內，大家可以看一下上圖中左側的圖例。</p>
<p>接下來我們再把橘球和綠球的意義換成是，一組Hypothesis預測每筆Data的好或壞，預測正確的是綠球，預測失敗的是橘球，所以橘球的比例正是一組Hypothesis的預測誤差，所以在Out-sample就是E<sub>out</sub>，在In-sample就是E<sub>in</sub>，也就得到上圖右側的公式。</p>
<p>如果我們定義E<sub>in</sub>和E<sub>out</sub>差異大於 ε 的情形為Bad Data(不好的數據)，則上述式子保證的是出現這樣Bad Data的機率將被一個定值給限制住，所以只要出現Bad Data的機率不是太大，基本上我們就可以說E<sub>in</sub> ≈ E<sub>out</sub>。</p>
<p><img alt="image" src="https://dl.dropbox.com/s/yq5l9mz9y5ulh4h/MachineLearningFoundations.006.jpeg"></p>
<p>而事實上，我們的hypothesis不會只有一個，所以接下來來考慮如果有M個Hypotheses的情況下我們的E<sub>in</sub>和E<sub>out</sub>的差異會怎麼被參數影響。</p>
<p>如果我們考慮M組Hypotheses，就會發現每種Hypothesis出現Bad Data的地方可能不一樣，因此大大的減少能使用的Data，如上圖左側所示。</p>
<p>今天如果我有1000份從Target Function取N個Data的情形，然後只用一個Hypothesis來衡量，根據Hoeffding's Inequality，1000份裡面假設大概5份會出現Bad Data，但今天我再增加一組Hypothesis來衡量，對於這個Hypothesis也可能有自己的5份Bad Data，如果很不幸的，剛剛好這5份Bad Data和前5份沒有重疊，因此用這兩個hypotheses來評估的話，1000份裡頭將會出現10份的Bad Data，由此類推，如果有M組Hypotheses，最差的情況會發生在什麼時候呢? 那就是M個Hypotheses的每份Bad Data彼此都沒有交集，夠慘吧! 所以把這些出現Bad Data的機率取聯集得到上圖右側的公式。</p>
<p>大家現在回想一下上一篇所提到的Perceptron Hypothesis Set就會發現，糟糕了! Perceptron Hypothesis Set 裡有無限多組的Hypotheses，也就是M→∞，那我們不就需要無限多的Data才能做到E<sub>in</sub> ≈ E<sub>out</sub>，否則機器根本不會學習，所以前一篇都在亂講，PLA根本無法學習，等一下，先沉住氣，聽我解釋一下，你就會明白PLA還是可以做到機器學習的。</p>
<h5><u>VC Generalization Bound</u></h5>
<p><img alt="image" src="https://dl.dropbox.com/s/5p6sz6y53oh58xe/MachineLearningFoundations.007.jpeg"></p>
<p>問題出在這裡，我們在Multi-Bin Hoeffding’s Inequality中採用了一個假設，就是假設每組Hypotheses的Bad Data彼此間都沒有重疊，所以在M→∞的情況下，當然會有一個無限大的上限值，但如果考慮了Bad Data重疊的情形，縱使M→∞的情況下還是有機會把Bad Data的出現機率壓在一個有限的定值之下。</p>
<p>我們回到二元分類問題，看一下上圖中左側的圖例，如果今天在二維平面上做二元分類，當n=1時，就算你的Hypotheses有無限多組，對於一組Data來說就只有兩種而已，再來看n=2的情況，一樣的無限多組的Hypotheses也只能分類成4種。</p>
<p>因此Hypotheses彼此之間因為Data數量的關係，而出現重疊的狀況。但聰明的你一定想到，如果今天n的數量不斷的增加，則Hypotheses被分類的數量就會增加，Hypotheses彼此之間的重疊就會漸漸減少，我們還是無法限制住Bad Data出現的機率。</p>
<p>我們繼續看下去，當n=3，沒有意外的Hypotheses會被分類為8種，那接下來n=4時，你就會發現一個有趣的現象，開始有一些情況是不會出現在這一組Hypothesis Set的，因此我們擔心因為Data數量增加而造成Hypotheses的種類暴增的情形被排除了，有一些狀況是不會出現的。</p>
<p>剛剛所提到的分類方式的數量又稱為Dichotomy。在n=1、n=2到n=3的情形，所有列得出來的方式都可被完整分類開來，我們稱這情形為Shatter，但是到了n=4的時候，有些不可能被分類的情形出現了，稱為不可被Shatter，另外又稱此情形開始發生的那點為Break Point，這邊注意一下喔! 會不會有Break Point取決於你的Hypothesis Set長怎麼樣，現在是因為線性二元分類的Hypothesis Set，所以Break Point才會在n=4，其他的Hypothesis Set就不一定了。</p>
<p>Break Point的出現非常重要，他所代表的是Bad Data的出現機率不會無所限制的大下去，因此把這概念帶入Multi-Bin Hoeffding’s Inequality，經過繁複的計算，就可以得到上圖右側的公式，原本的M消失了，取而代之的是Growth Function，Growth Function與Data數量N有關，這就是我們剛剛解說的，決定Hypothesis Set的種類的其實是 Data的數量N。</p>
<p>那麼Growth Function要怎麼和Break Point連結起來呢？</p>
<p>先定義一下VC Dimension：d<sub>VC</sub>= Break Point-1，Break Point代表首次出現不Shatter的情況，那比它小一級代表的正是最大可以Shatter的點，上面的例子中d<sub>VC</sub>=3。而這個VC Dimension就可以和我們在意的Growth Function連接起來，經過數學推倒可以得到上圖右側下方的關係式。</p>
<p>所以我們就知道啦！<strong>只要有Break Point存在，VC Dimension就是一個有限的值，也因此Growth Function是一個有限的值，VC Bound就產生了，就可以確保Bad Data出現的機率被壓在一個定值之下，所以一樣的只要資料量N夠多就可以確保E<sub>in</sub> ≈ E<sub>out</sub>，機器將可以學習。</strong></p>
<p>另外一件重要的事，VC Dimension在數學上是有意義的，<strong>d<sub>VC</sub> ≈ 可調控變數的個數</strong>，像是上述的二維二元分類問題，它的可調控變數有w0, w1 和 w2，總共3個，所以d<sub>VC</sub>=3。<strong>也就是說Hypothesis Set的可調變參數如果是有限，大部分都可以做機器學習。</strong></p>
<h5><u>機器要能學習的三要素</u></h5>
<p>前面拉哩拉雜的講了一堆，終於要推出我們的結論了! 所以如果剛剛的數學讓你感到很挫敗，沒關係，讀懂這段那就足夠了。</p>
<p>從VC Generalization Bound，我們可以知道機器學習是可能的，只要它具備三點要素：</p>
<ol>
<li><strong>Good Hypothesis Set: Hypothesis Set 必須有Break Point的存在，也意味著VC Dimension是有限的，而且越小越好，在意義上代表可以調控的變數不要太多。</strong></li>
<li><strong>Good Data: 數據量越大越好，可以壓低VC Generalization Bound</strong></li>
<li><strong>Good Learning Algorithm: 以上兩點可以確定的是E<sub>in</sub> ≈ E<sub>out</sub>，接下來好的Learning Algorithm要有能力找到E<sub>in</sub> 最小的參數。很直觀的，當我們可以調控的變數越多，我們的選擇就越多，也就是我們可以找到更小E<sub>in</sub> 的機會變多了，所以可以調控的變數不可以太少。</strong></li>
</ol>
<p>眼尖的你有沒有發現矛盾啊! 可以調控的變數很少，我們能確保E<sub>in</sub> ≈ E<sub>out</sub>，但是如果我想要找到更小的E<sub>in</sub> 又必須有更多的調控變數，這個矛盾是機器學習上一個重要的課題，<strong>解法是我們必須要能找到適當的調控變數數量，也就是適當大小的d<sub>VC</sub> </strong>。</p>
<p><img alt="" src="https://dl.dropbox.com/s/0dxzdyi0r8ourz6/MachineLearningFoundations.000.02.jpeg"></p>
<p>from: <a href="https://d396qusza40orc.cloudfront.net/ntumlone/lecture_slides/07_handout.pdf">https://d396qusza40orc.cloudfront.net/ntumlone/lecture_slides/07_handout.pdf</a></p>
<p>上圖中，我們把VC Generalization Bound公式帶入Growth Function和d<sub>VC</sub>的關係式，並且設δ 為最大可以容忍的Bad Data出現機率，把它帶入取代掉ε，整理一下，就可以推出上圖的公式，後面帶根號的紅字稱為Model Complexity，這一項代表的是Hypothesis Set造成的模型複雜度，我們可以看到它隨著d<sub>VC</sub>增加而增加。Model Complexity越大代表Bad Data更容易出現，所以E<sub>in</sub>和E<sub>out</sub>開始被帶開了。</p>
<p><strong>這個現象有一個很常見的名字叫做Overfitting，指的是使用非常複雜的Model來Fitting，雖然可以把手頭上的數據Fit的很漂亮，但是拿到其他的數據來看就會發現這Model的預測性非常的差，原因就是因為Model Complexity造成E<sub>in</sub>和E<sub>out</sub>脫鉤了，所以選擇一個複雜度適中的Model是很重要的。</strong></p>
<h5><u>機器學習架構一般化</u></h5>
<p><img alt="image" src="https://dl.dropbox.com/s/h8qabqhjjaew5gs/MachineLearningFoundations.008.jpeg"></p>
<p>最後我們來總結一下機器學習的流程，上圖中是之前提到的機器學習的架構，額外的我們還需要考慮到一些真實情形，</p>
<ol>
<li>每筆Data出現的機會不一定，同樣的採樣結果也是會受機率的影響，所以上圖中標示為P(x)，這個修改並不會影響機器學習的流程和結果。</li>
<li>Data可能會受到Noise的影響，所以給定X<sub>n</sub>並不一定會百分之一百得到y<sub>n</sub>，他存在著可能會出錯，上圖標示為P(y|x)，我們可以增大我們採樣的數量N來減少Noise的影響。</li>
<li>我們是採用E<sub>in</sub>來當作選擇Model參數的指標，因此我們需要訂出Error的評估方式，常見的有Squared Error = (y<sub>n</sub> - y<sub>prediction</sub>)<sup>2</sup>。</li>
</ol>
<p>跟著架構我們就有一套機器學習的<strong>標準流程</strong>，</p>
<ol>
<li><strong>準備好足夠的數據</strong></li>
<li><strong>把Model建立好，d<sub>VC</sub>必須要是有限的，而且大小要適中</strong></li>
<li><strong>定義好評估E<sub>in</sub>的Error Measurement</strong></li>
<li><strong>使用演算法找出最佳參數把E<sub>in</sub>降低</strong></li>
<li><strong>最後評估一下是否有Overfitting的狀況，確保E<sub>in</sub> ≈ E<sub>out</sub></strong>（未來會講怎麼做）</li>
</ol></dd>
              
            	<dt>2016 / 6月 06</dt>
            	<dd><a href="../ml-course-foundations_1.html">機器學習基石 學習筆記 (1)：何時可以使用機器學習?</a></dd>
              <dd style="border:0.5px solid rgb(200,200,200);padding:15px;margin-top:10px;margin-bottom:50px;max-height:60vh;overflow:hidden;pointer-events:none;background-color:rgb(250,250,250);"><h5><u>前言</u></h5>
<p>經過幾個月的努力，終於完成田神在Coursera上machine learning的兩門課中的第一門課—<a href="https://www.coursera.org/course/ntumlone">機器學習基石</a>，田神不愧為田神的名號，整門課上起來非常流暢，每個觀念講得非常得清晰，考究學理，但是又不會單單只有理論而已，課程中會舉很多實用的例子，讓你了解每個觀念如何實踐。因此，非常推薦大家去把Coursera上面的課程完整聽一次，應該會收益良多，接下來一系列的文章，我會摘要出《機器學習基石》之中主要的概念，適合對Machine Learning（ML）有興趣的初學者來一窺它的脈絡。</p>
<p>《機器學習基石》一共有16堂課，主要分為四個方向，第一個方向，<strong>何時可以使用機器學習(When Can Machines Learn? )</strong>，點出什麼是機器學習，適合在哪些情形下使用，並引入貫穿整個課程的二元分類問題，第二個方向，<strong>為什麼機器可以學習(Why Can Machines Learn?)</strong>，介紹學理上機器學習必須要有哪些條件才可行，這些理論是了解機器學習非常重要的內功，第三個方向，<strong>機器可以怎麼樣學習(How Can Machines Learn?)</strong>，學習完了學理，我們來看機器學習有哪些的使用方法，最後一個方向，<strong>機器可以怎麼樣學得更好(How Can Machines Learn Better?)</strong>，探討哪些問題會造成機器學不好，然後怎麼去改善。</p>
<h5><u>什麼是Machine Learning (ML)</u></h5>
<p>在了解機器學習之前，我們不妨來想想「你」從小是怎麼學習的，有人會說學習就是一個不斷記憶的過程，但這樣的說法顯然不夠全面，你總不會認為把考題的所有答案都背起來的學生就已經學會一門知識了吧！所以，考題只是表象，我們真正要學習的是它背後的觀念，可以拿來推敲未知的知識。</p>
<p>同樣的，ML的學習方式也有點類似於人類的學習，機器從Data中開始學習起，這些Data就像是一道一道的考題，而ML做的事正是去學習Data後面的觀念，而不是單純把Data給儲存起來，有了Data背後的觀念才能舉一反三，才算是真正的學會了。</p>
<p>所以，做ML有點像是手把手的造一顆大腦，並且訓練它學會Data背後的知識。那這個大腦要怎麼設計呢？這個大腦用我們學物理的人的說法就是建一個Model，而餵給它Data的過程就是Fit Model。</p>
<p>那什麼是Model呢？讓我來解釋一下，<strong>所謂的Model就是一個用來描述未知現象的架構</strong>，舉個例子，我們都知道力的公式是F=ma（力＝質量x加速度），但如果你今天拿一顆皮球來，你就會發現這個公式不那麼正確，因為皮球會形變，那怎麼辦呢？我們可以假設形變會把部份的力給抵消掉，所以式子改寫成(F-F1)=ma，在這邊F1就是那個抵消的力，這樣就是設計了一個Model來描述這個現象，而F1是一個未知的值，我們可以用實驗數據來推估F1，這就是所謂的Model Fitting。</p>
<p>物理上的Model通常是這樣做的，我們先觀察未知現象，然後從中猜測可能造成這現象的原因，總結這些原因來設計一個Model，Model中可能有一些參數還沒被決定，此時我們就可以用數據來決定它，這就是Model Fitting。</p>
<p><img alt="MachineLearningFoundations.001" src="https://dl.dropbox.com/s/rjxzcwyfabb02ae/MachineLearningFoundations.001.jpeg"></p>
<p>了解了Model的概念就相當好了解ML的架構，上圖是ML的基本架構，<strong>假設我們今天要讓機器學一樣技術，這個技術我們用一個函數來表示，稱之為Target Function，這個Target Function就是隱藏在Data後面的真正道理</strong>，每個變數X會有相應的正確答案Y。</p>
<p>今天我從Target Function中取出N組當作Data來給我的機器學習，那目標是什麼?<strong>目標當然是讓機器學習出這個Target Function啦！</strong>所以我們要先設計我們的Model，最終目的是決定Model裡的參數之後，這個被選擇的Model就是Target Function。</p>
<p>Model就是上圖中的Hypothesis Set，在Model參數還沒被決定之前，你可以想像它就像一個集合包含很多可以選擇的函數，而使用數據Model Fitting以後，選出一組最佳化的參數，就好像從這個集合中挑選一組函數一樣。</p>
<p>在這個找最佳化參數的過程，我們需要一個機制，這個機制可以評估Hypothesis Set中每組函數描述Data的好壞，並且找出描述Data最好的那組參數，這個機制就是上圖中的Learning Algorithm。</p>
<p><strong>建立Model，使用Data加上Learning Algorithm找出最佳參數，這就是ML的架構輪廓</strong>。當然這邊要補充一下，物理上的Model通常是建基在已知的知識之上，而常見的ML強大之處是不需要太多的人為的智慧，機器可以自行學習，所以我這裡指的Model是比物理上的Model更為廣義的。</p>
<h5><u>Machine Learning (ML)的使用時機</u></h5>
<p>剛剛帶大家初探了ML的架構，接下來帶大家了解什麼時候我們適合使用ML。</p>
<p>舉幾個例子，大家可能比較有感覺，譬如說Netflix曾辦過一場競賽，競賽的內容是利用客戶的影片評分紀錄，來預測未評分影片的得分，如果可以增進預測率10%，就可以獨得100萬美元獎金，這個問題就可以使用ML，Data是過去得評分紀錄，Target Function是用戶評分的規律，如此一來，機器學到了這個技術，未來就可以舉一反三的推出未評分影片的分數，和用戶喜歡的影片可能有哪些。</p>
<p>再多看幾個例子，例如設計火星勘查機，人類目前對火星的了解仍相當有限，所以我們沒辦法完全猜測勘查機在火星會遇到什麼問題，所以必須讓勘查機有ML的能力去學習各種問題的解決方法。</p>
<p>再來個例子，現在很夯的汽車自動駕駛也需要ML技術，機器去學習辨識交通號誌。</p>
<p>看了這麼多例子，我們會發現這些例子都很難以寫出簡單的規則，但是卻又存在著一種規律，這種情形正是適合用ML來做。</p>
<p>在以往電腦工程幾乎都是由工程師用嚴謹的邏輯去逐條的把規則一一的寫上，這樣的機器不具有學習能力，或稱得上人工智慧，因為它只是單純反應工程師的工人智慧而已，但如果遇到一些困難的問題，譬如告訴機器什麼是狗，這時候你就會發現很難用規則來描述，有尾巴，可是是怎樣的尾巴？有耳朵，那這耳朵怎麼和貓區分開來？此時Hard Coding就太困難了，我們不這麼做，反過來我們設計架構讓機器自己去從Data中學習。</p>
<p>總結一下，ML的使用時機有以下三種</p>
<ol>
<li><strong>你想要學習的技術存在一種模式</strong></li>
<li><strong>要學習的技術不容易簡單的Hard Coding</strong></li>
<li><strong>有可以代表這個要學習模式的Data</strong></li>
</ol>
<h5><u>二元分類問題</u></h5>
<p><img alt="img" src="https://dl.dropbox.com/s/4chm6lt80pnb684/MachineLearningFoundations.000.01.jpeg"></p>
<p>from: <a href="https://class.coursera.org/ntumlone-003/lecture/17">https://class.coursera.org/ntumlone-003/lecture/17</a></p>
<p>好! 大家現在應該對於機器學習有一些認識了，那接下來我們來實作一些例子來了解機器學習架構怎麼運作。像個小學生一樣，我們先從簡單的是非題來學起，雖然是非題看起來非常簡單，但它其實非常的powerful，是非題饒口一點的講法就是「二元分類問題」，這樣的問題將會貫穿整個16堂課程，相當重要!</p>
<p>舉個例子，今天有一家銀行想要開發一款ML的軟體，這個軟體可以根據過去信用卡核發用戶的資料，去判斷要不要核發信用卡給這個新的申請人，這些過去的資料可能包括：用戶年齡、用戶性別、用戶年薪等等，讓機器藉由這些資料去學習判斷要不要核發信用卡。把這樣的二元分類問題化作</p>
<p>Target Function：f: X =&gt; y</p>
<p>X有年齡、性別和年薪這些變數，而y則是個二元類別，不是y=1(核發)就是y= -1(不核發)。</p>
<p>那接下來，我們就要決定我們的Learning Model，也就是Hypothesis Set。</p>
<p><img alt="MachineLearningFoundations.002" src="https://dl.dropbox.com/s/r2vv0p2k097v6wb/MachineLearningFoundations.002.jpeg"></p>
<p>引入<strong>Perceptron(感知器) Hypothesis Set</strong>來當作我們的Hypothesis Set，如上圖，我們給予我們的輸入變數個別的權重，然後相加起來，並且看這個值是正還是負，來決定輸出值是+1或-1，sign函數的作用是假設輸入的值為正則輸出+1，反之則輸出-1。</p>
<p>對應核發信用卡這個例子，</p>
<p>x1 = 用戶年齡; x2 = 用戶性別; x3 = 用戶年薪，</p>
<p>在分別乘上weight w1, w2, w3，這個變數前面的weight代表這個變數對於答案Y有什麼影響，如果是正向影響，weight &gt; 0，如果沒有影響，weight = 0，如果負向影響，weight &lt; 0，舉個例子，高年薪也許可以提升核發信用卡的機會，那它前面的weight應該就是正的，也許性別並不影響核發信用卡的機會，則weight = 0，那麼考慮到這些input變數對結果影響的評估，我們會得到一個數值 w1*x1+w2*x2+....。</p>
<p>此時我們要用這個數值去做「二元分類」，也就是一分為二，怎麼做呢? 很簡單，給他一分水嶺，高於一個值(-w0)我就給他 y=+1，低於(-w0)我就給他 y=-1，用數學表示就是 sign(w0+w1*x1+w2*x2+...) ，w0可以看成是一個閥值。</p>
<p>上圖中的 s = w0+w1*x1+w2*x2+... 就像一個分數(score)一樣，高分 s&gt;0 的我就核發(+1)，低分 s &lt; 0 的我就不核發(-1)，其中權重 w0, w1, w2, ... 都可以由機器學習去調整，這些不同的weight就構成了Hypothesis Set，也就是Model，那接下來我們還需要Learning Algorithm來取出最佳參數，也就是決定一組最佳weight。</p>
<p><img alt="MachineLearningFoundations.003" src="https://dl.dropbox.com/s/51aipr85rfbylj3/MachineLearningFoundations.003.jpeg"></p>
<p>如上圖所示，<strong>Perceptron Learning Algorithm(PLA)</strong>是用於處理Perceptron Hypothesis Set的一種演算法。</p>
<p>它的作法簡單來講是，藉由一筆一筆的數據去逐步的更新它的weight使得Model可以描述這筆數據，直到不需要再更新為止，此時所有的Data都可以用這個Model表示，更新的方法是先判斷進來的這筆數據是否符合目前的Model，如果不符合，則朝變數向量Xn的方向，跨出或後退大小為Learning Rate的一步來更新weight，前進還是後退端看你的Data是y=-1或+1，y=+1就往前跨，y=-1就往後退。</p>
<p>因此，這個跨步更新的動作必須可以使Model接近正確答案，這麼神奇，真的假的？不太直覺，先從score來想起，假設有一筆資料為(Xn,yn)，則Score：s = Wt・Xn，在Wt和Wn向量彼此有同向分量的情況下，s &gt; 0，如果這個時候yn剛好為+1，則sign(s)=yn，這個時候Wt描述這個數據就很好啊，我們就不需要去更新它；如果相反yn=-1，這個Wt描述這個數據就不正確，也就是說Wt 和 Xn不應該同向，所以我們讓Wt加上-Xn(=yn*Xn)，把Wt從原本與Xn同向的狀態反向拉離開來。那如果在Wt和Xn向量彼此不同向的情況下，s &lt; 0，這個時候如果yn剛好為-1，則sign(s)=yn，很好我們不去更新它；如果相反yn=+1，這個Wt描述這個數據不正確，也就是說Wt 和 Xn不應該反向，所以我們讓Wt加上Xn(=yn*Xn)，把Wt拉到和Xn同向一點。這就是PLA找到更好Wt的機制。</p>
<p><img alt="MachineLearningFoundations.004" src="https://dl.dropbox.com/s/aq6n1491d91z906/MachineLearningFoundations.004.jpeg"></p>
<p>Seeing is believing，上面這張圖帶我們來看PLA如何運作，</p>
<ul>
<li>Initially: 在最一開始的時候，我們weight Wt先設成零向量</li>
<li>Update 1: PLA更新把零向量的Wt拉成W(t+1)</li>
<li>Update 2: 上一輪的W(t+1)已經是這一輪的Wt，也就是紅色的那個向量，Wt決定了一條壁壘分明的二元分類邊界，這條線的方程式其實就是 w0+w1x1+... = 0，如果你還記得高中數學的話，這條邊界必然會和Wt垂直，如圖所示，而Wt的方向是屬於y=+1的區域，這一輪剛剛好找到一個圈(y=+1)落在y=-1的區域，因此我們需要更新weight，做法是把Wt 和 yn*Xn(=Xn)相加成為新的weight Wt+1</li>
<li>...........以此類推</li>
</ul>
<p><strong>如果資料線性可分的話，PLA在迭代多次後，是可以用一條線完全區分兩種數據</strong>。但如果數據不是線性可分，不存在一條線來區分數據，此時最佳解就必須評估整體犯錯有多少，找出犯錯最少的那條直線就是最佳解，但可惜的是PLA方法並不會在迭代中趨向於犯錯最少的那條線，什麼時候該停止迭代是個世紀難解的NP-Hard問題（如果不了解這個名詞，<a href="http://www.ycc.idv.tw/YCNote/post/19">詳見</a>）。</p>
<p>因此要改變一下PLA，這個方法我們稱之為Pocket，當每次得到一組weight的時候，都拿它來評估它對所有Data的區分能力好或壞，而只留下一組最好的放進口袋裡，所以當迭代次數做多了，保留在口袋的這組解就可以看成是最佳解，就這麼簡單。</p>
<h5><u>多元學習</u></h5>
<p>機器學習和人類學習一樣，有各式各樣的學習型態。剛剛的<strong>「二元分類問題」</strong>就像考「是非題」一樣，答案要嘛是Yes不然就是No，表示為 <strong>y={-1, 1}</strong>，這就像是機器在小學時代的問題，較為簡單。</p>
<p>現在機器脫離國小來到了國中，考試題目開始出現「選擇題」，這和機器學習中的<strong>「多元分類問題」</strong>一樣，必須從兩個以上有限的答案中作選擇，表示為 <strong>y={1, 2, ... , k}</strong>。</p>
<p>另外機器還可能遇到傷透腦筋的「計算題」，在機器學習裏頭稱為<strong>「Regression 問題」</strong>，這個時候答案已經放寬到整個實數系了，表示為 <strong>y∈R</strong>，舉個例子，譬如利用過去天氣的數據去預測明日氣溫，或者利用歷史股價資料預測未來股價，都是Regression的應用。</p>
<p>此時，機器到了大學，開始碰到不那麼容易回答，甚至不存在單一答案的「申論題」，這在ML中像是<strong>「Structure Learning 問題」</strong>，答案的選擇換成了各種結構，表示為 <strong>y={structures}</strong>，舉個例子可能比較好理解，例如：自然語言，我們都希望有一天電腦可以理解我們的語言，我們可以不再需要以機器語言來和電腦溝通，而是用人類的語言直接和電腦溝通，聽起來很棒對吧! 這個部分的ML就需要Structure Learning來學習語言的文法結構。</p>
<p>我們教機器學習也有各種不同的教育方法。</p>
<p>有像是填鴨式教育的<strong>「Supervised Learning」(監督式學習）</strong>，直接告訴機器考題和答案，讓機器從中學習，這種情況下每筆資料Xn對應的yn都有明確Label，答案是人類直接告訴機器的。</p>
<p>有像是培養科學家教育方法一樣的<strong>「Unsupervised Learning」(非監督式學習）</strong>，此時每筆資料Xn對應的yn都沒有Label，所以機器要自己歸納整理，然後從中學到規律，通常用於分群問題，對資料做分類找出規律性。</p>
<p>那還有折衷於上述兩種方法的啟發式教育，<strong>「Semi-supervised Learning」(半監督式學習）</strong>，在這個情形下有部分資料yn是有Label的，機器可以藉由有Label的正確答案和資料的規律性來做更好的學習，一個有名的例子是Facebook的人臉辨識標記功能，有部分已經被用戶標記的照片，這屬於有Label的yn，但有更多沒有標記的照片，這些照片也可以幫助ML學習。</p>
<p>那還有像是訓練小狗的方法，當我跟小狗說坐下，如果牠真的坐下了，這個時候我就給牠獎勵，譬如說餵牠好吃的食物，久而久之牠就會學會聽從這個命令，<strong>「Reinforcement Learning」(強化式學習）</strong>就是不直接表明yn的Label，但是機器能知道yn結果的好壞，再從這個好壞當作回饋去優化它的學習。</p>
<p>Data給的方法也可以有很多種類。</p>
<p>剛剛舉的ML例子都是屬於<strong>「Batch Learning」</strong>，也就是一次給你所有的Data。另外一種給Data的方法叫做<strong>「Online Learning」</strong>，這個情形下Data會一個一個以序列的方式餵給機器，這麼方式下的Model可以隨時更新。最後一種方式是<strong>「Active Learning」</strong>，機器不僅是被動的接受 Data，而是會根據它自己的需求向使用者索取它想要的Data。</p>
<p>另外，除了有輸出值yn有多種種類之外，輸入的變數 Xn的來源也有很多種，我們稱之為Features。</p>
<p>如果具有物理意義的輸入變數，稱之為<strong>「Concrete Features」</strong>，這些變數建立在人類知識的預先處理。還有輸入變數並不具有物理含意的情形，這稱之為<strong>「Abstract Features」</strong>。那有些情形下直接採用不加以處理的原始數據，稱為<strong>「Raw Features」</strong>。</p>
<p>而使用工人智慧由人力從Raw Features中萃取出Concrete Features，這叫做Feature Engineering，而現在很夯的Deep Learning厲害的地方是他可以自行從Data中學習 Features。</p>
<p><strong>總結一下，機器學習有很多種型態，從Data的給予方式可分為Batch Learning、Online Learning和Active Learning。Data的表達形式由輸入變數 Xn和輸出值 yn所決定，從輸入變數 Xn的來源可分為Concrete Features、Raw Features和Abstract Features，從輸出值 yn的種類上可以分為二元分類、多元分類、Regression和Structured Learning 問題，從輸出值 yn的Label給予情況可分為Supervised Learning、Unsupervised Learning、Semi-supervised Learning 和 Reinforcement Learning。</strong></p>
<p>順道一提，這16堂課裡頭主要聚焦在探討Batch Supervised Learning with Concrete Features。</p>
<h5><u>後話</u></h5>
<p>這篇文章帶大家初探了一眼機器學習，介紹了機器學習的架構和種類，以及它的使用時機，還有介紹了整門課非常重要的二元分類問題。但是講這麼多，機器學習真的可能嗎? 那如果可以做到，會需要哪一些要素呢? 這就必須深入理論之中，才能找到答案，在下一篇文章裡，我將介紹這門課的第二個部分：Why Can Machines Learn? </p></dd>
              
            </dl>
        </div>
    </div>
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Sitemap</div>
                        <ul class="list-unstyled">
                            <li><a href="../archives.html">Archives</a></li>
                            <li><a href="../tags.html">Tags</a></li>
                            <li><a href="YCNote/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">Atom Feed</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Contact Me</div>
                        <ul class="list-unstyled">
                            <li><a href="./about-me.html" target="_blank">About Me</a></li>
                            <li><a href="https://github.com/GitYCC" target="_blank">Github</a></li>
                            <li><a href="mailto:ycc.tw.email@gmail.com" target="_blank">Email</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; YC Note 2018</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>